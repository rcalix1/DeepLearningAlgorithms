<html>
<head>

  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

  <body>

<div class="navbar">
  <a href="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/index.html"> Deep Learning </a>
  <a href="https://ricardocalix.substack.com">Substack</a>
  <a href="https://www.youtube.com/channel/UCKRgi-HJDEq0a3nhlG2nQvg">YouTube</a>
  <a href="https://github.com/rcalix1/DeepLearningAlgorithms/tree/main/SecondEdition">GitHub</a>
  <a href="https://www.galacticbackwater.com/theAIhub/index.html">Recommender</a>
  <a href="https://amzn.to/3OauEG0">Books</a>
  <a href="https://www.linkedin.com/in/ricardo-calix-phd">About</a>
  <a href="https://scholar.google.com/citations?hl=en&user=TiKVs6AAAAAJ">Scholar</a>	
  <a href="">Shop</a>
  <a href="https://www.rcalix.com">Contact</a>
</div>

    

<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->

<div class="main">    <!-- for the fixed nav bar -->

<h1>Chapter  - Generative Adversarial Networks (GANs)</h1>

    <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/ganNN.300dpi.jpg" height="400" width="auto">
      </div>

    </center>

<p>
	In this section of the book I will cover Generative Adversarial Networks (GANs). Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) are a first attempt at creating generative models.  In the context of games, GANs are modeled as a two player adversarial games. One of the biggest challenges faced with supervised learning is annotating the data. We cannot annotate automatically and without annotations we cannot train our learning models. But what if we could substitute the annotation of the data for something else? For instance, what if we could model the annotation task as a game or use other previous knowledge about the world as labels. These ideas are one of the main motivations for GANs. 
GANs are deep neural networks that consist of a generator network connected to a discriminator network. The discriminator network has training data and the generator network only has random or noise data as input. GANs are essentially 2 player games where one player (the generator) creates synthetic data samples, while the second player (the discriminator) takes the generated sample and performs a classification. 
This classification is performed to determine if the synthetic sample is similar to the distribution of the discriminator's training data. Since both networks are connected, the deep neural network (GAN) can learn to generate better synthetic samples with the help of the discriminator’s feedback. Basically, the discriminator tells the generator how to adjust its weights to produce better synthetic samples. 

Generative Adversarial Networks are methods that use 2 deep neural networks to interact with each other and generate data. Its formulation is consistent with 2 player adversarial game frameworks. One of the 2 algorithms (or networks) tries to learn a data distribution and produce new samples similar to the samples in the real data (the generator). The second algorithm (the discriminator) is a classifier that tries to determine if the new samples generated by the generative algorithm are fake or real. These 2 algorithms work together to achieve an optimal outcome of producing better output samples from the Generator. 


The generator in a GAN is based on Auto-encoders. Therefore, before looking at GANs, we will look at the Auto-encoder
</p>




<h1>Copyright, License, FTC and Amazon Disclaimer</h1>

<p>
 Copyright &copy by Ricardo A. Calix. <br/>
 All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, without written permission of the copyright owner. <br/>
 This post/page/article includes Amazon Affiliate links to products. This site receives income if you purchase through these links. 
 This income helps support content such as this one. 
 <br/>

	

  
</p>

     <center>
      <div class="img"> 
        <a href="https://amzn.to/3vOL8NF"><img src="https://m.media-amazon.com/images/I/71Wi+z5fKzL._SL1233_.jpg" height="500" width="auto"></a>
      </div>

    </center>
    

<h1>

	Generative Adversarial Networks
</h1>


<p>

In this section of the book I will cover Generative Adversarial Networks (GANs). Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) are 
	a first attempt at creating generative models.  In the context of games, GANs are modeled as a two player adversarial games. One of the biggest challenges
	faced with supervised learning is annotating the data. We cannot annotate automatically and without annotations we cannot train our learning models. But what 
	if we could substitute the annotation of the data for something else? For instance, what if we could model the annotation task as a game or use other previous
	knowledge about the world as labels. These ideas are one of the main motivations for GANs. 
GANs are deep neural networks that consist of a generator network connected to a discriminator network. The discriminator network has training data and the generator 
	network only has random or noise data as input. GANs are essentially 2 player games where one player (the generator) creates synthetic data samples, while the 
	second player (the discriminator) takes the generated sample and performs a classification. 
This classification is performed to determine if the synthetic sample is similar to the distribution of the discriminator's training data. Since both networks are 
	connected, the deep neural network (GAN) can learn to generate better synthetic samples with the help of the discriminator’s feedback. Basically, the discriminator 
	tells the generator how to adjust its weights to produce better synthetic samples. 
<br />
Generative Adversarial Networks are methods that use 2 deep neural networks to interact with each other and generate data. Its formulation is consistent with 2 player
	adversarial game frameworks. One of the 2 algorithms (or networks) tries to learn a data distribution and produce new samples similar to the samples in 
	the real data (the generator). The second algorithm (the discriminator) is a classifier that tries to determine if the new samples generated by the generative 
	algorithm are fake or real. These 2 algorithms work together to achieve an optimal outcome of producing better output samples from the Generator. 

<br />
The generator in a GAN is based on Auto-encoders. Therefore, before looking at GANs, we will look at the Auto-encoder
	
</p>

<h1>
Autoencoders
	
</h1>

<p>

Autoencoders are a type of compression method where a neural network learns how to represent a vector of size “m” into a vector of size “n” where m >> n. 
	Here, the input and output vectors in the network are the original sample and the reproduced sample and the hidden layer of the network is the new
	compressed representation of the input vector. The objective function minimizes the difference/distance between the original input sample and the reproduced 
	output sample.  
	
</p>

<h1>
Original GAN
	
</h1>

<p>
The original GAN consists of a generator and a Discriminator and was proposed in a 2014 paper by Ian Goodfellow. The general architecture of the GAN can be seen
	in the figure below.

	
</p>

	

\begin{figure}[H]\centering
\adjustbox{max height=.40\textheight}{
    \includegraphics{images/ganNN.300dpi.jpg}
}
\caption{A GAN network using MNIST}
\label{RegLin:fig}
\end{figure}



<h1>
Generating MNIST digits with GANs
	
</h1>

<p>
In this section, I will describe how to implement a GAN that can generate images. The algorithm will work with the MNIST data set. As always, 
	the code can be downloaded from my GitHub. 
<br/>
First we import the libraries. 


	
</p>


<center>
<div>
<textarea rows="20" cols="100">

import torch
import numpy as np
import os
from torchvision import datasets
from torchvision import transforms
import torchvision.transforms as T
import matplotlib.pyplot as plt
import pandas as pd
from numpy import genfromtxt
from PIL import Image
import sklearn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
from mlxtend.plotting import heatmap
from sklearn.model_selection import train_test_split
from mlxtend.plotting import heatmap
from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim 
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable


</textarea>
  
</div>
</center>






     


Next we can define the parameters as follows



<center>
<div>
<textarea rows="7" cols="100">

learning_rate    = 0.003  ## Adam default   ## 0.001
batch_size       = 32
N_Epochs         = 30  ##27000  

</textarea>
  
</div>
</center>



<p>
We load the MNIST data in a similar way to what we did in previous chapters

	
</p>

<center>
<div>
<textarea rows="16" cols="100">

data_path   = "data/MNISTdata/"
mnist_train = datasets.MNIST(data_path, train=True, download=True)
mnist_test = datasets.MNIST(data_path, train=False, download=True)

mnist_train_tr = datasets.MNIST(data_path, train=True, download=False, 
                                            transform=transforms.Compose([
                                                transforms.ToTensor()
                                            ]))
                                            
mnist_test_tr  = datasets.MNIST(data_path, train=False, download=False, 
                                            transform=transforms.Compose([
                                                transforms.ToTensor()
                                            ]))

</textarea>
  
</div>
</center>





     


It is a good idea to print the shapes of the tensors before creating the DataLoaders.

<center>
<div>
<textarea rows="16" cols="100">

mnist_train_tr.data.shape
## [60000, 28, 28]

mnist_test_tr.data.shape
## [10000, 28, 28]

train_dl  = torch.utils.data.DataLoader(mnist_train_tr, batch_size=batch_size, shuffle=True  ) 

test_dl   = torch.utils.data.DataLoader(mnist_test_tr,  batch_size=batch_size, shuffle=False ) 


</textarea>
  
</div>
</center>





     


Now we are ready to define the GAN architectures. GANs have a Generator and a Discriminator

In the following code segment we define the architecture for the Generator. Notice that this will be a neural network of size 100x256x784. 

<center>
<div>
<textarea rows="25" cols="100">

class Generator_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        

        self.linear1 = nn.Linear(100, 256)
        self.act1    = nn.LeakyReLU(0.02)
        self.norm1   = nn.LayerNorm(256)
        self.linear2 = nn.Linear(256, 784)
        self.act2    = nn.Sigmoid()
        self.dropout = nn.Dropout(0.25)
        
    def forward(self, rand_input ):
        

        x      = self.linear1( rand_input )
        x      = self.act1(x)
        x      = self.norm1(x) 
        x      = self.linear2(x)
        x      = self.act2(x)
        y_pred = x
        
        return y_pred

     
</textarea>
  
</div>
</center>





I also tried a deeper architecture for the GAN but was not able to get it to learn in 30 epochs as I did with the simple MLP GAN. I am including it here and leave it as a exercise for the reader. 


<center>
<div>
<textarea rows="25" cols="100">


class Generator_DL_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.linear1 = nn.Linear(100, 60)
        self.act1    = nn.LeakyReLU(0.02)
        self.norm1   = nn.LayerNorm(60)
        self.linear2 = nn.Linear(60, 120)
        self.act2    = nn.LeakyReLU(0.02)
        self.norm2   = nn.LayerNorm(120)
        self.linear3 = nn.Linear(120, 784)
        self.act3    = nn.Sigmoid()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, rand_input ):
        

        x      = self.linear1( rand_input )
        x      = self.act1(x)
        x      = self.norm1(x) 
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.norm2(x) 
        x      = self.dropout(x)
        x      = self.linear3(x)
        x      = self.act3(x)
        
        y_pred = x
        
        return y_pred

     

</textarea>
  
</div>
</center>
	




The architecture for the Discriminator can be seen in the next code segment.



<center>
<div>
<textarea rows="25" cols="100">

class Discriminator_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.linear1 = nn.Linear(784, 100)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(100, 50)
        self.act2    = nn.ReLU()
        self.linear3 = nn.Linear(50, 1)
        self.act3    = nn.Sigmoid()             ## nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        

    def forward(self, x):
        
        x      = self.linear1(x)
        x      = self.act1(x)
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.dropout(x)
        x      = self.linear3(x)
        y_pred = self.act3(x)
        
        return y_pred

     
</textarea>
  
</div>
</center>
	






Notice that the architecture for this network is 784x100x50x1. Its input is an image vector (real or fake) and its output is one neuron with value 0 or 1. 

The following function can be used to generate seed random noise vectors for the Generator input. For training we want batches of noise vectors.



<center>
<div>
<textarea rows="9" cols="100">

def random_G_batch_vector_input():
    rand_vec = torch.randn( (batch_size, 100 ) )
    return rand_vec

    
</textarea>
  
</div>
</center>
	









To generate individual images, we can use the following function to generate seed noise vectors



<center>
<div>
<textarea rows="9" cols="100">

def random_G_vector_input():
    rand_vec = torch.randn( 100 )
    return rand_vec
    
</textarea>
  
</div>
</center>






     


The Training function for the GAN is the most complicated we have seen so far. The full code can be seen seen below. As can be seen, we train the discriminator twice and the generator once. The Discriminator looks at a real image and it should predict that it is real (a one). Then the discriminator looks at a generated image (fake) and it should predict that it is a fake (a zero). The discriminator weights should be updated accordingly for these objectives. The final step is to update the weights of the Generator. Here, we want to trick the discriminator. So now the generated image (fake) is given to the Discriminator but we want it to say that it is real (a one). We do this using the loss of the Discriminator but adjust the weights of the Generator. So the Generator weights are updated in such a way that it generates images that trick the Discriminator into predicting that the fake images are true (a one). 

Notice that before training, we need to squeeze and reshape the input \textbf{xb} tensor from [batch, 1, 28, 28] to [batch, 784] . We can do that with the following statements.

<center>
<div>
<textarea rows="6" cols="100">

xb = torch.squeeze(xb, dim=1)
            
xb = xb.reshape((-1, 784))

    
</textarea>
  
</div>
</center>
	


<p>

	and the GAN training function is
</p>
     

<center>
<div>
<textarea rows="35" cols="100">

	
list_losses_real    = []
list_losses_fake    = []
list_losses_tricked = []
def training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt   ):
    for epoch in range(N_Epochs):
        for xb, yb in train_dl:              ## xb = [batch, 1, 28, 28]
            xb = torch.squeeze(xb, dim=1)
            xb = xb.reshape((-1, 784))
            #################################################
            ## G_model.eval()     ## No G training
            ## gen_img = G_model( random_G_vector_input() )
            gen_img = G_model( random_G_batch_vector_input() ).detach()
            ## Train D with real data
            D_real_y_pred = D_model(  xb  )
            D_real_loss   = D_loss_fn( D_real_y_pred, torch.ones((batch_size, 1)) )
            D_opt.zero_grad()
            D_real_loss.backward()
            D_opt.step()
            ## Train D with fake data
            D_fake_y_pred = D_model(  gen_img  )
            D_fake_loss   = D_loss_fn( D_fake_y_pred, torch.zeros((batch_size, 1)))
            D_opt.zero_grad()
            D_fake_loss.backward()
            D_opt.step()
            ## G_model.train()    ## yes G training
            #################################################
            ## D_model.eval()     ## No D training
            ## gen_img = G_model( random_G_vector_input() )
            gen_img = G_model( random_G_batch_vector_input() )
            ## Train G with D_loss (need to trick D)
            D_tricked_y_pred = D_model(  gen_img  )
            D_tricked_loss   = D_loss_fn( D_tricked_y_pred, torch.ones((batch_size, 1)) )
            G_opt.zero_grad()
            D_tricked_loss.backward()
            G_opt.step()
            ## D_model.train()    ## yes D training
        if epoch % 1 == 0:
            print("******************************")
            print(epoch, "D_real_loss=", D_real_loss)
            print(epoch, "D_fake_loss=", D_fake_loss)
            print(epoch, "D_tricked_loss=", D_tricked_loss)
            list_losses_real.append(        D_real_loss.detach().numpy()  )
            list_losses_fake.append(        D_fake_loss.detach().numpy()  )
            list_losses_tricked.append(  D_tricked_loss.detach().numpy()  )
            


    
</textarea>
  
</div>
</center>




Finally, we can call the core functions and print the losses during training. 

<center>
<div>
<textarea rows="12" cols="100">

G_model     = Generator_Net()

## G_model     = Generator_DL_Net()

D_model     = Discriminator_Net()

## D_loss_fn   = nn.CrossEntropyLoss( )  
## D_loss_fn   = F.mse_loss

D_loss_fn   = nn.BCELoss()

G_opt       = torch.optim.Adam( G_model.parameters(), lr=learning_rate )
D_opt       = torch.optim.Adam( D_model.parameters(), lr=learning_rate )

training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt )


</textarea>
  
</div>
</center>





We can seen below that the losses are going down for both the Generator and Discriminator. 

<center>
<div>
<textarea rows="25" cols="100">

******************************
0 D_real_loss= tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)
0 D_fake_loss= tensor(0.0114, grad_fn=<BinaryCrossEntropyBackward0>)
0 D_tricked_loss= tensor(7.8405, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
1 D_real_loss= tensor(0.2492, grad_fn=<BinaryCrossEntropyBackward0>)
1 D_fake_loss= tensor(0.0604, grad_fn=<BinaryCrossEntropyBackward0>)
1 D_tricked_loss= tensor(5.4396, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
2 D_real_loss= tensor(0.1128, grad_fn=<BinaryCrossEntropyBackward0>)
2 D_fake_loss= tensor(0.0804, grad_fn=<BinaryCrossEntropyBackward0>)
2 D_tricked_loss= tensor(4.2457, grad_fn=<BinaryCrossEntropyBackward0>)

...

******************************
27 D_real_loss= tensor(0.6145, grad_fn=<BinaryCrossEntropyBackward0>)
27 D_fake_loss= tensor(0.3502, grad_fn=<BinaryCrossEntropyBackward0>)
27 D_tricked_loss= tensor(1.2594, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
28 D_real_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)
28 D_fake_loss= tensor(0.3535, grad_fn=<BinaryCrossEntropyBackward0>)
28 D_tricked_loss= tensor(1.2053, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
29 D_real_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)
29 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)
29 D_tricked_loss= tensor(1.2962, grad_fn=<BinaryCrossEntropyBackward0>)

     

</textarea>
  
</div>
</center>





Using the following function, we can plot the losses. 

<center>
<div>
<textarea rows="15" cols="100">

def plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked):
    
    the_epochs = [i for i in range(len(list_losses_real))]  

    plt.plot(the_epochs, list_losses_real,    label = "real") 
    plt.plot(the_epochs, list_losses_fake,    label = "fake") 
    plt.plot(the_epochs, list_losses_tricked, label = "tricked")
    plt.legend() 
    plt.show()

plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked)


</textarea>
  
</div>
</center>






     


We can see that the losses of the Generator did not go below the discriminator loss. A good objective would be for them to be equal. 


\begin{figure}[H]\centering
\adjustbox{max height=.85\textheight}{
    \includegraphics{images/GAN_losses_plot.png}
}
\caption{Plot of GAN losses}
\label{RegLin:fig}
\end{figure}

And that is it. The GAN is now trained. We can now proceed to test it and generate a few images. We can do that with the following code segment. 

<center>
<div>
<textarea rows="15" cols="100">

gen_test_img3 = G_model( random_G_vector_input() )
gen_test_img3 = gen_test_img3.reshape( (28,28) )
plt.imshow( gen_test_img3.detach().numpy() )
plt.show()

</textarea>
  
</div>
</center>





     


I did this several times and the results of the generated images are as follows. This first image looks like a bad zero. 

\begin{figure}[H]\centering
\adjustbox{max height=.35\textheight}{
    \includegraphics{images/bad_zero_gan.png}
}
\caption{Generated bad zero}
\label{RegLin:fig}
\end{figure}


This next image looks like a better version of the zero.

\begin{figure}[H]\centering
\adjustbox{max height=.35\textheight}{
    \includegraphics{images/good_zero_gan.png}
}
\caption{Generated good zero}
\label{RegLin:fig}
\end{figure}

And I believe this looks like a five.

\begin{figure}[H]\centering
\adjustbox{max height=.85\textheight}{
    \includegraphics{images/good_5_gan.png}
}
\caption{Generated good five}
\label{RegLin:fig}
\end{figure}

\begin{comment}





\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}





We can use this handy function to print out the images generated by the Generator.


Here we the Generator which produces a set of fake images (G\_sample). Then we run the discriminator twice. Once on the real data (X) and once on the fake data (G\_sample). 



We can define the losses like this using the cross entropy function 


Or like this with the PyTorch built in cross entropy functions. The cross entropy functions are even more intuitive. D\_logit\_real is for real images so the discriminator wants to classify it as ones. For D\_logit\_fake, the discriminator goals is to classify it as zero. 



The generator loss is similar


If you notice, this approach is even more intuitive because you can see the goal of each loss. The goal of G\_loss is to fool the discriminator. As such, its goal is to make D\_logit\_fake equal to ones. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}


Here we define the optimization for our two losses D\_loss for the Discriminator and G\_loss for the Generator.  

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}

We specify a few parameters such as the batch size for training which is 128 and the size of the seed random vector that you feed to the generator. In this case 100.



You can read the images from PyTorch examples like this 



Or you can read your own images like in the code below. Here we read the images from a folder testA using PIL and Image. Notice that I have used images that are 28x28 for convenience. 



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}




The function convert(‘LA’) changes color images to gray scale. The result image with be of size (28, 28, 2) because .png files have a transparency. You will need to convert it to (28, 28, 1) using image[…,:1]. Now make data set float and numpy array. You can print the dimensions to confirm your data is correct. 



Now you can save the numpy array

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}

I also renamed the data set


You can view image dimensions with the following functions:



In the case of color images you could convert using the following:




It is recommended that you normalize your data to improve the learning process of the GAN. 



In the next code segment we initialize the session and create the output folder where we will save the new images generated by the Generator network. 




The main loop here is implemented with the PyTorch provided data



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}




Notice the high number of iterations.





Now the loop with your own data




In this code segment, every 1000 iterations we generate a set of fake images using the generator to see how it is doing.



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Percentage of sucesses}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


??

     
\end{lstlisting}
\end{minipage}


That’s it!

\section{Some Uses of GANs}

Generative Adversarial Networks (GANs) are one of the latest and most exciting developments in machine learning during the last decade (Goodfellow 2014). At this point, the use of GANs has been focused on research for image processing and synthetic generation. However, several studies have looked at the application of GANs to cyber security problems. 
 Currently, GANs have been used to generate works of art in the styles of Picasso, for instance, or they can potentially generate text that is similar to the styles of Shakespeare or other great authors. The application of GANs to cyber security is more recent but there already exists a body of work to highlight possible applications. In particular, the common theme is that GANs can be used by attackers to masquerade their efforts. Recent works have used GANs for password generation (Hitaj 2017) and steganography (Shi 2017). It is easy to see how this idea could also be extended to polymorphic viruses and synthetically generated network attacks.  
Understanding how attackers can use GANs to masquerade their efforts is critical to understanding how to develop better intrusion or malware detection systems. 

\section{Conditional GANs}

This section covers conditional GANs.


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Numpy math operations}}
%\lstset{label={lst:code\\\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

x = np.array([1,2,3,4])

print(x+10)
print(x-10)
print(x*10)
print(x/2)
print(-x)
print(x ** 3) 
print(np.power(4, x)) 
print(np.log(x))
print(np.log2(x)) 
print(np.log10(x) )

\end{lstlisting}
\end{minipage}

\end{comment}

\section{Conditional GANs}

The conditional GAN  (CGAN) can generate more than random images from a distribution. Instead, in the case on MNIST, for example, it can generate the image of an image given the corresponding label for the image. The architecture for the CGAN can be seen below.

\begin{figure}[H]\centering
\adjustbox{max height=.30\textheight}{
    \includegraphics{images/ConditionalGanDiagram.jpg}
}
\caption{Conditional GAN}
\label{RegLin:fig}
\end{figure}

<h1>
Summary
</h1>
	
<p>
In this chapter, a description of Generative Adversarial Networks was provided. Some sample code was addressed as well as some applications of GANs. 


	
</p>









	


<h1>Numpy arrays, tensors, and linear algebra</h1>
    
<p>
Linear algebra, numpy arrays, and tensor operations are at the heart of understanding the Transformer architecture. Before you continue, 
  I strongly recommend that you read and practice the topics in chapter 1, and in particular, the section on linear algebra, numpy arrays, and tensor operations. 

  
</p>

<h1>
Attention
  
</h1>

<p>

  The Attention mechanism in Transformers is the heart of the whole algorithm. The attention matrix is nothing more than a dot product matrix multiplication 
  between all the tokens (e.g. words, syllables, subwords, etc.) in a sentence (e.g. the input English sentence). The idea is that, given the input and output, the model learns to correlate the words in
  the sentence to determine their importance. This is done multiple times and that is why it is called a multi head attention mechanism. 


</p>

    <h1>

      Embeddings
    </h1>

<p>

Sequences of tokens in a sentence are converted into sequences of IDs. An Embedding approach converts the sequence of ids into a sequence of embeddings. 
  You will go from a 2d tensor 

  
</p>
    
<p>
[N_batches, _tokens]
  <br/>
  to a 3d tensor of size:
<br/>
 [N_batches, N_tokens ,   embedding_dimension ]
  <br/>
  
 The term N_tokens can also be called  seq_length_max. Here N_batches is the batch size, N_tokens or seq_length_max is 40, and embedding_dimension is 512.
  The term N_tokens (i.e. 40) just establishes the size of the input sentences we wiil allow. Sentences in Transformers are not of variable length. Instead you define
  a buffer size to hold the sentence. If the sentence is too long, then it is truncated. If the sentence is too short, then the buffer is padded. The embedding size is 
  selected arbitrarily like in word2vec. 

  
</p>




<h1>Masks</h1>

    <p>
Masks serve several purposes. One is to help ignore the padded values during training. The other goal is to block the given word you want to predict 
      or future words). This brings up the important aspect of training with Transformers. Transformers predict the last word in a sequence. For example:
    </p>
<p>

 Given an input in english: "the cat is sleeping"
 
</p>
	  
<p>
a Transformer is also given part of the output sentence. In this case:  "el gato esta ?". 
      The Transformer will predict the next word in the sequence which in this case would be "durmiendo" to complete the translation as “el gato esta durmiendo”. 
	All of this is achieved through the masks to ignore padded values and to only show the partial sentence. 
  
    </p>


<h1>
Positional Encoding
  
</h1>

<p>

  This is the technique that allows you to encode sequence. Transformers are all about being parallel. Their direct competitor is Recurrent Neural Networks (RNNs).
  RNNs have had several problems in the past. One is that they do not scale well to GPUs and parallel approaches because of their recurrence and dependence on previous
  steps. The other problem is the famous "vanishing gradients" problem which was addressed by by residuals and LSTMs seem to have addressed this now.  Transformers did
  away with the type of sequence modeling approach used in RNNs all together so they are very good for parallel approaches. But how do they address or encode the sequence? 
  Obviously knowing that the word "cat" goes before the word "sleeping" is useful. This is where a technique called positional encoding comes into play. Basically, after 
  embedding, you have a vector per token of, say, size 512. 

Now, with positional encoding, a function that calculates sines and cosines, is used to create a new vector also of size 512 that represents position (i.e. sequence) of 
  the tokens. The 2 vectors are added together (embedding + positional_encoding) to get the new inputs to the network. Also, the position vector values are smaller than
  the embedding vector values so as to not let position dominate. 

</p>

 

<h1>
Tokens
</h1>
    
<p>

  In a GPT we want to predict the next word given previous words. However, to improve performance, transformer models do not predict the next word. Instead, they 
  predict the next subword. A good analogy for subword is syllable, although transformer do not use syllables either. The subwords are calculated based on specific 
  algorithm such as BPE or SentencePiece. This allows transformers to learn to generate new words never seen before. For example, it may have seen 
<br/>
The dog is play - ing.
<br/>
And by breaking the word into subwords (i.e. play and ing), it can learn to generate new variations of words it never saw before such as
<br/>
The lady is iphone - ing.
<br/>
We and the Transformer know intuitively what this means.
<br/>
The fact is that tokens can be words, syllables, subwords, letters, etc. Subwords through SentencePiece type algorithms just have proven to give the best results. 

</p>

<h1>

Inputs and Outputs
  
</h1>

<p>
    
So, let us start there. Let's quickly remember our classic example of MNIST supervised classification. In MNIST standard feed forward classification, you have an 
  input image which is 28x28 and a predicted vector of size 10 for the classes. So, what do the inputs and outputs look like for transformers? For language translation, 
  they are lists of ids. Each id can represent a word in a sentence. This is best visualized with an example. 
First, let us look at the classic use case for Transformers. As I said earlier, Transformers have been used extensibly in NLP. And the first example was in language 
  translation where we have sentence pairs. Such as the following for English-Spanish translation:
<br/>
"the cat is sleeping"    -->   which translates to   -- >    "el gato esta durmiendo"
<br/>
Therefore, first we need to understand how to encode this for the neural network and then to understand how exactly it is that the network will train and learn. 
  So, again, before you look into the network's very deep and complex layers, I believe that one needs to  focus on:

  
</p>

	  <p>
    <ul>
    <li> Padding these sequences of ids</li>
    <li> Taking text sentences and converting them into sequences of ids</li>   
    </ul>
	  </p>
   



 <p>

   Consider that after encoding and padding, your sentences will look like this:

 </p>


<center>
<div>
<textarea rows="8" cols="90">


  [ 12110   203     4  3947    29     2   168     2     4    27    
       68  4333     8  3622  2943  1012     1 12111     0     0     
        0     0     0     0     0     0     0     0     0     0     
        0     0     0     0     0     0     0     0     0     0 ]

  
</textarea>
  
</div>
    </center>






<p>

	and for the other language


</p>
   



 <center>
<div>
<textarea rows="8" cols="90">

  
[ 12110    13     4  3947    29     2     5    32    36    16  
   1145     4    58    34  7905    58    25    28   354  2482     
      3    17    27    28  4395     9  2886     7 12111     0     
      0     0     0     0     0     0     0     0     0     0 ]

  
</textarea>
</div>
  </center>


<h1>

	GPTs
</h1>



<p>
GPTs stand for Generative Pre-trained Transformers. The GPT uses the decoder only part of the Transformer. The input to the decoder varies based on whether you are 
	training or predicting. If you are training, the input to the decoder is the sentence itself. When training, a mask is needed here to prevent the model from 
	seeing all the words it is trying to predict. This is called a look ahead mask.
If you are testing, the input is just the previous words before the word you are trying to predict. You start with a start of sentence token (e.g. <sos>) and predict. 
	The predicted word is then added to the previous tokens and the process is repeated.
The decoder consists of N (e.g. 6) decoder layers, followed by a fully connected layer.

The full architecture of the decoder can be seen in the following figure. 

	
</p>



  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/full_decoder_gpt.png" height="800" width="auto">
      </div>

    </center>

<p>
Each decoder layer consists of a decoder multi-head attention layer, followed by a fully connected layer. The attention layers consist of m_heads (e.g. 8) parallel 
	attention sub layers that are later concatenated. The numbers 6 and 8 are a choice the architect makes.

	
</p>


<h1>

	Teacher Forcing
</h1>
	  
<p>
You may have already read somewhere (on-line) that the Decoder in the Transformer network predicts one word at a time and that that word is read back as an input in the 
	next iteration. Also, the network predicts the last word in the sequence of words. But you may think, aren't those last words just padding? Eh? So, what is going on 
	here? As it turns out, the mechanism of predicting one word at a time and feeding it back as an input in the next iteration is only done during the "testing"
	phase and it is not done during "training". Instead, during "training" of a decoder we use “Teacher Forcing”.
Teacher forcing is a technique in auto regressive models where you do not use the predicted outputs of the decoder to feed back as input but instead you use the real data. 
	This helps the model to learn the correct information instead of its own erroneous predictions (especially at the beginning of training).
</p>

	  <h1>
Implementing a GPT in PyTorch from Scratch
		  
	  </h1>

	  <p>
In this section,  I will implement a simple GPT using everything we have learned in this book. The code will be very object oriented for efficiency. That being said, 
	this GPT is implemented from scratch, works really well, and can be scaled. Thanks to Andrej Karpathy for helping me to better understand the PyTorch 
		  implementation of a GPT (<a href="https://karpathy.ai">Andrej Karpathy</a>).

For the sake of simplicity I will not use subwords here and instead just use the letters of the English alphabet and a few symbols. The vocabulary of a large GPT such as
	GPT-4 could be hundreds of thousands of subwords or more. This GPT reads in one text file and trains on it. 

<br/>
Here, we first input our common python libraries.  

	
</p>


<center>
<div>
<textarea rows="8" cols="40">

import torch
import numpy as np
import torch.nn as nn

from torch.nn import functional as F
  
</textarea>
</div>
  </center>


<p>

	In the following code segment we can set the parameters as we have done before.

</p>
	


<center>
<div>
<textarea rows="20" cols="70">


torch.manual_seed(256)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

block_size        = 40      ## N tokens in sequence
batch_size        = 64 
max_iters         = 6000
eval_interval     = 500     
learning_rate     = 0.0003
eval_iters        = 300
vocab_size        = 65

## every id for a given token is embedded to vector of this size
n_embd            = 512                  
n_head            = 8         ## 8 attention heads
n_layer           = 6         ## 6 eoncoder layers
dropout           = 0.2
  
</textarea>
</div>
    </center>

      
<p>

Now we proceed to read the text data to train on. 

	
</p>



<center>
<div>
<textarea rows="10" cols="80">


text = ''

input_file2 = 'AdventureHuckFinn.txt'

with open(input_file2, 'r', encoding='utf-8') as f:
    text = f.read()
  
</textarea>
  
</div>
    </center>

<p>
After reading the text file, we can look at the information about it with the following code. 

	
</p>




<center>
<div>
<textarea rows="8" cols="80">

print("length of data in letter or characters")
len(text)

list(set(text))
  
</textarea>
  
</div>
 </center>



  <p>
With the previous code we can look at the length of the text and type of characters. The length of data in letters or characters is 2,365,132, for instance. 
	  The characters can be seen in the next code listing. 


	  
  </p>





<center>
<div>
<textarea rows="10" cols="130">


['u', 'v', 'W', "'", '$', 'I', 'Q', 'L', ',', 'Y', 'w', 'D', 'e', 'P', 'h', 'z', 'F', 'n', 'l', 'T', '-', 'q',
 '&', 'p', '3', 'r', 'j', 'X', '!', 's', 'A', 'H', '\n', 'O', '.', ':', 'S', 'K', 'C', 'N', 'E', 'Z', ' ', 'd', 
 'y', 'x', 'c', 'f', ';', '?', 'B', 'g', 'o', 'G', 'V', 'R', 't', 'i', 'm', 'M', 'k', 'b', 'a', 'U', 'J']

 
</textarea>
  
</div>
    </center>


<p>
With the following code we can calculate the size of the vocabulary which is 65 and can print the tokens as a string. 

		
</p>


  
<center>
<div>
<textarea rows="15" cols="100">

the_chars  = sorted(     list(set(text))     )

vocab_size = len( the_chars )      ## 65

print(  len(the_chars)  )

print(  ''.join(the_chars)  )

## The printed oputput
## !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz

 
  
</textarea>
</div>
    </center>

<p>
The tokens need to be converted into IDs. We can use a dictionary and reverse dictionary for this like so. This was previously shown in the word2vec code description. 
	These are called the tokenizer. 
	
</p>


 
<center>
<div>
<textarea rows="5" cols="60">

   stoi = { ch:i for i, ch in enumerate(the_chars) }
   itos = { i:ch for i, ch in enumerate(the_chars) }
  
</textarea>
  
</div>
</center>
  

<p>
We can now print the dictionary (string to int ) and reverse dictionary (int to string). 	
</p>



<center>
<div>
<textarea rows="5" cols="60">

print( stoi )
print( itos )
  
</textarea>
  
</div>
</center>

<p>
The string to int dictionary will give us	
</p>



<center>
<div>
<textarea rows="30" cols="85">


{'\n': 0,
 ' ': 1,
 '!': 2,
 '$': 3,
 '&': 4,
 "'": 5,
 ',': 6,
 '-': 7,
 '.': 8,
 '3': 9,
 ':': 10,
 ';': 11,
 '?': 12,
 'A': 13,
 'B': 14,
 'C': 15,
 'D': 16,
 'E': 17,
 ...
 }

</textarea>
  
</div>
    </center>
  

<p>
and the int to string dictionary will give us

	
</p>



<center>
<div>
<textarea rows="30" cols="85">


{0: '\n',
 1: ' ',
 2: '!',
 3: '$',
 4: '&',
 5: "'",
 6: ',',
 7: '-',
 8: '.',
 9: '3',
 10: ':',
 11: ';',
 12: '?',
 13: 'A',
 14: 'B',
 15: 'C',
 16: 'D',
 17: 'E',
 ...
 }

  
</textarea>
  
</div>
    </center>
  

<p>

	
Now we need to define an encoding tokenizer called "encode" so we can convert string to integer.

</p>



<center>
<div>
<textarea rows="5" cols="100">

encode = lambda s: [ stoi[c]          for c in s   ] 

encode("bahh")


</textarea>
  
</div>
    </center>
  

<p>
Encoding from the sheep language "bahh" with the tokenizer encoder gives [40, 39, 46, 46].
<br/>
We do the same for the tokenizer decode to decoder from integer to strings as follows: 

	
</p>


<center>
<div>
<textarea rows="5" cols="100">

decode = lambda l: ''.join(   itos[i] for i in l   )    

decode([40, 39, 46, 46])


</textarea>
  
</div>
    </center>



<p>
Using the function decode([40, 39, 46, 46]) gives us our sheep tokens back which are  'bahh'.

Now we need to encode the text from our book and convert it to a Torch tensor. The code for that is as follows: 

	
</p>




   <center>
<div>
<textarea rows="10" cols="100">


data = torch.tensor(   encode(text), dtype=torch.long   )

print( data )

  
</textarea>
  
</div>
    </center>
  
<p>

Printing the encoded data in the Torch tensor gives us:  
<br/>
<br/>
tensor([18, 47, 56,  ..., 45,  8,  0])
<br/>
<br/>

We now proceed to split the data into train and text. We do that next by slicing the data torch tensor with $ n $.

	
</p>



<center>
<div>
<textarea rows="10" cols="100">

n          = int(   0.9*len(data)   )

train_data = data[:n]
val_data   = data[n:]

  
</textarea>
  
</div>
    </center>

  
<p>
The next step is to create a function to read the data so we can train the GPT. We will use a function to get the data in batches. The code can be seen in the
	  next code listing.


	
</p>



<center>
<div>
<textarea rows="20" cols="100">

def get_batch(split):
    if split == "train":
        data = train_data
    else:
        data = val_data
        
    ix = torch.randint(   len(data) - block_size, (batch_size,)   )
    
    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    ) 
    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )
    
    x, y = x.to(device), y.to(device)

    return x, y

  
</textarea>
</div>
    </center>

  <p>

To better understand the previous function, I will create a simple example with smaller values for the batch size and the M\_tokens parameter. 
	  This will help to illustrate what is going on on this function. 
<br/>
A GPT is a very deep neural network. To train it you need inputs ( "x" ) and outputs ( "y" ).  Inputs and outputs are matrices of the
	  same size [batch_size, N_tokens]. They are basically several sentences as rows (batch_size) with N_tokens (i.e. 40) as columns for each sentence.  
<br/>
The same sentence is selected for "x" and "y" . They are the same sentence but "y" is shifted by one from "x".
<br/>
For our example, we can slice batches of 4 with a sentence sequence length of 16. The torch.randint function helps us to select random starting points for the 4 sentences
	  from the text. Printing the variable "ix" from the code below gives us the following 4 starting points in the text. 
<br/>
tensor([   213173, 989153, 193174, 874116   ])

	  
  </p>




    <center>
<div>
<textarea rows="15" cols="100">


temp_batch_size = 4
temp_block_size = 16

## select random starting points for the 4 sentences
ix = torch.randint(   
            len(data) - block_size, 
            (temp_batch_size,)   
)

print( ix )

  
</textarea>
  
</div>
</center>




<p>
Given the four index position (13173, 989153, 193174, 874116), we can see what Tokenizer IDs are stored there with the following code listing. The "for" loop gives us: 
<br/>
tensor(59), tensor(43), tensor(58), tensor(17)



	
</p>








    <center>
<div>
<textarea rows="5" cols="100">


for index_temp in ix:
    print(  data[index_temp]  )



</textarea>
  
</div>
    </center>



<p>

Now with these 4 index positions we can proceed to slice out the four sentences of size 16 from the torch data tensor. Remember that we hold IDs for the tokens and not 
	the actual letter in this tensor. This gives us 4 pairs of (x, y). Notice that "y" is shfted by one from "x". 

  
	
</p>




<center>
<div>
<textarea rows="15" cols="100">

x  = torch.stack(    
    [ data[   i : i+  temp_block_size ]   for i in ix ] 
    
) 

y  = torch.stack(    
    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]    
)

print(x)
print(y)
  

  
</textarea>
  
</div>
    </center>
  


<p>

Printing "x"and "y" gives us our "x" batch of size [4, 16] and our shifted "y" batch of size [4, 16] as can be seen below.
	
</p>





  <center>
<div>
<textarea rows="20" cols="100">


x = 
tensor([
[59, 58,  1, 15, 50, 39, 56, 43, 52, 41, 43, 12,  1, 39, 52, 42],
[43, 56,  1, 24, 59, 41, 43, 52, 58, 47, 53,  8,  0,  0, 24, 33],
[58, 46, 53, 59, 45, 46, 58, 57,  6,  1, 39,  1, 50, 43, 45, 47],
[17, 37, 10,  0, 32, 56, 59, 50, 63,  6,  1, 57, 47, 56,  6,  1]])

y = 
tensor([
[58,  1, 15, 50, 39, 56, 43, 52, 41, 43, 12,  1, 39, 52, 42,  1],
[56,  1, 24, 59, 41, 43, 52, 58, 47, 53,  8,  0,  0, 24, 33, 15],
[46, 53, 59, 45, 46, 58, 57,  6,  1, 39,  1, 50, 43, 45, 47, 53],
[37, 10,  0, 32, 56, 59, 50, 63,  6,  1, 57, 47, 56,  6,  1, 47]])


  
</textarea>
  
</div>
    </center>
  





<p>


And that is how you get and process the data to train a GPT. This is sometimes called data wrangling. More detail about data wrangling is provided later in the chapter.

Now we proceed to define the loss function. In this function we evaluate the model by predicting and comparing the predictions to the real values. The difference is the 
	loss as can be seen below. 


	
</p>







  <center>
<div>
<textarea rows="20" cols="100">


@torch.no_grad()    ## for efficient processing
def estimate_loss():
    out = {}
    model.eval()   ## set to no training
    for split in ['train', 'val']:
        losses = torch.zeros(eval_iters)
        for k in range(eval_iters):
            X, Y = get_batch(split)
            logits, loss = model(X, Y)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()  ## back to training
    return out


  
</textarea>
  
</div>
    </center>
  


<p>




I will now proceed to describe the architecture of the decoder (GPT). 


	
</p>




<h1>
Architecture of the GPT or Decoder
	
</h1>
	  
<p>
As can be seen in the following figure, the decoder starts with inputs that go in sequentially into N (e.g. 6) decoder layers, and then a feed forward layer to predict 
	the logit for the given token in the vocabulary. Each decoder layer has the exact same architecture and consists of multi-head attention layers, feed forward layers, 
	and performance improvement steps such as batch normalizations, residuals, dropouts, etc. Remember that the encoder is not used for the GPT.


</p>


  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/full_decoder_gpt.png" height="700" width="auto">
      </div>

    </center>
	  

<p>

In the following code segment we can see the class to instantiate the whole decoder with all 6 decoder layers and the last feed forward layer. 

	
</p>


  <center>
<div>
<textarea rows="30" cols="130">


class GPTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]
        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]
        
        self.blocks = nn.Sequential(
                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]
        )
        
        self.ln_f    = nn.LayerNorm(  n_embd    )        
        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer
        
    def forward(self, idx, targets=None):
        B, T = idx.shape     ## (Batch, 40)
        ## ids and targets are both (B, T) tensors of integers
        
        tok_emb = self.token_embedding_table(idx)      
        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  
        
        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]

        ## This is the architecture
        x = self.blocks(  x  )   ## (B, T, E)        
        x = self.ln_f(    x  )   ## (B, T, E)   ## norm
        logits = self.lm_ffw_head(x)         ## [B, 40, 65] 
        
        if targets is None:
            loss = None
        else:
            B, T, E  = logits.shape
            logits  = logits.view( B*T, E)
            targets = targets.view(B*T)
            loss    = F.cross_entropy(logits, targets)
        return logits, loss
        
    def generate(self, idx, max_new_tokens):    ## idx is (B, T)
        for _ in range(max_new_tokens):
            ## crop idx to the last block_size tokens
            idx_cond = idx[:, -block_size:]
            logits, loss = self(idx_cond)    ## ## get preds
            logits = logits[:, -1, :]    ## focus on last one (B, E)
            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs
            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected
            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence
        return idx
            

  

  
</textarea>
  
</div>
    </center>
  

<p>
The GPTmodel class consists of 3 functions. They are init, forward, and generate. We initialize the embedding and positional encoding object in init. 

The following code is what instantiates the 6 decoder layers in sequence where the outputs from one decoder layer become the inputs of another decoder layer. 



	
</p>



  <center>
<div>
<textarea rows="6" cols="100">

self.blocks = nn.Sequential(
                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]
        )


</textarea>
  
</div>
    </center>


  


<p>

The final 2 lines of code in the init function define a normalization and the feed forward layer to predict the logits (i.e. the tokens).
<br/>
The second function is the forward funtion which is where we actually define the architecture from inputs to outputs through the entire deep neural network of the decoder.
<br/>
First we take "idx" (the data as ids) an pass it through the embedding layer. This gives us "tok_emb". Remember that the token embedding are learned by 
	Transformers during the training. After that we create the positional encoding table. The encoded "tok_emb" does not go through this object. 
	Instead "pos_emb" is added to "tok_emb". Sequence was established when "pos_emb" was instantiated. Adding them gives us "x" which
	goes into  the main architecture as can be seen below


	
</p>






<center>
<div>
<textarea rows="7" cols="100">


x      = self.blocks(  x  )      ## (B, T, E)        
x      = self.ln_f(    x  )      ## (B, T, E)   norm
logits = self.lm_ffw_head(x)     ## [B, 40, 65] 


</textarea>
  
</div>
    </center>



<p>
Finally, the generate function invokes the model defined through forward to generate text auto-regressively. 
<br/>
The GPTmodel class used a Block class to define the the decoder layers. We can now define that class. Block needs "n_embd" which is the embedding
	dimension (e.g. 512), and "n_head" which is the number of Attention heads we will use (e.g. 8). We need to 
	calculate the "head_size" by dividing "n_embd" by "n_head". For our example this should be

</p>
	<center>
<p>

 64 = 512 / 8 
		
	</p>
	</center>
	
<p>

Here it might help to look at a diagram of the decoder layer.


	
</p>
	


 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/Decoder_Layer_gpt.png" height="700" width="auto">
      </div>

    </center>


<p>

As can be seen we need a Multi-Head Attention layer followed by a FeedForward layer. Two normalizations (ln1, ln2) can also be performed. 
	
</p>



  
<center>
<div>
<textarea rows="20" cols="100">


class Block(nn.Module):
    
    def __init__(self, n_embd, n_head):     ## (512, 8)
        super().__init__()
        head_size = n_embd // n_head        ## 64
        self.sa   = MultiHeadAttention(n_head, head_size)
        self.ffwd = FeedForward( n_embd)    ## 512
        self.ln1  = nn.LayerNorm(n_embd)
        self.ln2  = nn.LayerNorm(n_embd)
        
    def forward(self, x):
        x = x + self.sa(     self.ln1(x)      )
        x = x + self.ffwd(   self.ln2(x)      )
        return x

  
</textarea>
  
</div>
    </center>
  




<p>

The Block class uses 2 more classes which are Multi-Head Attention and FeedForward. We can now proceed to define these. 
<br/>
We can first define the Multi-Head class as follows


	
</p>




 


<center>
<div>
<textarea rows="16" cols="100">


class MultiHeadAttention(nn.Module):

    def __init__(self, num_heads, head_size):    ## (8, 64)
        super().__init__()
        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )
        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )
        out = self.proj(  out   )
        out = self.dropout(   out   )
        return out

  
</textarea>
  
</div>
    </center>




<p>


The Masked multi-head attention layer is done N\_head times (e.g. 8) in parallel and the results are concatenated. This concatenated result is added to the original 
	after mapping it through one more layer and a Residual can also be used.

The 2 key aspects are the instantiation of 8 heads which are parallel and independent of each other using "nn.ModuleList"as can be seen in the next code listing



	
</p>






<center>
<div>
<textarea rows="6" cols="100">


self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )


</textarea>
  
</div>
</center>
  


<p>

and the concatenation of the 8 head Heads of size 64 to create a new tensor of size 512 ( 64 * 8 = 512).


	
</p>




 


   <center>
<div>
<textarea rows="4" cols="100">

out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )

</textarea>
  
</div>
    </center>


<p>

	
The FeedForward class is very straight forward  as can be seen below. It is a simple linear layer followed by a non-linearity. 



</p>




<center>
<div>
<textarea rows="20" cols="100">


class FeedForward(nn.Module):

   def __init__(self, n_embd):         ## 512
        
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(n_embd, 4 * n_embd),      ## [512, 4*512]
            nn.ReLU(),
            nn.Linear(4 * n_embd, n_embd),      ## [4*512, 512]
            nn.Dropout(dropout),
        )
        
    def forward(self, x):
        return self.net(x)

  
</textarea>
  
</div>
    </center>




<p>

Finally, the Multi-Head Attention class use the Head class where the Attention mechanism is defined. The  next code segment is probably the most important in
	terms of the power of Transformers. It defines the Attention layer. Here we define the Attention Head class. 

 

	
</p>




    <center>
<div>
<textarea rows="30" cols="100">


class Head(nn.Module):

    def __init__(self, head_size):
        super().__init__()
        
        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]

        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]
        
        self.register_buffer(
                  'tril', 
                  tril_def
               )
        
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        
        B, T, E = x.shape   ## [batch_size, 40, 512]
        
        k = self.key(   x )            ## k = (B, T, 64)
        q = self.query( x )            ## q = (B, T, 64)

        E2 = 64     ## I think this is 64 and not 512
        ## (B, T, E) @ (B, E, T)  -> (B, T, T)
        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        
        
        wei = wei.masked_fill(
                      self.tril[:T, :T] == 0, 
                      float('-inf')
        )   
        
        ## (B, T, T)
        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
        wei = self.dropout(   wei   )
        
        ## perform weighted aggregation of values
        
        v   = self.value(  x  )   ## x = (B, 40, E)
        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)
        
        return out
  

  
</textarea>
  
</div>
    </center>
  

<p>

The sentence and corresponding padding mask are the only inputs to this Attention layer. The output of this Attention mechanism is then passed to a 
	fully connected layer. The mask must not be part of the computational graph since it is only used for masking. We use the following command to keep it 
	out of the computational graph. 


</p>






   <center>
<div>
<textarea rows="4" cols="100">

self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))

</textarea>
  
</div>
    </center>


<p>


The Attention mechanism uses K, Q, and V to compute the Attention scores. The values are computed from the original "x" input. The intuition is that the sentence 
	is compared with itself and that is why the comparison or scores matrix will result in size [N_tokens, N_tokens] (e.g. [40, 40]). This is accomplished with 
	the following code:

	
</p>




<center>
<div>
<textarea rows="7" cols="100">


self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]


</textarea>
  
</div>
    </center>
  


<p>


The input "x" is of size [N, 40, 512] and the "look_ahead_mask" is of size [N_batches, 40, 40].


Remember that using "nn.Linear" is equivalent to the following:


	
</p>





     <center>
<div>
<textarea rows="16" cols="100">


Wq = torch.tensor( [batch_size, 512, 64] )
bq = torch.tensor( [batch_size,  40, 64] )  
Q  = torch.matmul( x, Wq ) + bq    # Nx40x64
    
Wk = torch.tensor( [batch_size, 512, 64] )  
bk = torch.tensor( [batch_size,  40, 64] )  
K = torch.matmul(x, Wk) + bk    # Nx40x64
    
Wv = torch.tensor( xavier_init( [batch_size, 512, 64] )  )
bv = torch.tensor( torch.random_normal( [batch_size, 40, 64] )  )
V = torch.matmul(x, Wv) + bv    # Nx40x64


</textarea>
  
</div>
    </center>



<p>

Once Q, K, and V are defined, the next step is to multiply Q times K. You can think of this as calculating a score of the importance of "token_i" in
	"x" to all other words in "x".


	
</p>

 


  
     <center>
<div>
<textarea rows="17" cols="100">


## (B, T, 64) @ (B, E, 64)  -> (B, T, T)

wei = q @ k.transpose(-2, -1) * E ** -0.5        
        
wei = wei.masked_fill(
        self.tril[:T, :T] == 0, 
        float('-inf')
)   
        
## (B, T, T)
wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
wei = self.dropout(   wei   )


</textarea>
  
</div>
    </center>

  

<p>

The variable "wei" is computed by a nn.matmul between Q and the transpose of K like so
<br/>
<br/>
    wei = nn.matmul( Q, K, transpose_b=True) 
<br/>
<br/>
	
This nn.matmul results in a matrix of size  [N, 40, 40]. We then divide "wei" by 
<br/>
<br/>
    sqrt(  Embd_size  )        
<br/>
<br/>
	
where Embd_size is equal to 64 (i.e. E ** -0.5). At this point "wei" continues to be of size [N, 40, 40].

The following code segment adds "wei" to the Mask. 


	
</p>






      <center>
<div>
<textarea rows="8" cols="80">

wei = wei.masked_fill(
        self.tril[:T, :T] == 0, 
        float('-inf')
)
  
</textarea>
  
</div>
</center>


<p>


The "look_ahead_mask" is of size [N, 40, 40]. This should be an addition of [N, 40, 40] + [N, 40, 40]. Notice that the wei.masked_fill function
	makes use on an infinity parameter. A simplified view of this operation is as follows:

<br/>
    wei = wei + (look_ahead_mask * -1e9)
<br/>


The final part of the forward function in the Head class (next code segment) finishes the Attention computation. The softmax is used to normalize on 
	the last axis so that the scores add up to 1 (axis -1 is for last dimension in the tensor). 


	
</p> 
        



  

<center>
<div>
<textarea rows="20" cols="100">


class Head(nn.Module):

    ...

    def forward(self, x):
        
        ...
        
        ## (B, T, T)
        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
        wei = self.dropout(   wei   )
        
        ## perform weighted aggregation 
        
        v   = self.value(  x  )   ## (B, T, E)
        out = wei @ v             ## (B, 40, 40) @ (B, 40, 64) -> (B, 40, 64)
        
        return out

  
</textarea>
  
</div>
    </center>



<p>
   

Finally, the following operation is performed which result in a tensor of size [N, 40, 64]. Remember that 8 of these Head output tensors will be concatenated to return 
	to the original size of [N, 40, 512] (64 * 8 = 512). 

<br/>
out = nn.matmul(wei, V)    
<br/>
    
The operation looks like the following [N, 40, 40] * [N, 40, 64].


So, in summary you calculate the keys, queries, and values which are tensors that map the input \textbf{x} of size [N, 40, 512] to size [N, 40, 64]. We then
	calculate the scores matrix (wei) which is the Attention mechanism. This is a dot product. We matrix multiply Q with the transpose of K. This results 
	in a matrix that is size [N, 40, 40].

After calculating the score matrix (wei), we need to mask the values so that we don’t cheat by looking ahead. We apply the look ahead and padding masks. 
	The mask for look ahead attention happens before the softmax calculation. Notice that the masking is done to the dot_product scores matrix (wei) only. 
	The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is 
	applied immediately before a softmax. The goal is to zero out padded cells, and large negative inputs to softmax are near zero in the output.

<br/>
	<br/>
For example, the  softmax ( torch.nn.softmax(a7) ) for “a” defined as follows:
<br/>
	<br/>
a7 = torch.constant([0.6, 0.2, 0.3, 0.4, 0, 0, 0, 0, 0, 0]) 
 <br/>
	<br/>
gives the following

	
</p>
        

  
<center>
<div>
<textarea rows="8" cols="100">


<torch.Tensor: shape=(10,), dtype=float32, numpy=
array([0.15330984, 0.10276665, 0.11357471, 0.12551947, 0.08413821,
0.08413821, 0.08413821, 0.08413821, 0.08413821, 0.08413821], dtype=float32)>


</textarea>
</div>
</center>



<p>

now, if some of the values are negative infinities
<br/>
	<br/>
b7 = torch.constant([0.6, 0.2, 0.3, 0.4, -1e9, -1e9, -1e9, -1e9, -1e9, -1e9])
<br/>
	<br/>
then the softmax operation on b7 (torch.nn.softmax(b7)) should give us
<br/>

	
</p>



 


      <center>
<div>
<textarea rows="6" cols="100">

<torch.Tensor: shape=(10,), dtype=float32, numpy=
array([ 0.3096101 , 0.20753784, 0.22936477, 0.25348732, 0. ,0. , 0. , 0. , 0. , 0. ], dtype=float32)>

</textarea>
  
</div>
    </center>




  




</div>  <!-- for the fixed nav bar -->

    
  </body>
</html>
