{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install imageio\n",
    "## !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CNNs for CIFAR10\n",
    "\n",
    "* https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/chapter6_CNNs/index.html\n",
    "\n",
    "## Load and save torch model checkpoints\n",
    "\n",
    "* https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "## Data\n",
    "\n",
    "* Data: https://github.com/YoongiKim/CIFAR-10-images/tree/master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## !pip install torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.current_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assign device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch_device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch_device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch_device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CIFAR10 DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_train = '/home/maquina1/Desktop/CIFAR-10-images-master/train/'\n",
    "\n",
    "raw_data_test  = '/home/maquina1/Desktop/CIFAR-10-images-master/test/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PATH to checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH = \"/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = []\n",
    "labels_train  = []\n",
    "targets_train = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py37_new_GANs_Torch/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for folder in os.listdir( raw_data_train ):\n",
    "    ## print(folder)\n",
    "    for image in os.listdir( os.path.join(raw_data_train, folder) ):\n",
    "        if folder not in labels_train:\n",
    "            labels_train.append( folder )\n",
    "        targets_train.append(  labels_train.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_train, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_train.append(img)\n",
    "        \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len( targets_train )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_train[3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_train    = torch.stack( dataset_train )\n",
    "targets_train = torch.Tensor(  targets_train  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_train, targets_train, labels_train), \"InClass_CIFAR10_data\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 3, 32, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_train[4].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_train[24000:25000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2627, 0.2667, 0.2667,  ..., 0.3098, 0.3176, 0.3176],\n",
       "         [0.2863, 0.2863, 0.2902,  ..., 0.3373, 0.3412, 0.3412],\n",
       "         [0.3137, 0.3176, 0.3176,  ..., 0.3647, 0.3725, 0.3725],\n",
       "         ...,\n",
       "         [0.2941, 0.2784, 0.2824,  ..., 0.2824, 0.2824, 0.2784],\n",
       "         [0.2471, 0.2627, 0.2941,  ..., 0.2706, 0.2627, 0.2588],\n",
       "         [0.2863, 0.2863, 0.2824,  ..., 0.2745, 0.2667, 0.2588]],\n",
       "\n",
       "        [[0.5686, 0.5725, 0.5725,  ..., 0.6118, 0.6078, 0.6078],\n",
       "         [0.5843, 0.5843, 0.5882,  ..., 0.6314, 0.6235, 0.6275],\n",
       "         [0.5961, 0.6000, 0.5961,  ..., 0.6510, 0.6471, 0.6471],\n",
       "         ...,\n",
       "         [0.3490, 0.3451, 0.3373,  ..., 0.3529, 0.3529, 0.3490],\n",
       "         [0.3098, 0.3333, 0.3569,  ..., 0.3490, 0.3412, 0.3373],\n",
       "         [0.3569, 0.3569, 0.3529,  ..., 0.3529, 0.3451, 0.3373]],\n",
       "\n",
       "        [[0.8196, 0.8235, 0.8235,  ..., 0.8863, 0.8863, 0.8863],\n",
       "         [0.8275, 0.8275, 0.8314,  ..., 0.8980, 0.9059, 0.8980],\n",
       "         [0.8275, 0.8314, 0.8392,  ..., 0.9176, 0.9216, 0.9176],\n",
       "         ...,\n",
       "         [0.4000, 0.3843, 0.3804,  ..., 0.3922, 0.4000, 0.3961],\n",
       "         [0.3686, 0.3804, 0.4078,  ..., 0.3843, 0.3843, 0.3804],\n",
       "         [0.4118, 0.4118, 0.4000,  ..., 0.3882, 0.3882, 0.3804]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img_tr = data_train[46000]\n",
    "img_tr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = T.ToPILImage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = transform(  img_tr  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Class balance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train_np = targets_train.numpy() \n",
    "y_train_np.shape\n",
    "\n",
    "the_set = np.unique(  y_train_np  )\n",
    "the_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_train.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = []\n",
    "labels_test = []\n",
    "targets_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maquina1/anaconda3/envs/py37_new_GANs_Torch/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for folder in os.listdir( raw_data_test ):\n",
    "    ## print(folder)\n",
    "    for image in os.listdir( os.path.join(raw_data_test, folder) ):\n",
    "        if folder not in labels_test:\n",
    "            labels_test.append( folder )\n",
    "        targets_test.append(  labels_test.index(folder)  )\n",
    "        img_arr = imageio.imread(  os.path.join(raw_data_test, folder, image), pilmode=\"RGB\"  )\n",
    "        \n",
    "        img = torch.from_numpy( img_arr ).permute( 2, 0, 1 ).float()\n",
    "        \n",
    "        img /= 255\n",
    "        dataset_test.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test   = torch.stack( dataset_test )\n",
    "targets_test = torch.Tensor(  targets_test  ).type(   torch.LongTensor   )\n",
    "\n",
    "torch.save(   (data_test, targets_test, labels_test), \"InClass_CIFAR10_data_test\"     )\n",
    "\n",
    "## data1, targets1, labels1 = torch.load(\"InClass_CIFAR10_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 3, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "targets_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "_ = plt.hist( targets_test.numpy() , bins=\"auto\" )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = data_train  \n",
    "y_train = targets_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_test = data_test  \n",
    "y_test = targets_test \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Change to float 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.numpy()\n",
    "X_test  = X_test.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype(  np.float32  )\n",
    "X_test  = X_test.astype(   np.float32  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.from_numpy(X_train )\n",
    "X_test = torch.from_numpy( X_test  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_norm_mean = (0.5, 0.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_norm_std = (0.5, 0.5, 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "other_normalization = transforms.Compose([\n",
    "                            ## transforms.ToTensor(),\n",
    "                            transforms.Normalize( img_norm_mean, img_norm_std )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocess = transforms.Compose([\n",
    "                 transforms.Resize(256),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = other_normalization( X_train )  \n",
    "\n",
    "X_test  = other_normalization( X_test ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Print shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n",
    "type(y_train[30000].item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_train[30000].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2392, -0.2314, -0.2314,  ..., -0.1216, -0.1294, -0.1451],\n",
       "         [-0.2706, -0.2000, -0.1451,  ..., -0.1059, -0.1059, -0.1216],\n",
       "         [-0.2549, -0.1608, -0.0902,  ..., -0.0667, -0.0902, -0.1216],\n",
       "         ...,\n",
       "         [ 0.0039,  0.2784,  0.0431,  ..., -0.2706, -0.3647, -0.2157],\n",
       "         [ 0.0510,  0.0824,  0.1451,  ..., -0.3333, -0.4667, -0.3569],\n",
       "         [ 0.1843,  0.0980, -0.2784,  ..., -0.5059, -0.3804, -0.4039]],\n",
       "\n",
       "        [[-0.1608, -0.1529, -0.1529,  ..., -0.0588, -0.0902, -0.0980],\n",
       "         [-0.1922, -0.1137, -0.0667,  ..., -0.0431, -0.0667, -0.0745],\n",
       "         [-0.1843, -0.0902, -0.0196,  ...,  0.0118, -0.0275, -0.0588],\n",
       "         ...,\n",
       "         [-0.0039,  0.2706,  0.0353,  ..., -0.1373, -0.2392, -0.0902],\n",
       "         [ 0.0196,  0.0510,  0.1373,  ..., -0.2078, -0.3412, -0.2157],\n",
       "         [ 0.1529,  0.0667, -0.2863,  ..., -0.3804, -0.2392, -0.2627]],\n",
       "\n",
       "        [[-0.0902, -0.0824, -0.0824,  ..., -0.0431, -0.0667, -0.0980],\n",
       "         [-0.1216, -0.0667,  0.0039,  ..., -0.0196, -0.0431, -0.0745],\n",
       "         [-0.1294, -0.0510,  0.0353,  ...,  0.0275, -0.0039, -0.0431],\n",
       "         ...,\n",
       "         [-0.0196,  0.2549,  0.0196,  ..., -0.0588, -0.1373,  0.0118],\n",
       "         [ 0.0275,  0.0588,  0.1216,  ..., -0.1059, -0.2235, -0.1059],\n",
       "         [ 0.1608,  0.0745, -0.3020,  ..., -0.2784, -0.1294, -0.1529]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " X_train[78]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_train_list = [  ( X_train[i],  y_train[i].item() )  for i in range( X_train.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " CIFAR_test_list = [  ( X_test[i],  y_test[i].item() )  for i in range( X_test.shape[0]   )  ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64  ## 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl = torch.utils.data.DataLoader( CIFAR_train_list, batch_size=batch_size, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dl = torch.utils.data.DataLoader( CIFAR_test_list, batch_size=10000, shuffle=True  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Residual Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ResNet\n",
    "class MyResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(MyResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "32*32*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DL_3h_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 , 200)\n",
    "        self.act1    = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(200 , 100)\n",
    "        self.act2   = nn.ReLU()\n",
    "        \n",
    "        self.linear3 = nn.Linear( 100 ,50)\n",
    "        self.act3    = nn.ReLU()\n",
    "        \n",
    "        self.linear4 = nn.Linear(50 , 10)\n",
    "        self.act4    = nn.Softmax(dim=1)\n",
    "        \n",
    "        ## self.norm    = nn.LayerNorm()\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.linear2(x)\n",
    "        x            = self.act2(x)\n",
    "        x            = self.linear3(x)\n",
    "        x            = self.act3(x)\n",
    "      \n",
    "        x            = self.linear4(x)\n",
    "        y_pred       = self.act4(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear( 128 , 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(512, 10),\n",
    "            nn.Softmax(dim=1)        ## nn.LogSoftmax()\n",
    "            \n",
    "        \n",
    "        )\n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.model( x  )\n",
    "       \n",
    "        \n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        # self.shape = shape,\n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "class CNN_net_DH(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            ## nn.Conv2d(32, 32, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, padding=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            View((-1, 256)),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            \n",
    "            nn.Linear(64, 10) # Output 10 classes\n",
    "            ## nn.Softmax(dim=1)        ## nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "            \n",
    "     \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y_pred = self.model( x  )\n",
    "       \n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP_net(nn.Module):\n",
    "    ## init the class\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear( 32*32*3 ,20)\n",
    "        self.act1    = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(20 , 10)\n",
    "        self.act2    = nn.Softmax(dim=1)\n",
    "        \n",
    "        self.norm    = nn.LayerNorm()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    ## perform inference\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x            = self.linear1(x)\n",
    "        x            = self.act1(x)\n",
    "        x            = self.norm(x)\n",
    "        x            = self.dropout(x)\n",
    "        \n",
    "        x            = self.linear2(x)\n",
    "        y_pred       = self.act2(x)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_loop( N_Epochs, model, loss_fn, opt ):\n",
    "    for epoch in range(N_Epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            \n",
    "            ## xb = xb.view(  (16, -1 ) )\n",
    "            \n",
    "            xb = xb.to( torch_device )\n",
    "            yb = yb.to( torch_device )\n",
    "            \n",
    "            y_pred = model(xb)\n",
    "            \n",
    "            loss = loss_fn(y_pred, yb)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(epoch, \"loss=\", loss)\n",
    "            new_PATH = PATH + str(epoch)\n",
    "            print( new_PATH )\n",
    "            torch.save(model, new_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## torch.save(model, PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Core functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_Epochs      = 500\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## model = MLP_net()\n",
    "## model =  DL_3h_net()\n",
    "\n",
    "## model = CNN_net()\n",
    "\n",
    "## model = CNN_net_DH()\n",
    "## model.to( torch_device )\n",
    "\n",
    "model = MyResNet(ResidualBlock, [2, 2, 2]).to( torch_device )\n",
    "\n",
    "\n",
    "opt = torch.optim.SGD(  model.parameters(), lr=learning_rate,  momentum=0.9, weight_decay=0.001 )\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss= tensor(1.1995, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR100\n",
      "5 loss= tensor(1.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR105\n",
      "10 loss= tensor(0.8869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1010\n",
      "15 loss= tensor(0.7998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1015\n",
      "20 loss= tensor(0.4471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1020\n",
      "25 loss= tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1025\n",
      "30 loss= tensor(0.2160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1030\n",
      "35 loss= tensor(0.0592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1035\n",
      "40 loss= tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1040\n",
      "45 loss= tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1045\n",
      "50 loss= tensor(0.1967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1050\n",
      "55 loss= tensor(0.2521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1055\n",
      "60 loss= tensor(0.1717, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1060\n",
      "65 loss= tensor(0.2199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1065\n",
      "70 loss= tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1070\n",
      "75 loss= tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1075\n",
      "80 loss= tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1080\n",
      "85 loss= tensor(0.1642, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1085\n",
      "90 loss= tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1090\n",
      "95 loss= tensor(0.0359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR1095\n",
      "100 loss= tensor(0.0194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10100\n",
      "105 loss= tensor(0.3734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10105\n",
      "110 loss= tensor(0.0994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10110\n",
      "115 loss= tensor(0.0847, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10115\n",
      "120 loss= tensor(0.0441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10120\n",
      "125 loss= tensor(0.0356, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10125\n",
      "130 loss= tensor(0.0570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10130\n",
      "135 loss= tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10135\n",
      "140 loss= tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10140\n",
      "145 loss= tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10145\n",
      "150 loss= tensor(0.0360, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10150\n",
      "155 loss= tensor(0.0292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10155\n",
      "160 loss= tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10160\n",
      "165 loss= tensor(0.0290, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10165\n",
      "170 loss= tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10170\n",
      "175 loss= tensor(0.0884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10175\n",
      "180 loss= tensor(0.2435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10180\n",
      "185 loss= tensor(0.1333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10185\n",
      "190 loss= tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10190\n",
      "195 loss= tensor(0.1023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10195\n",
      "200 loss= tensor(0.4992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10200\n",
      "205 loss= tensor(0.1034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10205\n",
      "210 loss= tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10210\n",
      "215 loss= tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10215\n",
      "220 loss= tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10220\n",
      "225 loss= tensor(0.3122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10225\n",
      "230 loss= tensor(0.2150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10230\n",
      "235 loss= tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10235\n",
      "240 loss= tensor(0.0402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10240\n",
      "245 loss= tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10245\n",
      "250 loss= tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10250\n",
      "255 loss= tensor(0.0854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10255\n",
      "260 loss= tensor(0.1668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10260\n",
      "265 loss= tensor(0.5674, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10265\n",
      "270 loss= tensor(0.0094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10270\n",
      "275 loss= tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10275\n",
      "280 loss= tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10280\n",
      "285 loss= tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10285\n",
      "290 loss= tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10290\n",
      "295 loss= tensor(0.2320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10295\n",
      "300 loss= tensor(0.0793, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10300\n",
      "305 loss= tensor(0.1422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10305\n",
      "310 loss= tensor(0.1580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10310\n",
      "315 loss= tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10315\n",
      "320 loss= tensor(0.1902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10320\n",
      "325 loss= tensor(0.0656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 loss= tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10330\n",
      "335 loss= tensor(0.0339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10335\n",
      "340 loss= tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10340\n",
      "345 loss= tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10345\n",
      "350 loss= tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10350\n",
      "355 loss= tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10355\n",
      "360 loss= tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10360\n",
      "365 loss= tensor(0.4390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10365\n",
      "370 loss= tensor(0.2277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10370\n",
      "375 loss= tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10375\n",
      "380 loss= tensor(0.0386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10380\n",
      "385 loss= tensor(0.0872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10385\n",
      "390 loss= tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10390\n",
      "395 loss= tensor(0.1340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10395\n",
      "400 loss= tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10400\n",
      "405 loss= tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10405\n",
      "410 loss= tensor(0.3712, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10410\n",
      "415 loss= tensor(0.5106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10415\n",
      "420 loss= tensor(0.0599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10420\n",
      "425 loss= tensor(0.0624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10425\n",
      "430 loss= tensor(0.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10430\n",
      "435 loss= tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10435\n",
      "440 loss= tensor(0.1163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10440\n",
      "445 loss= tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10445\n",
      "450 loss= tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10450\n",
      "455 loss= tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10455\n",
      "460 loss= tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10460\n",
      "465 loss= tensor(0.7154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10465\n",
      "470 loss= tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10470\n",
      "475 loss= tensor(0.1738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10475\n",
      "480 loss= tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10480\n",
      "485 loss= tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10485\n",
      "490 loss= tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10490\n",
      "495 loss= tensor(0.0521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_loop( N_Epochs, model, loss_fn, opt )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_metrics_function(y_test, y_pred):\n",
    "    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confmat)\n",
    "    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n",
    "    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Confusion Matrix:\n",
      "[[492  19  72  47 204  13  71  49  10  23]\n",
      " [ 13 831   7   7   6  26   7   5  70  28]\n",
      " [ 92   6 757  11  34  11  33  34   6  16]\n",
      " [ 26   8  12 776  78   8  28  50   4  10]\n",
      " [109   4  37  60 683   5  44  45   6   7]\n",
      " [ 10  29   6   6   5 859  15   4  28  38]\n",
      " [ 69   7  90  36  76  16 565  59   3  79]\n",
      " [ 77   5  76  83  36   9  67 624   3  20]\n",
      " [  6  79   4   1   2  25   2   3 867  11]\n",
      " [ 18  42   8  14   5  90  35  17  11 760]]\n",
      "Precision: 0.719\n",
      "Recall: 0.721\n",
      "F1-measure: 0.719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        x_real = x_real.to( torch_device )\n",
    "        \n",
    "        y_pred = model(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function( y_real, preds.cpu() )\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## From checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model class must be defined somewhere\n",
    "model2 = torch.load('/home/maquina1/Desktop/checkpoints/CNN_model_CIFAR10495')\n",
    "## model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "Confusion Matrix:\n",
      "[[560  14  67  46 146   8  66  68   4  21]\n",
      " [ 10 859   5   7   5  18   6   5  61  24]\n",
      " [ 51   1 812   9  28   6  42  34   7  10]\n",
      " [ 38  15   6 790  48   3  33  53   3  11]\n",
      " [143   4  28  58 657   2  47  45   7   9]\n",
      " [ 13  27   5   3   4 872  10   6  23  37]\n",
      " [ 64   9  64  30  42  12 642  78   1  58]\n",
      " [ 63   0  43  55  31  14  56 715   4  19]\n",
      " [  7  53   3   1   4  20   3   3 898   8]\n",
      " [ 19  30   7  16   5  62  57  16   7 781]]\n",
      "Precision: 0.757\n",
      "Recall: 0.759\n",
      "F1-measure: 0.758\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for x_real, y_real in test_dl:\n",
    "        \n",
    "        batch_size = x_real.shape[0]\n",
    "        \n",
    "        ## x_real = x_real.view(  (batch_size, -1 ) )\n",
    "        \n",
    "        x_real = x_real.to( torch_device )\n",
    "        \n",
    "        y_pred = model2(  x_real  )\n",
    "        \n",
    "        vals, indeces = torch.max( y_pred, dim=1  )\n",
    "        preds = indeces\n",
    "        print_metrics_function(y_real, preds.cpu() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rc = data_train[4].view((-1))\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rc = torch.unsqueeze(rc, dim=0)\n",
    "rc.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label = model( rc )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Figure out the dimensions of CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_batches_rc = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "model_rc = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten()\n",
    "            \n",
    "            \n",
    "        \n",
    "        )\n",
    "        \n",
    "'''\n",
    "\n",
    "\n",
    "model_rc  = nn.Sequential(\n",
    "            \n",
    "            ## conv layer 1\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 2\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            ## conv layer 3\n",
    "            nn.Conv2d(32, 32, kernel_size=5, stride=1, padding=1  ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Dropout(0.2),\n",
    "              \n",
    "            ## FeedForward\n",
    "            \n",
    "            nn.Flatten()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 128])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_tensor_test   = torch.randn(N_batches_rc, 3, 32,  32)\n",
    "\n",
    "res_actual_model = model_rc(  my_tensor_test   )\n",
    "\n",
    "res_actual_model.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
