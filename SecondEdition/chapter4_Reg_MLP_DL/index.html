<html>
<head>

  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

  <body>

<div class="navbar">
  <a href="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/index.html"> Deep Learning </a>
  <a href="https://ricardocalix.substack.com">Substack</a>
  <a href="https://www.youtube.com/channel/UCKRgi-HJDEq0a3nhlG2nQvg">YouTube</a>
  <a href="https://github.com/rcalix1/DeepLearningAlgorithms/tree/main/SecondEdition">GitHub</a>
  <a href="https://www.galacticbackwater.com/theAIhub/index.html">Recommender</a>
  <a href="https://amzn.to/3OauEG0">Books</a>
  <a href="https://www.linkedin.com/in/ricardo-calix-phd">About</a>
  <a href="https://scholar.google.com/citations?hl=en&user=TiKVs6AAAAAJ">Scholar</a>	
  <a href="">Shop</a>
  <a href="https://www.rcalix.com">Contact</a>
</div>

    

<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->

<div class="main">    <!-- for the fixed nav bar -->

<h1>Chapter 4 - Getting Started with Deep Learning </h1>

    <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/full_transformer.png" height="500" width="auto">
      </div>

    </center>






<h1>Copyright, License, FTC and Amazon Disclaimer</h1>

<p>
 Copyright &copy by Ricardo A. Calix. <br/>
 All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, without written permission of the copyright owner. <br/>
 This post/page/article includes Amazon Affiliate links to products. This site receives income if you purchase through these links. 
 This income helps support content such as this one. 
 <br/>

	

  
</p>

     <center>
      <div class="img"> 
        <a href="https://amzn.to/3vOL8NF"><img src="https://m.media-amazon.com/images/I/71Wi+z5fKzL._SL1233_.jpg" height="500" width="auto"></a>
      </div>

    </center>
    

<h1>
Deep Learning: Starting at the beginning
	
</h1>


<p>

In this chapter, I will introduce the topic of deep learning. My goal here is to help students and practitioners alike to get started with deep learning. 
	In particular, I want them to be able to get data and pre-process it for deep learning, load it on their programs, perform classification tasks, and 
	evaluate their results.  I will discuss some aspects of the theory providing as much intuition as possible. For this task, I will use Linux, Python, Sklearn,
	and the PyTorch framework. I will also discuss some aspects of using GPU based hardware by the end of the book. 
For most of my sample code, I used the conda environment. I installed the PyTorch framework following the instructions in the main PyTorch website (https://www.PyTorch.org/ ).
	

	
</p>

<h1>
Things to know about the code
	
</h1>


	<p>
As in the previous section with sklearn, I have included the libraries first. Notice, that I use as many sklearn libraries as possible and only use the PyTorch
		module when absolutely necessary. The goal, again, is to help the reader to best capture the PyTorch concepts by simplification. Once your skills 
		improve with deep learning frameworks, you will be able to more easily replace sklearn modules with alternative PyTorch modules.


		
	</p>



<center>
<div>
<textarea rows="20" cols="100">

import torch
import numpy as np
from numpy import genfromtxt

from sklearn import datasets
from sklearn.datasets import fetch_mldata
from sklearn.cross_validation import train_test_split 

import sklearn
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score, f1_score 
import pandas as pd
import matplotlib.pyplot as plt
  
</textarea>
  
</div>
</center>
  





In the previous code section, it can be seen that for our deep learning code to work, we only need a few new libraries. The most important new library is Torch. This of course is the main source of our new code. We will still rely on numpy to efficiently get the data although we can also get data with the statement sklearn.datasets import fetch\_mldata.
The next important issue in our code to do would be to set some parameters. Deep learning algorithms are iterative in the sense that they load samples in batches to avoid running out of memory. This is very important as it allows you to load millions of data samples in subsets called batches. Therefore, we can set up the parameters for batch processing. In the code below, we can see that we want to load batches of 100 samples each. For a training set of 1,000 samples, we would divide the set into 10 bins of 100 samples each and therefore run 10 batches. 
Two additional parameters in this code are the learning\_rate and the n\_epochs. The n\_epochs parameter represents the number of times that we will run our main “for” loop. This is the loop that we will run to provide data to our algorithms for training and testing. At this point, an optimization begins to occur which helps the supervised learning algorithm to learn from the samples. 
The learning\_rate value (in this case 0.01) is a very important parameter in the learning algorithm. Simply speaking, it represents the step that is taken in a gradient descent algorithm to find an optimal solution. Think of this like a giant walking over a mountainous region with many peaks and valleys. He is trying to find an optimal location; if the step is too big, the giant could go from peak to peak and skip a valley altogether. On the other hand, if the step is to small the giant may take too long to move in or out of a valley. In terms of PyTorch, the learning rate can affect convergence. 



Convergence is the term that means that the iterative algorithm is starting to tend to the optimal solution. The learning\_rate can also be assigned a function instead of just a value. 
This helps to adjust the learning rate in real time while the algorithm is running. Some researchers have suggested that this type of optimization can provide better results than just using a fixed value learning rate. 



<center>
<div>
<textarea rows="20" cols="100">

learning_rate = 0.01 
n_epochs      = 27000         #1000 
batch_size    = 100
  
</textarea>
  
</div>
</center>



Deep learning algorithms in PyTorch consist of a basic structure. Simply put, they have:



\begin{itemize}
\item Creating the dataset or DataLoaders
\item Defining the NN architectures (Inference Function)
\item Defining the loss function and optimizer
\item Training the model and adjusting the weights
\end{itemize}



In the next section I will proceed to further elaborate on this. 

The figure below presents the accuracy plot per epoch of a deep neural net as it is being trained. The x axis represents the epochs over time and the y axis represents the accuracy score. As can be seen, the accuracy is low at first but it starts to improve after a certain number of epochs when the classifier begins to learn and converge.  



    <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/accuracy_per_epoch.png" height="700" width="auto">
      </div>
    </center>

In this example on the figure, a deep net takes a few epochs to learn how to detect and classify the samples. After about 200 epochs, a deep net of say 2 hidden layers stabilizes and is able to maintain a consistent accuracy score. 

\section{Getting Started with Deep Leaning }


So what’s it all about? Again, my focus here is not to discuss deep learning from the equations point of view or talk about the derivatives. Those are all very important concepts but can be overwhelming when starting. Instead, I want to help the reader write deep learning code with PyTorch. Then, the reader will, no doubt, have many questions where the theory and fundamentals will help him or her to better understand and use the algorithms. 
The figures below present some of the challenges that must be addressed when dealing with real data. Real data such as language data from Twitter is highly noisy and un-balanced. An imbalance in the data means, for example, that 80 \% of the samples belong to 1 class and the remaining 20 \% belong to the other class. Therefore, training a classifier to, say, perform emotion classification (where data is highly imbalanced) can be a difficult task. In the figure below, a sample of Twitter data is represented. Each sample in the dataset had multiple features but was compressed into a two dimensional vector for visualization purposes. 
As can be seen, the data in the figures has a high overlap in the classes and the data is difficult to separate. A linear classifier (the line seen on the graph) can only separate a small portion of the samples and the majority are not easy to separate in this space. The graph below is available on-line in color. 



 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/log_reg_line.png" height="700" width="auto">
      </div>
    </center>


So how can we get more of the samples of one class without getting too many of the samples of the other class? Well, the answer is that we could use another type of line for the separation. For instance, instead of using a straight line we could use a curved line. This is why some algorithms are called linear and others are called non-linear. Non-linear algorithms can sometimes create better separations in the data and therefore obtain fewer errors. In the next Figure, an example of this is shown using Support Vector Machines (SVM). SVM methods can sometimes build better non-linear classifiers because of their ability to project data to higher dimensional spaces.  Deep neural networks can be used to learn non-linear models as well. This property of non-linear models can help to obtain better classification accuracy scores. This figure is available on-line in color. 





 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/svm_line_chart.png" height="700" width="auto">
      </div>
    </center>

The figure above shows an SVM classifier building a non-linear separation line (the curved line in the graph) on the data. It could be expected that a deep neural network could build even better separation boundaries and that different architectures could give different results. This takes us to the very important aspect of deep learning architecture. 
Deep learning architecture is where we define the parameters such as layers and neurons that define a deep neural network. You could think of this as the way that you construct the line that you want to build and use. We will discuss this in the next sections but it is important to know that you can define many deep learning architectures.

\section{Deep Leaning Definition}


Deep learning systems are neural networks with many layers. As such, the more layers they have the deeper they are considered to be. In the next sections, I will begin to discuss neural networks. I will focus mostly on intuition when talking about neural networks. I will use linear regression and logistic regression constructs to define them. We can also think of deep neural nets as functions and this will become very useful as we start to program our code. Additional discussions of deep learning theory can be found in many other books such as “Fundamentals of Deep Learning: Designing Next-Generation Machine Intelligence” by Nikhil Buduma and Nicholas Locascio and Deep Learning by Goodfellow et al. (2016).

\section{PyTorch Basics}
 
The main idea with the implementation of deep neural networks in PyTorch is that you need to define a computational graph and run your code through this graph on the CPU (s) or GPU (s). 


Here are some of the main aspects of PyTorch to be aware of:


\begin{itemize}
\item PyTorch is object oriented
\item Tensors are multidimensional arrays 
\item PyTorch variables are memory buffers that contain these tensors
\item We call elements from PyTorch by referencing the object torch as such: torch.nn
\item In PyTorch you need to define a graph and then run it
\end{itemize}


It is now time to write some PyTorch code. Here let us add 2 numbers with PyTorch.

<center>
<div>
<textarea rows="10" cols="100">

a = torch.tensor(  [10]   )
b = torch.tensor(  [32]  )

def model(a, b):
    
    return a + b
    
res = model(a, b)
  
</textarea>
  
</div>
</center>










In this code we initialize 2 variables $ a $ and $ b $ as torch tensors, and add them together. . What is important to note here is that whenever you reference an object in PyTorch with torch, such as initializing the variable a, you are actually adding elements or nodes to a graph.  The graph can be seen in the following figure.


 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/tensorflowGraph.ch4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>




In this case, the command adds the 2 numbers together. The answer for this after printing the results should be 42.

\section{ Loading your Data into your PyTorch code}


Loading the data can actually be somewhat complicated in PyTorch. One of the issues is that you need to convert the data, say from something like the below example, to another format using one-hot encoding for the labels. This can sometimes be complicated and can cause you problems when writing your algorithms. 

<center>
<div>
<textarea rows="10" cols="100">

class,f1,f2,f3,f4 
1.0,6.1,2.8,4.7,1.2 
0.0,5.7,3.8,1.7,0.3 
2.0,7.7,2.6,6.9,2.3 
1.0,6.0,2.9,4.5,1.5 
1.0,6.8,2.8,4.8,1.4 
0.0,5.4,3.4,1.5,0.4 
1.0,5.6,2.9,3.6,1.3 
2.0,6.9,3.1,5.1,2.3 
1.0,6.2,2.2,4.5,1.5 
1.0,5.8,2.7,3.9,1.2
  
</textarea>
  
</div>
</center>
	    






Here, we are looking at the iris data set. The first column represents the annotated class. The IRIS dataset has 3 classes (0, 1, and 2). The other 4 columns represent the features per each sample. The code provided below will show how to read the data. 
In the code below, we assume that the data is contained in the file iris.csv (available at the book github). We can use the numpy loadtxt() function to obtain the data and to load it into a numpy matrix. Notice that the file has a header for the class and the 4 features. We can easily remove the header by using the parameter skiprows=1 in the numpy.loadtxt() function. 

<center>
<div>
<textarea rows="10" cols="100">

f_numpy = open("data/iris.csv",'r')

Matrix_data = numpy.loadtxt(f_numpy, delimiter=",", skiprows=1) 

#X=Matrix_data[:, [1,2,3,5,6]]

X = Matrix_data[:, 1:4]
y = Matrix_data[:,  0]
  
</textarea>
  
</div>
</center>




In the previous code we can slice the class column into the \textbf{y} variable and the rest of the columns into the \textbf{X} variable. Notice that we are following the SKlearn approach from the previous chapters. PyTorch has its own approaches but I have used SKlearn here for the sake of simplicity. When slicing a 2-D matrix (matrix[i, j] ) we specify the number of rows with \textbf{“i”} and the number of columns with \textbf{“j”}. We can also specify ranges by doing the following: matrix[2:5, :]. The “:” on the “j” index indicates select all columns. If we wanted to select from a list of column indices we could do the following: X=Matrix\_data[:, [1,2,3,5,6]].

Now we can split the data.


<center>
<div>
<textarea rows="10" cols="100">

X_train, X_test, y_train, y_test = train_test_split(
              X, 
              y,    
              test_size=0.20, 
              random_state=42
)
  
</textarea>
  
</div>
</center>






Similarly to the previous chapters, we can now split the data from \textbf{X} and \textbf{y} to obtain the train and test sets: X\_train, X\_test, y\_train, y\_test. As can be seen in the previous code segment, these data sets are now ready for one-hot encoding. Only the labels need to be one-hot encoded. The code for performing the one hot-encoding step is below. The one-hot encoding function and process was defined in the previous chapter. 



<center>
<div>
<textarea rows="5" cols="100">

y_train_onehot = convertOneHot_data2(y_train)
y_test_onehot  = convertOneHot_data2(y_test)

  
</textarea>
  
</div>
</center>
	    


In the code above we take the labels in y\_train and y\_test and pass them through our one-hot encoding function to produce the new variables y\_train\_onehot and y\_test\_onehot. You can visualize the new one-hot encoded vectors by running print y\_train\_onehot[:20,:] for the first 20 samples. 


The next step in the process is to scale the X data. I suggest running your data with scaling and without to compare the performance of your model. Convergence of your deep learning algorithm and model results can be better with scaled data. In this case we can use SKlearn’s scaling module StandardScaler() to perform this task. 


<center>
<div>
<textarea rows="8" cols="100">

sc = StandardScaler()

sc.fit(X_train)

X_train_normalized = sc.transform(X_train)
X_test_normalized  = sc.transform(X_test)

  
</textarea>
  
</div>
</center>
	    







As can be seen in the above code segment, we only need to scale the X data. We can fit a model with the train set and then use that model to scale both the X\_train and X\_test sets. 

Now that our data is ready, we want to save some information about the dimensions of the data sets in a couple of variables "A" and "B". This can be very helpful for code re-usability. We will store the number of features in "A" and the number of classes in "B". 

To obtain these values, we can use the .shape[z] function available to numpy arrays. In the code below we can see an example of how to get this value for "A". In this case, “z” represents the matrix dimension (number 0 for rows ,and number 1 for columns). 




<center>
<div>
<textarea rows="25" cols="100">

# features (A) and classes (B)
# A = number of features
# B = number of classes
# 10 numbers for Mnist (0,1,2,3,4,5,6,7,8,9), 
# 4 numbers for iris


A = X_train_normalized.shape[1] 
#num features 

B = y_train_onehot.shape[1] 
#num classes 

samples_in_train = X_train_normalized.shape[0] 
samples_in_test  = X_test_normalized.shape[0] 

print("num features", A)
print("num classes",  B)
print("num samples train", samples_in_train )

print("num samples test", samples_in_test)

  
</textarea>
  
</div>
</center>  










At this point, we have completed most of the pre-processing steps and we are ready to define the learning algorithms. This is where we define neural network architecture, the cost functions to be used, and the functions to predict results for given test samples. In the next section, I will implement a linear regression algorithm in PyTorch. After that, I will extend the linear regression framework to build a logistic regression model and later a deep architecture neural network model.

\section{Linear Regression}


Linear regression refers to a model for predicting any kind of magnitude (such as housing prices, sales prices, ages, etc.) instead of just classes (e.g. happy vs. sad, etc.). In the next subsections will cover the theory, intuition, and implementation in PyTorch code. 

\subsection{Theory and Intuition of Linear Regression}


Two important aspects to consider are the inference equation and the loss function. 

\begin{itemize}
    \item Linear regression inference equation
    \item Linear regression loss functions
\end{itemize}



In linear regression, multiple variables and coefficients are combined to form an equation that can be used to fit a particular data set.  The fitting process involves an optimization approach that minimizes the Least Squares Error. 

The coefficients or weights for each variable are useful in determining the contribution of each variable to the fitted model of the data.  The definition of the least squares error function can be seen in the function below (also known as MSE)

\begin{center}
    $ E = \frac{1}{n} \sum_{i = 0}^{n} (y_i - (  x * x_i + b  ))^2 $
\end{center}



Where $ n $ represents the number of samples. 


In linear regression, a line is fitted to the dataset in feature space by minimizing the sum of errors. That is to say, the sum of the error distances between the values in the predicted line and the real values are estimated (see figure below). 


     <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/linearregressionline.chap4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>






In the equation below, the term $ \Biggl \langle \bullet, \bullet \biggr \rangle $ denotes the dot product in the input space between $ w $ and $  x $. Here, $ x $ is the input vector, $ w $ is the weight vector, and $ b $ is the bias. 

\begin{center}
$  f(x) = \Biggl \langle w, x \biggr \rangle + b  $
\end{center}

This simple equation defines the linear regression and the parameters that must be learned given the training data. With this theoretical framework I will now proceed to describe how to code this with PyTorch.
The linear regression model is implemented in the code below. The purpose of the code below is to be simple and to show how a linear regression algorithm can be implemented in python using PyTorch.



For our example, we are going to assume a very simple regression problem for housing prices. We are going to have 1 input (1 feature $ x_1 $ ) in our samples (the size of the house) and we will predict 1 output value $ y $ (the cost of the house). Therefore, we will have an equation as such: 

\begin{center}
$ y = w_1 * x_1 + b $
\end{center}

We will need to solve this equation by learning the values of $ w_1 $ and $ b  $ (the parameters) given the training data in $ x_1 $ and $ y $. 

For an equation with 2 input features such as 

\begin{center}
$ y = w_1 * x_1 + w_2 * x_2 + b $
\end{center}

we can show it in diagram form as can be seen in the figure. 




 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/linearregressionarchitecture.chp4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>

As shown in the previous equation, a linear regression is an equation made up of 3 main elements: x, w, and b. The x value holds the training data (features), w represents the weights per feature, and b is the offset value (bias) learned by the model. These values are directly coded into our algorithm using PyTorch. 



The  2 variables, W and b, are variables that define the prediction equation. They are the parameters to be learned. All examples in this book will use these variables whether we are defining logistic regression or deep neural nets. W and b are matrices (tensors) whose dimensions need to be defined. This is where we start to define the architecture of our models. In this case, the dimensions are [1,1] for W and just [1] for b. In the case of W the dimension is [1, 1] because it is for a model with 1 feature ( $ x_1 $) and 1 output value (the predicted housing price y). Think of W as a matrix that connects one layer to the next. In this case, we are connecting the inputs to the outputs.




                    
                    
Okay, so now that we have defined the variables, the next step is to define the equation and define the cost function to learn the parameters (e.g. the weights). To do that, we use the following section of code. This is one of the most important parts of deep learning programming. 

In the next section we proceed to train a linear regression model for a wine quality dataset using PyTorch. 



\subsection{Linear Regression model for wine quality data}


In this section a linear regression model is trained with PyTorch for a Wine Quality Dataset. Our Wine Quality dataset can also be used in a classification example since the \textbf{y} values are discrete and consist of the values [0, 1, 2, 3, 4, 5]. These represent the wine quality rating from 0 to 6.

The data can be used to illustrate the differences between regression and classificatio modeling.


We first add some of our common libraries. 

<center>
<div>
<textarea rows="15" cols="100">

import numpy as np
import torch
import pandas as pd
import sklearn 
import random 
import matplotlib.pyplot as plt

from mlxtend.plotting import heatmap
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import r2_score

  
</textarea>
  
</div>
</center>
	 






The following are the main libraries to define neural network architectures in PyTorch


<center>
<div>
<textarea rows="6" cols="100">

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

  
</textarea>
</div>
</center>






Next, the parameters are set. These include the learning rate, the number or epochs, and the batch size. 

<center>
<div>
<textarea rows="8" cols="100">

batch_size    = 16
learning_rate = 0.0003
N_epochs      = 200        ## 1000

epsilon = 0.0001
  
</textarea>
</div>
</center>

<p>

Now we read the data:
	
</p>

<center>
<div>
<textarea rows="6" cols="100">

path_data = 'winequality-white.csv'

WINE_raw_data_df = pd.read_csv(path_data, delimiter=";")

  
</textarea>
</div>
</center>




We can print the data with 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={print the wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]
print( WINE_raw_data_df )


\end{lstlisting}
\end{minipage}


This prints the pandas data frame like so 

\begin{figure}[H]\centering
\adjustbox{max height=.30\textheight}{
    \includegraphics{images/wine_in_pandas_frame.png}
}
\caption{Wine data in pandas data frame }
\label{RegLin:fig}
\end{figure}

Now we can print the features in the data frame

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The features in the data frame}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

headers_list = WINE_raw_data_df.columns.values.tolist()

print( headers_list )

\end{lstlisting}
\end{minipage}



which gives us


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{showstringspaces=false}  %% remove weird symbol in spaces
\lstset{frame=lines}
\lstset{caption={Wine dataset features}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


['fixed acidity',
 'volatile acidity',
 'citric acid',
 'residual sugar',
 'chlorides',
 'free sulfur dioxide',
 'total sulfur dioxide',
 'density',
 'pH',
 'sulphates',
 'alcohol',
 'quality']


\end{lstlisting}
\end{minipage}

We can also select a subset to focus on 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={A subset}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


headers_list2 = [ 'density',
 'pH',
 'sulphates',
 'alcohol',
 'quality']

print( headers_list2 )


\end{lstlisting}
\end{minipage}



which should give us


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Printed selected features}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


['density', 'pH', 'sulphates', 'alcohol', 'quality']


\end{lstlisting}
\end{minipage}

To print a correlation matrix and perform some data science we can run the following

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Code to print correlation matrix}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


cm = np.corrcoef(   WINE_raw_data_df[ headers_list ].values.T  ) 

hm = heatmap(cm, row_names=headers_list, column_names=headers_list, figsize=(20,10))


\end{lstlisting}
\end{minipage}



This gives us the figure as follows

\begin{figure}[H]\centering
\adjustbox{max height=.60\textheight}{
    \includegraphics{images/wine_correlation_matrix.png}
}
\caption{Wine data correlation matrix }
\label{RegLin:fig}
\end{figure}

The key is that rows and columns with values very close to zero have no correlation, whereas rows and columns with values close to one (either positive or negative) have strong correlation. 


Now we can proceed to process the data and convert from pandas to Numpy.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Convert pandas wine data to numpy}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


WINE_raw_data_np = WINE_raw_data_df.to_numpy()

print( WINE_raw_data_np )

\end{lstlisting}
\end{minipage}

this will print the numpy array as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Wine data as numpy }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],
       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],
       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],
       ...,
       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],
       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],
       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]])


\end{lstlisting}
\end{minipage}



If we print the shape we can see it is (4898, 12)


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Print shape}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


print( WINE_raw_data_np.shape ) 


\end{lstlisting}
\end{minipage}


Now we proceed to slice the wine data into \textbf{x} and \textbf{y} which gives the dimensions 

X = (4898, 11)

y = (4898, 1)

With this we know we have 11 features and one predicted value 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={slice wine data into x and y}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


X = WINE_raw_data_np[:, :-1]

y = WINE_raw_data_np[:, 11:12]

print( X.shape )

print( y.shape)


\end{lstlisting}
\end{minipage}



printing the y numpy vector gives us


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The y numpy vector}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


array([[6.],
       [6.],
       [6.],
       ...,
       [6.],
       [7.],
       [6.]])


\end{lstlisting}
\end{minipage}

I like to split the data randomly every time I train the model. By doing this, I get to see the performance variation. I usually call this a "poor man's ten fold cross validation". I can achieve it quite simply by doing the following:

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Random split}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


random_seed =   int( random.random() * 100 )   ## 42

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)

print( X_train.shape)
print( X_test.shape)
print( y_train.shape)
print( y_test.shape)


\end{lstlisting}
\end{minipage}



after the split you can get the following shapes


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Shapes after the split}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


(3918, 11)
(980,  11)
(3918,  1)
(980,   1)


\end{lstlisting}
\end{minipage}

Sometimes, torch can give you strange errors. One common one relates to the data type being size 64 when it torch wants it to be 32 such as:

dtype('float64')

You can check and change the type like this in numpy array and then change to PyTorch tensors

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Correct data type error}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


print( y_test.dtype ) 

X_train = X_train.astype( np.float32  )
X_test  = X_test.astype(  np.float32  )
y_train = y_train.astype( np.float32  )
y_test  = y_test.astype(  np.float32  )


print( y_test.dtype ) 



\end{lstlisting}
\end{minipage}



after this, the data type should be set to 32. 

Now we are ready to convert to PyTorch.


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={From numpy to torch}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

X_train_tr = torch.from_numpy(  X_train  )
X_test_tr  = torch.from_numpy(  X_test   )
y_train_tr = torch.from_numpy(  y_train  )
y_test_tr  = torch.from_numpy(  y_test   )



\end{lstlisting}
\end{minipage}

In general, deep learning data likes to be scaled. 

There are two main types of scaling which both have worked well for me. Generally speaking, I have used standardization. They are:  

\begin{itemize}
\item standardization
\item normalization
\end{itemize}

In this example we will standardize by first calculating the data means and standard deviations as can be seen below. The epsilon helps to avoid divide by zero errors. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Means and Standard deviations}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

x_means      = X_train_tr.mean(0, keepdim=True)
x_deviations = X_train_tr.std( 0, keepdim=True) + epsilon


\end{lstlisting}
\end{minipage}


These can be viewed, for instance, by printing x\_means and we get 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The means for standardization}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


tensor([[6.8566e+00, 2.7671e-01, 3.3420e-01, 6.3712e+00, 4.5989e-02, 3.5417e+01,1.3811e+02, 9.9402e-01, 3.1890e+00, 4.8992e-01, 1.0511e+01]])


\end{lstlisting}
\end{minipage}


As we saw in the previous chapters, deep learning algorithms are so complex now that using object oriented approaches whenever possible helps to better understand what is going on. In this case we load the data into the torch object "DataLoader" like the code below. the "shuffle" parameter handles randomizing the data as batches are read into the torch model during training. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Torch Dataset and DataLoader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


train_ds = TensorDataset( X_train_tr, y_train_tr  )

train_dl = DataLoader( train_ds, batch_size, shuffle=True   )


\end{lstlisting}
\end{minipage}



At this stage, we are ready for the linear regression architecture. We define the class for it below. Notice that in the init function we define the number of neurons in the layers. In forward function we then define the neural network sequence from input to output. This even includes the standardization part. 

Our architecture object oriented classes will inherit the "nn.Module" class from torch which is a classic example of class inheritance in object oriented programming. We make use of super init function to instantiate the inherited NN class. 

The input layer has 11 neurons for the 11 features, and the last layer has 1 neuron for the regression output. 

Notice there are no hidden layers or activation functions. 

In the following code segment, we define the linear regression architecture. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Linear Regression NN architecture}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


## Linear Regression

class LinRegNet(nn.Module):
    ## init the class
    def __init__(self, x_means, x_deviations):
    
        super().__init__()
        
        self.x_means      = x_means
        self.x_deviations = x_deviations
        
        self.linear1 = nn.Linear(11, 1)
    
    ## perform inference
    def forward(self, x):
        
        x = (x - self.x_means ) / self.x_deviations
        
        y_pred = self.linear1(x)
        
        return y_pred


\end{lstlisting}
\end{minipage}

Now, we should be ready to train the model. First we want to define a training function we can re-use. The function has 2 "for" loops. one loop is to repeat the process based on the number of epochs. The second "for" loop is to read the $ xb $ and $ yb $ data in batches from our DataLoader named "train\_dl". Here, $ xb $ is run through the model to predict $ y\_pred $. The predicted value is compared to the real value in $ yb $ to calculate the loss. This loss is what we minimize according to the definition of the loss function. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={NN training function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


def train_loop(N_epochs, model, loss_fn, opt):
    
    for epoch in range(N_epochs):
        for xb, yb in train_dl:
            
            y_pred = model(xb)
            loss = loss_fn(y_pred, yb)
            
            opt.zero_grad()
            loss.backward()
            opt.step()
            
        if epoch % 20 == 0:
            print( epoch, "loss=", loss)


\end{lstlisting}
\end{minipage}



The following 3 commands from our training function zero out the grads buffer, perform the derivatives to calculate the gradients, and finally take a step to update the weights. 

If you noticed, the training function takes arguments for the optimization object and the loss function object. These will be described shortly. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Calculate gradients and update the weights}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


opt.zero_grad()
loss.backward()
opt.step()


\end{lstlisting}
\end{minipage}

Now we can invoke the core functions and instantiate the "Adam" optimizer and the loss function. Two important items to notice are that the weights from the model are passed to the optimizer with 

\begin{center}
 model.parameters()
\end{center}


 and that the loss is initialized to the MSE regression loss function with 

 
 \begin{center}
 loss\_fn = F.mse\_loss
\end{center}

Now we are ready to call the core functions

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Call the core functions}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


model = LinRegNet(x_means, x_deviations)

opt = torch.optim.Adam( model.parameters() , lr=learning_rate  )

loss_fn = F.mse_loss

train_loop(  N_epochs, model, loss_fn, opt    )


\end{lstlisting}
\end{minipage}


Running the training loop begins the training process and should give us the following output. Notice that the loss is going down. That is the desirable objective. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Losses output during training }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


0   loss= tensor(28.6100, grad_fn=<MseLossBackward0>)
20  loss= tensor(0.3579, grad_fn=<MseLossBackward0>)
40  loss= tensor(0.6686, grad_fn=<MseLossBackward0>)
60  loss= tensor(0.6591, grad_fn=<MseLossBackward0>)
80  loss= tensor(0.4780, grad_fn=<MseLossBackward0>)
100 loss= tensor(0.3440, grad_fn=<MseLossBackward0>)
120 loss= tensor(0.1906, grad_fn=<MseLossBackward0>)
140 loss= tensor(0.6763, grad_fn=<MseLossBackward0>)
160 loss= tensor(0.9073, grad_fn=<MseLossBackward0>)
180 loss= tensor(0.3839, grad_fn=<MseLossBackward0>)


\end{lstlisting}
\end{minipage}

Now we are ready to evaluate our trained model on the test set. Printing the shape of the predicted tensor gives us .
The score is measured with the $ R^2 $ also known as the coefficient of determination. This gives us a size of (980, 1) and the metric as follows: 

Testing $ R^2 $:  0.3152

The result should be close to 1 to be considered a good result. In future sections we can try better architectures than just linear regression. This is an especially difficult problem to model with regression so the modeling will be challenging but will give us a good dataset to practice on. The code: 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Evaluate model on test set }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


y_pred_test = model( X_test_tr  )

print( y_pred_test.shape )

print(  "Testing R**2: ", 
        r2_score( y_test_tr.numpy(), 
                  y_pred_test.detach().numpy()  
        )  
)


\end{lstlisting}
\end{minipage}


With the following code we can use the model to predict $ y $ given our $ x $ input vectors of size 11. The predicted torch tensors need to be detached and converted to numpy for further manipulation. This is a common practice when using Torch. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Code to Print predicted values}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


list_preds = []
list_reals = []

for i in range(len(X_test_tr)):
    print("**********************************")
    print("pred, real")
    np_real =   y_test_tr[i].detach().numpy()
    np_pred = y_pred_test[i].detach().numpy()
    print( (np_pred[0], np_real[0])  )
    list_preds.append(  np_pred[0]   )
    list_reals.append(  np_real[0]   )


\end{lstlisting}
\end{minipage}

The previous code results in the following output. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The predicted test values }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

**********************************
pred, real
(5.7949276, 6.0)
**********************************
pred, real
(6.347283, 6.0)
**********************************

...

**********************************
pred, real
(5.9985185, 5.0)
**********************************
pred, real
(5.6252785, 6.0)
**********************************
pred, real
(6.5844297, 7.0)



\end{lstlisting}
\end{minipage}



A nice visualization technique to assess our model is to plot together  the predicted and real y values from the test set. If perfect, predicted and real values should be in the same point and there should only be one color. 

In our graph below we see 2 colors and this shows that the model did not learn so well. The code to do this is as follows:


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Plot real and predicted test outputs}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


plt.figure(figsize=(13,4))

plt.plot(list_reals, label='real', color='r')
plt.plot(list_preds, label='pred')

plt.title("Preds vs. Real")
plt.xlabel("Test sample number")
plt.ylabel("Rating")
plt.legend()
plt.savefig("PredVsRealPlot", dpi=300)


\end{lstlisting}
\end{minipage}


and the plot is as follows: 






 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/LinRegRealVsPred.png" height="700" width="auto">
      </div>
    </center>
	

\section{Linear Regression to Logistic Regression and Neural Nets}


In this section, we are going to modify and extend our code from the linear regression model so that we can implement logistic regression, one-layer neural nets, and deeper neural networks of multiple layers (Deep Learning). In the following code sections I will make some modifications so that the new models can be implemented easily. 

Additionally, we can use the variables \textbf{A} and \textbf{B} that we previously described to define the number of neurons per layer. In this case \textbf{A} represents the number of features in our data set. For example, the iris data set has 4 features per sample ( $x_i = [f_1, f_2, f_3, f_4]$ ). The variable $ x $ is defined as a matrix (tensor) of [None, A] or [None, 4] for this iris dataset. Similarly, $ y $ is defined by [None, B] or [None, 3] where 3 stands for the number of classes which in this case, for the iris dataset, are Setosa, Versicolor, and Virginica. 



For the new models, we can continue to use the training function that we previously defined. Although very little changes, it is important to mention that the optimizer and learning rate can be changed and that there are many alternatives that could be used. A lot of research has been done on this topic and it is currently an on-going and open research field. Therefore, many optimization approaches exist and many of them are available in PyTorch.

\subsection{Regression vs Classification}

In linear regression we were training to predict any kind of real valued number.  From this point on, we build models that can predict either real valued numbers or discrete classes. The model architectures are similar and we just need to make a few changes usually to output layers and loss functions. 

\begin{itemize}
    \item Predict either real valued numbers (Regression)
    \item Predict discrete classes (Classification)
\end{itemize}

For classification modeling, where we predict discrete classes (also called labels), we will usually have the real labels and the predicted labels. Our models will predict the labels and we will need ways of comparing them to the real labels. The following function is a way to evaluate the actual or real classes per sample (y\_real) against the predicted classes (y\_pred) per sample in a test set. We can compare the two sets of one-hot encoded labels with torch.eq() to measure the accuracy.
The torch.eq() function returns a vector of boolean values that compares the values in two tensors of equal dimensions as can be seen in the following code listing:

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Torch.eq}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


y\_pred = [1, 2, 3]   
                        
y\_real = [0, 1, 3]

torch.eq(x, y)   =>    [False, False, True]   or  [0, 0, 1]



\end{lstlisting}
\end{minipage}

The loss functions vary for regression and classification. Classification uses Cross Entropy losss (defined later) and Regression uses Mean Squared Error usually (described earlier).

\begin{itemize}
    \item Classification loss is Cross Entropy
    \item Regression loss is MSE
\end{itemize}

\subsection{Instantiating the different models}
 

So, now we are ready to once again define our model architecture, and define the loss and training functions.  This is where the magic will happen and where the code will be specific to the algorithm and architecture being defined. Since this will vary based on model and output type we want to predict, each algorithm will be addressed in its own section later. For now, I will simply define how we can instantiate the architectures. For example, in the next code section I have the core function calls for logistic regression.


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Call the core functions for logistic regression}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


model = LogisticRegNet()

opt = torch.optim.Adam( model.parameters() , lr=learning_rate  )

loss_fn = F.cross_entropy

train_loop(  N_epochs, model, loss_fn, opt    )


\end{lstlisting}
\end{minipage}


If we were defining a deep neural network (with several layers), we can define the function calls as follows (below). 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Call the core functions for Deep Learning}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


model = DeepLearningNet()

opt = torch.optim.Adam( model.parameters() , lr=learning_rate  )

loss_fn = F.cross_entropy

train_loop(  N_epochs, model, loss_fn, opt    )


\end{lstlisting}
\end{minipage}


The important aspect is to notice that the structure of the code is mostly maintained and that the only things that change are the architecture definition and the loss function (usually from MSE to Cross entropy).


\subsection{Reading Data in batches}

Earlier in this book, I mentioned that one of the advantages of deep neural networks and PyTorch is that they were designed to process massive amounts of data. Loading millions of records directly into RAM memory would not be suitable for most big data challenges. Instead, to be more efficient we can load data in batches. That is, we can take our data set and divide it into bins of size \textbf{N\_batch\_size}.  

           

In the following code section, I will show how to create the batches manually. We need to define the size of each batch (in this case 100 samples) and the size of the train set file. Then we divide number of samples by number of batches. We can then easily slice out the batches from the data by iterating the \textbf{batch\_n} index. The dimensions are \textbf{sta} for the starting index and \textbf{end} for the ending index. In every iteration, we select the rows from \textbf{sta} to \textbf{end} (sta:end) and all the columns (:). 


PyTorch has tools to do this with Torch \textbf{TensorDataSet} and Torch \textbf{DataLoader} as we previously saw but this is how it works! The code is as follows: 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Creating batches manually}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

batch_size = 100

num_samples_train_set = X_train_normalized.shape[0] 

num_batches = int( num_samples_train_set/batch_size )

for i in range(n_epochs):
    for batch_n in range(num_batches):
        sta = batch_n * batch_size
        end = sta + batch_size
        y_pred = model(   
             X_train[sta:end, :],
             y_train[sta:end, :] 
        )

\end{lstlisting}
\end{minipage}

\subsection{What is Number of Epochs?}

The previous code section focuses on the training phase in the main loop. This section has 2 nested loops for training. The first one is to train the model for \textbf{n\_epochs}. This allows us to set how many times we want to run the optimization of the model to learn the parameters (i.e. the weight vectors). Stop here and think about this for a second and contemplate what this means. If we set \textbf{n\_epochs} to 100,000, then it means that the loop will show the same data to the model during training a total of 100,000 times! The data is usually randomized or shuffled each time but still. The model sees the data 100,000 (again and again). Do humans need that many times to learn something? We should think about this.



\section{Logistic Regression}

Before we look at the deep neural nets, it is a good idea to look at logistic regression. Logistic regression is still a linear classifier but deep neural nets can build on the ideas of logistic regression. So, basically here we will use all the code we have developed so far. The only main difference is that now we will re-define the code for:

\begin{itemize}
    \item The architecture classes (Inference class)
    \item The loss function
\end{itemize}


The logistic regression inference model class is mainly different from the linear regression approach because we now run our function \textbf{nn.linear} which represents the linear equation through a Softmax function.

\begin{center}
    y = Softmax( torch.matmul(x, W) + b  )

    
\end{center}

Additionally, instead of predicting a real valued number with just one output neuron, we now have several output neurons which represent each possible class (3 in the case of IRIS, or 10 in the case of MNIST or CIFAR-10, etc.). Our Wine Quality dataset can also be used in a classification example since the \textbf{y} values are discrete and consist of the values [0, 1, 2, 3, 4, 5]. These represent the wine quality rating from 0 to 6. So, in this case would have 6 classes. 

\subsection{Theory and Intuition of Logistic Regression  }

Intuitively think of it this way. Imagine you want to predict housing prices given square footage. The value we want to predict is a real value number and not a class. So, this means that you use regression modeling. As such:

\begin{center}
     $ housing\_price = w_1 * square\_footage + b $

\end{center}

or

\begin{center}
  
                        $ y = w_1 * x_1 + b $

    
\end{center}
     
This formula with values could look like this:

\begin{center}
  
                       \$250,500 = 50 * 5000 + 500

    
\end{center}



The model learned the parameters 50 and 500, and with an input of 5000 square feet can predict the housing price. This is a network of one input neuron and one output neuron. One can reason that you can create another similar equation with one input and one output and now you have 2 separate functions with 1 input each that predict one different output each. While these are 2 separate equations, we can combine them together using neural networks so that now both equations work together and can predict 2 outputs given 2 inputs. Basically, that is a model of multiple inputs (two in this case) to multiple outputs (two in this case).
We can extend this idea to models of several classes such as a model for the IRIS data set which has 3 classes, or the wine quality dataset which has 6. 

Now, how do we convert real valued numbers such as housing prices to discrete classes such as setosa, virgina, and versicolor? 


Well, we know in linear regression we can learn to predict real valued numbers given inputs. From maths we also know that we can run real valued numbers through certain functions to obtain scaled versions of those numbers. In this case a function such as the sigmoid (or the softmax) can do the following:

\begin{center}
  
                      new\_y  =  S(y)

    
\end{center}

                       
where 

\begin{center}
  
                 $   y  =  w * x  +  b $

    
\end{center}

                 
This function will take any value and convert it into a value in the range from 0-1. For example:

\begin{center}
  
            \$250,500 = 50 * 5000 + 500
                                                    
            new\_y  =  S(\$250,500)
                                                       
            new\_y  =   0.80

    
\end{center}
                                              
             

This allows us to learn functions that predict values between 0 and 1. This is good because these values can also be interpreted as probabilities or strengths of my prediction. As in, I have a 0.80 confidence that the house price is \$250,500. But what if I had 3 possible housing prices: \$150,700, \$250,500, and \$350,400. How can I represent this in the previous equation?  
Well, if we built one equation for \$250,000. Then we can definitely learn equations for the other 2 prices as such:

\begin{center}
  
            \$150,700 = 30 * 5000 +  700
                
            \$250,500 = 50 *  5000 +  500
                                            
            \$350,400 = 70 * 5000 +  400

    
\end{center}

                
So now if you notice, we have created a system of 3 equations


\begin{center}
  
             $ y_1   =    w_1  *   x   +   b_1 $
                    
             $ y_2   =    w_2   *  x   +   b_2 $
                    
             $ y_3   =    w_3  *    x   +  b_3 $


    
\end{center}

                  
If you look at this as a network, we can see that it has 3 output neurons and 1 input neuron and, in fact, the network will look like this:




 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/housingpriceequationsarch.chp4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>

	




If we apply our Sigmoid function:

\begin{center}
  
             new\_y  =  S(y) 


    
\end{center}

                       

to each equation then we can get a new set of outputs which are now scaled to be from 0..1 like so: 

\begin{center}
  
            $o_1     =  S( y_1 )  =    w_1  *   x   +   b_1$
            
            $o_2     =  S( y_2 )  =    w_2   *  x   +   b_2$
            
            $o_3     =  S( y_3 )  =    w_3  *   x   +   b_3$


    
\end{center}

           

 So the formulas, that looked like this 

 \clearpage

\begin{center}
  
              \$150,700 = 30 * 5000 +  700
                
              \$250,500 = 50 *  5000 +  500
                
              \$350,400 = 70 * 5000 +  400


    
\end{center}

              
        
Can now look like this

\begin{center}
  
                0.30       = S(30 * 5000 +  700)
                
                0.60       = S(50 * 5000 +  500)
                
                0.70       = S(70 * 5000 +  400)


    
\end{center}

             

This intuition hopefully shows you how you can train models to predict confidence values for a specific output neuron such as, confidence that, given a square footage of 5000, the housing price is more likely to be \$250,000 (based on the 0.60 confidence). 

For this example we have discretized the housing prices. The model cannot predict values in between these 3 house prices. It can only tell you which one of these 3 is the most likely. To get prices between these 3 we would use Regression. To assign the second housing price when  training the model we can use a one hot encoding approach like the following [0, 1, 0] to provide the real values. Notice that if you think of these as probabilities, it means we have 100\% confidence that this is for class 2 (second housing price). But our 3 house probabilities do not add up to one (0.30 + 0.6 + 0.7 = 1.6). Having these add up to 1.0 would be desirable. Luckily, we can accomplish this with the Softmax function. 

Formally, a Softmax function is a way of mapping a vector of real valued numbers in any range into a vector of real valued numbers in the range of zero to 1 (0-1.0) where all the values add up to 1.0. The result of the Softmax therefore gives a probability distribution over several classes. The softmax function can be written as follows:

\[ S(y_i)= \frac{e^{y_i}}{ \sum_{j=1}^{c} e^{y_i} }\]




This function takes the y values as inputs (called logit scores), which represent the classes "c",  and produces a new y vector where all values add up to 1. An example can be seen here:

\begin{center}
  
[2.0 , 1.0, 0.1]       and maps it to  =>        [0.7, 0.2, 0.1]


    
\end{center}




In python we can test this as follows:

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The Softmax }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


import numpy as np

logits      = [2.0, 1.0, 0.1 ]
exps        = [ np.exp(i) for i in logits] 
sum_of_exps = sum(exps)
softmax     = [ j/sum_of_exps  for j in exps ] 

print( sum(softmax) )

\end{lstlisting}
\end{minipage}


In the next code segment, the inference function for logistic regression is defined in PyTorch. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={The Softmax Inference function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


y = torch.matmul(x, W) + b
y_pred = nn.Softmax(  y  )

\end{lstlisting}
\end{minipage}

For illustration, the figure below shows the logistic regression neural network for the Iris dataset. 

\begin{figure}[H]\centering
\adjustbox{max height=.40\textheight}{
    \includegraphics{images/logregarchiiris.chp4.300dpi.jpg}
}
\caption{Logistic Regression Architecture for the Iris dataset}
\label{RegLin:fig}
\end{figure}



So, assuming we are working with the iris dataset, the features are equal to 4 and the classes are equal to 3. The previous figure shows the architecture for a logistic regression model. If you look closely, you can conclude that a logistic regression model is like a neural network with no hidden layers. There are only 2 layers: the input layer and the output layer. A hidden layer would be a layer in between input and output that connects these 2 layers. The number of neurons in one layer and the number of neuron in the next layer determine the size of the weights matrix W. For the Iris example we can see that W results in a matrix that is [4,3] in size. The b vector (bias) has dimension 3 (for the 3 output neurons). That is, there is now a bias for every neuron in the output layer. 



In the linear regression example we used a Least Squares Error loss function (or MSE). In this case we now use a logistic regression cost function.  Logistic regression uses a cost function called Cross Entropy. The Cross Entropy compares the real labels to the predicted labels.
There are actually 2 types of Cross Entropy. They are:

\begin{itemize}
    \item The binary form of cross entropy (for 2 classes)
    \item The multi-class form
\end{itemize}

\subsubsection{Binary Cross Entropy}

The binary form of cross entropy is for cases when you only have 2 classes. The Cross Entropy compares the real labels to the predicted labels using the following equation. The following Cross Entropy loss equation replaces our previously described MSE loss function when optimizing classification models. The Cross Entropy is formally defined as follows:

\begin{center}
$ 
\begin{aligned}
cost( g(w^T * x), y ) & = - log( g(w^T * x)) \qquad \longrightarrow  if \qquad y = 1 \\
                      & = - log( 1- g(w^T * x))     \longrightarrow  if \qquad y = 0 
\end{aligned}
$ 
\end{center}


In the previous cost function definition, g() represents the Sigmoid function. We can also write these equations as follows:


\begin{center}
$ 
\begin{aligned}
         & - log( h_0(x)) \qquad \longrightarrow  if \qquad y = 1 \\
         & - log( 1- h_0(x))     \longrightarrow  if \qquad y = 0 
\end{aligned}
$ 
\end{center}

These 2 equations generate the following graphs:

 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/logregcrossentropy1.ch4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>




 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/logregcrossentrpy2.ch4.300dpi.jpg" height="700" width="auto">
      </div>
    </center>


As can be seen in the graphs, the loss has one shape for one class and another shape for the other. 
For convenience, the previous logistic regression functions can also be written as one function as follows:

\begin{center}
    $   J( \theta ) = -(\frac{1}{m}) \sum_{i=1}^{m} \quad [y * log(h_{\theta}(x)) + (1-y)* log(1 - h_{\theta}(x))] $
\end{center}

\subsubsection{Multi Class Cross Entropy}


The following code shows the implementation of the Multi-Class loss function for logistic regression as if we were writing out the equations. 
One important thing to mention is that I have noticed that this model does not always converge. To correct this, you can use a clipping function like so

\begin{center}
    y\_pred2 = torch.clip\_by\_value (y\_pred, 1e-10, 1.0) 
    
\end{center}

           
           
This line of code helps because some values in the process become NaN (Not a Number) and the clipping in the function addresses the problem. This approach of writing out the cost function or equations is not always the most optimal but I have shown it here for contrast between linear regression and logistic regression. A better approach is to use PyTorch built-in cost functions for Cross Entropy calculations. Future code for deep neural networks will abstract this by using the built-in functions. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Cross Entropy loss with equations}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


def loss(y_pred, y_real):
    y_pred2 = torch.clip_by_value(y_pred, 1e-10, 1.0)
    dot_product = y_real * torch.log( y_pred2 )
    xentropy = -torch.reduce_sum( dot_product, reduction_indices=[1] ) 
    loss = torch.reduce_mean( xentropy )
    return loss

\end{lstlisting}
\end{minipage}


The following statement is where we invoke the multi-class cross entropy loss function.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Multi-Class Cross Entropy Function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

dot_product = y_real * torch.log( y_pred2 )


\end{lstlisting}
\end{minipage}



An easy way to understand the multi-class cross entropy loss function is with an example. Assume we try to classify images of vehicles and we have  5 categories for [plane, car, boat, bike, balloon]. Given a cross entropy model we have the following output vector for this multi-class problem as such:

\begin{center}
         $ Q_1 = [0.3,  0.2,    0.05,    0.05,   0.40] $
\end{center}
            
                           
According to this model, the image is 30\% plane, 20\% car, 5\% boat, 5\% bike, and 40\% ballon. The model is not very confident about what type of vehicle this is. In contrast, the label for each image would tell us with great certainty 

\begin{center}

    $ P_1 =  [ 1,    0,     0,      0,       0 ] $

\end{center}


that this is a plane. We can calculate the cross entropy to measure our model's cost. 

\begin{center}
      $ CrossEntropy(P_1, Q_1) = -\sum P_1(i) log Q_1(i) $
\end{center}
     

If we calculate the values we get:

\begin{center}

CrossEntropy = -(1 log 0.3  +  0 log 0.2  + 0 log 0.05  +  0  log 0.05  + 0 log 0.4)
  
  CrossEntropy         = - log 0.3
         
    CrossEntropy       =   1.20
    
\end{center}

  

After training, the model is much better and it can predict the following

\begin{center}

    $ Q_1 = [0.98,   0.01,    0.01,    0,   0] $
    
\end{center}
              
                    
As you can see below, the cross entropy is now lower and optimized. 

\begin{center}

  CrossEntropy = -(1 log 0.98  +  0 log 0.01  + 0 log 0.01  +  0  log 0  + 0 log 0)
  
                 CrossEntropy          = - log 0.98
                 
                CrossEntropy          =   0.0202
    
\end{center}



Therefore, with the cross entropy loss you compare predicted values to the labels. As the prediction improves, the cross entropy value goes down. 


\subsection{Logistic Regression NN Architecture}

In this section, I will show the architecture to implement a simple logistic regression NN for the Iris data set and the Wine Data Quality Dataset. 

\subsubsection{Iris Data set} 

The architecture for the inference NN is as follows:


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Logistic Regression NN architecture for Iris}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


class Logistic_Regression_Net(nn.Module):
    
    def __init__(self):
    
        super().__init__()
        
        self.linear1 = nn.Linear(4, 3)
        self.act1    = nn.Softmax(dim=1)
    
    def forward(self, x):
        
        x      = self.linear1(x)
        y_pred = self.act1(  x  )
        
        return y_pred


\end{lstlisting}
\end{minipage}


Notice that the model has 4 neurons in the input layer, and 3 output neurons for the 3 labels. The loss functions can be one of several versions of Cross Entropy such as

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Logistic Regression Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

loss_fn = nn.CrossEntropyLoss( )


\end{lstlisting}
\end{minipage}

Everything else should be the same as in the Linear Regression code. 

\subsubsection{Wine Quality Data set} 

The architecture for the inference NN is as follows:


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Logistic Regression NN architecture for the Wine Quality data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


class Logistic_Regression_Net(nn.Module):
    
    def __init__(self):
    
        super().__init__()
        
        self.linear1 = nn.Linear(11, 6)
        self.act1    = nn.Softmax(dim=1)
    
    def forward(self, x):
        
        x      = self.linear1(x)
        y_pred = self.act1(  x  )
        
        return y_pred


\end{lstlisting}
\end{minipage}


Notice that the model has 11 neurons in the input layer, and 6 output neurons for the 6 labels. The loss functions can be one of several versions of Cross Entropy such as

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Logistic Regression Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

loss_fn = nn.CrossEntropyLoss( )


\end{lstlisting}
\end{minipage}

Everything else should be the same as in the Linear Regression code. 

Now we are ready to add more layers. The next step is to add hidden layers.


\section{Layers of the Neural Network in PyTorch}
 
As we saw in the previous discussions, a logistic regression model is similar to a linear regression model. As you might imagine, a neural network is similar to the logistic regression model. 
In particular, the neural network now has more layers and the more layers it has, the deeper it becomes. 

Layers in between the input and output layers are called hidden layers and help to represent non-linearity along with activation functions. 

\begin{figure}[H]\centering
\adjustbox{max height=.40\textheight}{
    \includegraphics{images/onelayerNN.ch4.300dpi.jpg}
}
\caption{ A 1 layer neural network architecture (MLP)}
\label{RegLin:fig}
\end{figure}

A 1-layer neural network can look like the previous figure and a 2-layer neural network can look like the network in the figure below. As can be seen, we can continue to add layers and this is part of defining the architecture of a deep neural network. In theory, more layers can potentially give a model more power to learn from the data and be better. 
Notice, however, that this also means that many more parameters need to be estimated (e.g. more weights). Therefore, until recently, this was very expensive to achieve. With the advent of high performance hardware and GPUs, this is now more feasible. 



\begin{figure}[H]\centering
\adjustbox{max height=.40\textheight}{
    \includegraphics{images/twolayerNN.chp4.300dpi.jpg}
}
\caption{A 2 layer neural network architecture}
\label{RegLin:fig}
\end{figure}


\subsection{Intuition of adding more layers to a NN}

So why can  more layers potentially give a model more power to learn and be better? Let us think of an example. In an image processing problem, a neuron in a hidden layer might take as inputs 2 features or input neurons that detect circles. If these two circles are detected by the 2 input neurons, then the neuron in the next hidden layer which is connected to them might infer that a pair of eyes has been discovered. Therefore, this neuron in the hidden layer becomes a face detection or “pair of eyes” detection neuron. Given enough data, the model may discover this intuition and many others.  

\section{Going Deep: An N layer Neural Network in PyTorch}

We have defined so much of the code already that there really isn’t much left except to define the architecture and cost (or loss) function for the deep neural network. In the next code segments, I will define the 1-hidden layer NN (MLP), and a 2-Hidden layer NN (Deep Learning).

The architecture for an MLP is as follows:


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP Architecture for the Wine Quality data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


class MLP_Net_Net(nn.Module):
    
    def __init__(self):
    
        super().__init__()
        
        self.linear1 = nn.Linear(11, 8)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(8, 6)
        self.act2    = nn.Softmax(dim=1)
    
    def forward(self, x):
        
        x      = self.linear1( x  )
        x      = self.act1(    x  )
        x      = self.linear2( x  )
        y_pred = self.act2(    x  )
        
        return y_pred


\end{lstlisting}
\end{minipage}


Notice that the model has 11 neurons in the input layer, 8 neuron in the hidden layer, and 6 output neurons for the 6 labels in the output layer. ReLU activation is used on the hidden layer, and Softmax is used on the output layer. The loss functions can be one of several versions of Cross Entropy such as

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Cross Entropy Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

loss_fn = nn.CrossEntropyLoss( )


\end{lstlisting}
\end{minipage}

Everything else should be the same

The architecture for the deep neural network is as follows:


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Deep Neural Network with 2 Hidden layers for the Wine Quality data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


class Deep_Neural_Net_Net(nn.Module):
    
    def __init__(self):
    
        super().__init__()
        
        self.linear1 = nn.Linear(11, 15)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(15, 8)
        self.act2    = nn.ReLU()
        self.linear3 = nn.Linear(8, 6)
        self.act3    = nn.Softmax(dim=1)
    
    def forward(self, x):
        
        x      = self.linear1( x  )
        x      = self.act1(    x  )
        x      = self.linear2( x  )
        x      = self.act2(    x  )
        x      = self.linear3( x  )
        y_pred = self.act3(    x  )
        
        return y_pred


\end{lstlisting}
\end{minipage}


Notice that the model has 11 neurons in the input layer, 15 neurons in the first hidden layers, 8 neurons in the second hidden layer, and 6 neurons in the last output layer. The loss functions can be one of several versions of Cross Entropy such as

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Cross Entropy Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

loss_fn = nn.CrossEntropyLoss( )


\end{lstlisting}
\end{minipage}

Everything else should be the same. 

There are several activation functions but for these 2 architectures I have used the ReLU activation. The ReLU (Hahnloser et al. 2000) function stands for rectified linear unit. It is an optimal neuron for neural networks and it serves as a very effective activation function.  


\section{Easy Deep Learning with the Iris dataset}

In this section we will train models with the Iris dataset for classification. The Iris data set is a classic dataset that is not too difficult to model for classification. 

Let us get started. 

First we load the libraries. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Libraries}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

import numpy as np
import torch
import pandas as pd
import sklearn
import random
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
from mlxtend.plotting import heatmap
from sklearn.model_selection import train_test_split
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score


\end{lstlisting}
\end{minipage}

Now we set the parameters.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

batch_size    = 16
learning_rate = 0.003        ## 0.001
N_Epochs      = 4000

epsilon = 0.0001


\end{lstlisting}
\end{minipage}

Now we can load the data with Pandas

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Load the data with Pandas}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

path_data = 'iris.csv'

iris_raw_data = pd.read_csv( path_data, delimiter="," )


\end{lstlisting}
\end{minipage}

The labels for Iris are strings. We convert them to integers using Pandas as follows:

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Convert labels to integers}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

iris_raw_data.species = iris_raw_data.species.map( {'setosa':0 , 'virginica':1, 'versicolor':2} )


\end{lstlisting}
\end{minipage}

We can view the column headings which gives us 

['sepal\_length', 'sepal\_width', 'petal\_length', 'petal\_width', 'species']

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Column headings}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

headers_list = iris_raw_data.columns.values.tolist()

headers_list


\end{lstlisting}
\end{minipage}

We can now convert the Pandas data frame to numpy. Printing the shape gives us (150, 5)

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Convert Pandas to Numpy}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## Convert Pandas to Numpy

iris_raw_data_np = iris_raw_data.to_numpy()

iris_raw_data_np.shape

\end{lstlisting}
\end{minipage}

Now we slice the data for our "X" and "y" data.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Slice X and y}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

X = iris_raw_data_np[:, :-1]


y = iris_raw_data_np[:, 4:5]


\end{lstlisting}
\end{minipage}

we can convert the data type to integer

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Make sure y is int}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

y = y.astype(int)


\end{lstlisting}
\end{minipage}

let us determine the number of labels with np.unique. This give us [0, 1, 2]. There are 3 labels. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Find the unique labels }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

the_set = np.unique(y)

the_set

len(  the_set  )


\end{lstlisting}
\end{minipage}

In classification problems, it is a good idea to determine the class balance or imbalance. Imbalanced dataset are more difficult to model. We will see this with the Wine dataset in the next section. Using a histogram can help us to visualize this. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Plot histogram for classes}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

_ = plt.hist(y, bins='auto') 

plt.title("Histogram with 'auto' bins for Iris")

plt.show()


\end{lstlisting}
\end{minipage}

From the histogram below we can see that the classes are balanced. 

\begin{figure}[H]\centering
\adjustbox{max height=.55\textheight}{
    \includegraphics{images/HistogramIris.png}
}
\caption{Class Histogram for Iris}
\label{RegLin:fig}
\end{figure}

The shapes can be printed and seen below

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Print X and y shapes}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

print(X.shape)

print(y.shape)

## (150, 4)
## (150, 1)


\end{lstlisting}
\end{minipage}

Let us split the data

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Split the data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

random_seed = int( random.random() * 100 )     ## 42

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

## (120, 4)
## (30, 4)
## (120, 1)
## (30, 1)


\end{lstlisting}
\end{minipage}

Let us typecast the data to avoid possible errors and then convert to torch tensors. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Typecast the data to avoid possible errors}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

X_train = X_train.astype(  np.float32  )
X_test  = X_test.astype(   np.float32  )
y_train = y_train.astype(  np.int64 )       ## np.long  
y_test  = y_test.astype(   np.int64 )


X_train_tr = torch.from_numpy(X_train)
X_test_tr  = torch.from_numpy(X_test)
y_train_tr = torch.from_numpy(y_train)
y_test_tr  = torch.from_numpy(y_test)

\end{lstlisting}
\end{minipage}

Let us calculate means and standard deviations of the X data for data scaling. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Dara scaling parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

x_means      = X_train_tr.mean(0, keepdim=True ) 

x_deviations = X_train_tr.std( 0, keepdim=True) + epsilon

print( x_means.shape )
print( x_deviations.shape )

## [1, 4]
## [1, 4]

\end{lstlisting}
\end{minipage}

Torch provides a very handy DataLoader that works effieciently with our neural networks. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Create the list for the DataLoader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## X_train.shape[0] -> 120

iris_train_list = [  ( X_train_tr[i],  y_train_tr[i].item()  )  for i in range( X_train.shape[0] ) ]

iris_test_list  = [  ( X_test_tr[i],   y_test_tr[i].item()   )  for i in range( X_test.shape[0]  ) ]

print(  iris_train_list[:3]   )


\end{lstlisting}
\end{minipage}

three samples of the data should now look like this


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Cross Entropy Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

[(tensor([5.1000, 3.5000, 1.4000, 0.2000]), 0),
 (tensor([6.9000, 3.2000, 5.7000, 2.3000]), 1),
 (tensor([7.7000, 2.8000, 6.7000, 2.0000]), 1)]


\end{lstlisting}
\end{minipage}

The following command creates the DataLoader

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Create the Iris Dataloader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

train_dl = torch.utils.data.DataLoader(iris_train_list, batch_size=batch_size, shuffle=True)

\end{lstlisting}
\end{minipage}

we next create the test DataLoader with batch size equal to 30

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Create test DataLoader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## X_test.shape[0] -> 30

all_test_data = X_test.shape[0]

test_dl  = torch.utils.data.DataLoader(iris_test_list,  batch_size=all_test_data, shuffle=True)



\end{lstlisting}
\end{minipage}

We know define the architecture for the MLP as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP Architecture}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## MLP

class MLP_Net(nn.Module):
    ## init the class
    def __init__(self, x_means, x_deviations):
        super().__init__()
        
        self.x_means      = x_means
        self.x_deviations = x_deviations
        
        self.linear1 = nn.Linear(4, 3)
        self.act1    = nn.Sigmoid()
        self.linear2 = nn.Linear(3, 3)
        self.act2    = nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        
        
    ## perform inference
    def forward(self, x):
        
        ## x      = (x - self.x_means) / self.x_deviations
        
        x      = self.linear1(x)
        x      = self.act1(x)
        ## x      = self.dropout(x)
        x      = self.linear2(x)
        y_pred = self.act2(x)
        
        return y_pred
        


\end{lstlisting}
\end{minipage}

We can try another architecture such as a deep neural network of 2 hidden layers

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Deep learning for Iris}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## Deep Learning with 2 hidden layers

class DL_Net(nn.Module):
    
    def __init__(self, x_means, x_deviations):
        super().__init__()
        
        self.x_means      = x_means
        self.x_deviations = x_deviations
        
        self.linear1 = nn.Linear(4, 15)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(15, 9)
        self.act2    = nn.ReLU()
        self.linear3 = nn.Linear(9, 3)
        self.act3    = nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        
    ## perform inference
    def forward(self, x):
        
        x      = (x - self.x_means) / self.x_deviations
        
        x      = self.linear1(x)
        x      = self.act1(x)
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.dropout(x)
        x      = self.linear3(x)
        y_pred = self.act3(x)
        
        return y_pred


\end{lstlisting}
\end{minipage}

The next step is to define the train function. We have seen this before.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Train function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

def training_loop( N_Epochs, model, loss_fn, opt  ):
    
    for epoch in range(N_Epochs):
        for xb, yb in train_dl:
            
            ## yb = torch.squeeze(yb, dim=1)
            
            y_pred = model(xb)
            ## print(    yb.shape   )
            ## print( y_pred.shape  )
            loss   = loss_fn(y_pred, yb)
            
            opt.zero_grad()
            loss.backward()
            opt.step()
            
        if epoch % 50 == 0:
            print(epoch, "loss=", loss)


\end{lstlisting}
\end{minipage}

Now we call the Core Functions for the MLP. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Core Functions for MLP}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

model      = MLP_Net( x_means, x_deviations  )

opt        = torch.optim.Adam(    model.parameters(), lr=learning_rate )

## the y_test data can be integers and does not need to be one hot encoded with this function
loss_fn    = nn.CrossEntropyLoss( )   

training_loop(  N_Epochs, model, loss_fn, opt  )


\end{lstlisting}
\end{minipage}

The torch loss  \textbf{nn.CrossEntropyLoss( )}  is very versatile. It is defined to accept the real labels as integers and does not need them to be onbe hot encoded. 

Training gives us the following losses. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP losses}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

0   loss= tensor(1.1073, grad_fn=<NllLossBackward0>)
50  loss= tensor(0.9858, grad_fn=<NllLossBackward0>)
100 loss= tensor(0.7825, grad_fn=<NllLossBackward0>)
150 loss= tensor(0.7099, grad_fn=<NllLossBackward0>)
200 loss= tensor(0.6059, grad_fn=<NllLossBackward0>)
250 loss= tensor(0.6486, grad_fn=<NllLossBackward0>)
300 loss= tensor(0.6819, grad_fn=<NllLossBackward0>)
350 loss= tensor(0.6193, grad_fn=<NllLossBackward0>)

...

3650 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3700 loss= tensor(0.5598, grad_fn=<NllLossBackward0>)
3750 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3800 loss= tensor(0.5562, grad_fn=<NllLossBackward0>)
3850 loss= tensor(0.5525, grad_fn=<NllLossBackward0>)
3900 loss= tensor(0.5874, grad_fn=<NllLossBackward0>)
3950 loss= tensor(0.5525, grad_fn=<NllLossBackward0>)


\end{lstlisting}
\end{minipage}

We can use our previously defined funtion to determine classification performance.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Classification performance function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

def print_metrics_function(y_test, y_pred):
    print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))
    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)
    print("Confusion Matrix:")
    print(confmat)
    print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred, average='weighted'))
    print('Recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred, average='weighted'))
    print('F1-measure: %.3f' % f1_score(y_true=y_test, y_pred=y_pred, average='weighted'))


\end{lstlisting}
\end{minipage}

Finally, we can estimate the performance metrics for the MLP with Iris

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={predict with the model}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

with torch.no_grad():
    for x_real, y_real in test_dl:
        ## batch_size = imgs.shape[0]
        y_pred = model(  x_real  )
        vals, indeces = torch.max( y_pred, dim=1  )
        preds = indeces
        print_metrics_function(y_real, preds)


\end{lstlisting}
\end{minipage}

the performance can be seen below. Notice that the results are very good. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Performance results for MLP and Iris}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

Accuracy: 0.97
Confusion Matrix:
[[ 9  0  0]
 [ 0 10  1]
 [ 0  0 10]]
Precision: 0.970
Recall: 0.967
F1-measure: 0.967


\end{lstlisting}
\end{minipage}

We can also try the deep learning architecture

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Core Functions for Deep Learning}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

model      = DL_Net( x_means, x_deviations  )

opt        = torch.optim.Adam(    model.parameters(), lr=learning_rate )

## the y_test data can be integers and does not need to be one hot encoded with this function
loss_fn    = nn.CrossEntropyLoss( )   

training_loop(  N_Epochs, model, loss_fn, opt  )


\end{lstlisting}
\end{minipage}

the training gives us the following losses

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Deep NN losses with Iris}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

0   loss= tensor(1.0865, grad_fn=<NllLossBackward0>)
50  loss= tensor(0.5689, grad_fn=<NllLossBackward0>)
100 loss= tensor(0.8691, grad_fn=<NllLossBackward0>)
150 loss= tensor(0.6350, grad_fn=<NllLossBackward0>)
200 loss= tensor(0.5568, grad_fn=<NllLossBackward0>)
250 loss= tensor(0.6729, grad_fn=<NllLossBackward0>)
300 loss= tensor(0.5764, grad_fn=<NllLossBackward0>)
350 loss= tensor(0.5795, grad_fn=<NllLossBackward0>)
400 loss= tensor(0.5524, grad_fn=<NllLossBackward0>)
450 loss= tensor(0.6499, grad_fn=<NllLossBackward0>)

...

3550 loss= tensor(0.5536, grad_fn=<NllLossBackward0>)
3600 loss= tensor(0.6764, grad_fn=<NllLossBackward0>)
3650 loss= tensor(0.5515, grad_fn=<NllLossBackward0>)
3700 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3750 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3800 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3850 loss= tensor(0.5515, grad_fn=<NllLossBackward0>)
3900 loss= tensor(0.5514, grad_fn=<NllLossBackward0>)
3950 loss= tensor(0.5516, grad_fn=<NllLossBackward0>)


\end{lstlisting}
\end{minipage}

finally we predict with the DL model on the test set with 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Predict with DL model}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

with torch.no_grad():
    for x_real, y_real in test_dl:
        ## batch_size = imgs.shape[0]
        y_pred = model(  x_real  )
        vals, indeces = torch.max( y_pred, dim=1  )
        preds = indeces
        print_metrics_function(y_real, preds)
   


\end{lstlisting}
\end{minipage}

The performance metrics can be seen below and they are very good.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Cross Entropy Loss function}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

Accuracy: 0.97
Confusion Matrix:
[[ 9  0  0]
 [ 0 10  1]
 [ 0  0 10]]
Precision: 0.970
Recall: 0.967
F1-measure: 0.967


\end{lstlisting}
\end{minipage}

That was hopefully easy and a lot of fun. In the next section we explore a more challenging problem. It looks simple, an yet, helps us to see some of the common problems faced when training deep neural networks on noisy or more difficult data. 


\section{More Challenging Deep Learning with the Wine Quality dataset}

Here we repeat the process from the previous section but on the more challenging Wine Quality data set. We previously used this dataset for regression and now I will use it for classification. 

I will only include parts of the code that are new or different from the previous section. 

We use the following parameters.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

batch_size    = 32
learning_rate = 0.001 ## 0.001
N_Epochs      = 1000

epsilon = 0.0001


\end{lstlisting}
\end{minipage}

now we read the Wine quality data 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Read in the Wine quality data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

path_data = 'winequality-white.csv'

WINE_raw_data = pd.read_csv( path_data, delimiter=";" )


\end{lstlisting}
\end{minipage}

we can process the data like we did before

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## Convert Pandas to Numpy

WINE_raw_data_np = WINE_raw_data.to_numpy()

X = WINE_raw_data_np[:, :-1]
y = WINE_raw_data_np[:, 11:12]

y = y.astype(int)



\end{lstlisting}
\end{minipage}

The wine quality data was designed more for regression modeling. To make our classification modeling more interesting, I am going to process the data so we can also use it for classification. Since the predicted label consists of only 7 rating values, it is possible for us to convert into to classification data.

First we print the labels (ratings) from the y vector with the following

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={View unique values in y }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

the_set = np.unique(y)

the_set

len(  the_set  )

\end{lstlisting}
\end{minipage}

which gives us the ratings [3, 4, 5, 6, 7, 8, 9]. There are 7 ratings and these will become our labels. 

Let us visualize the label counts with a histogram using the following code

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Wine quality histogram}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

_ = plt.hist(y, bins='auto') 

plt.title("Histogram with 'auto' bins for Wine Quality")

plt.show()

\end{lstlisting}
\end{minipage}

As can be seen in the following histogram, the data is highly imbalanced. This means that this dataset will be more challenging to model for classification. 

\begin{figure}[H]\centering
\adjustbox{max height=.55\textheight}{
    \includegraphics{images/wine_quality_histogram.png}
}
\caption{Histogram for Wine Quality}
\label{RegLin:fig}
\end{figure}

let us first split the data like in the previous section

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Split the data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

random_seed = int( random.random() * 100 )     ## 42

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)

print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)

## (3918, 11)
## (980, 11)
## (3918, 1)
## (980, 1)


\end{lstlisting}
\end{minipage}

as in the previous section, let us change the data type and conver the numpy arrays to torch tensors. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Fix data type and convert to tensors}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## fix data type

X_train = X_train.astype(  np.float32  )
X_test  = X_test.astype(   np.float32  )
y_train = y_train.astype(  np.int64 )       ## np.long  
y_test  = y_test.astype(   np.int64 )

X_train_tr = torch.from_numpy(X_train)
X_test_tr  = torch.from_numpy(X_test)
y_train_tr = torch.from_numpy(y_train)
y_test_tr  = torch.from_numpy(y_test)


\end{lstlisting}
\end{minipage}

we now calculate parameters for standardization

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Standardization parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

x_means      = X_train_tr.mean(0, keepdim=True ) 

x_deviations = X_train_tr.std( 0, keepdim=True) + epsilon


\end{lstlisting}
\end{minipage}

To create the data loader we first need to create a label map. DataLoader does not allow gaps in label sequences. Our wine quality data does not have labels 2 or 1, for instance. So we need to fix this with a label\_map as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Label Maps}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## X_train.shape[0] -> 3918

## label_map = {0:0, 2:1 }
## the_set = array([ 3,   4,   5,   6,   7,   8,   9   ])

label_map         = { 3:0, 4:1, 5:2, 6:3, 7:4, 8:5, 9:6 }
reverse_label_map = { 0:3, 1:4, 2:5, 3:6, 4:7, 5:8, 6:9 }


\end{lstlisting}
\end{minipage}

with the folowing code we can fix the gap issue and create our list for the data loader as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={List for data loader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

wine_train_list = [  ( X_train_tr[i], label_map[ y_train_tr[i].item() ] )  for i in range( X_train.shape[0] ) ]

wine_test_list  = [  ( X_test_tr[i],  label_map[ y_test_tr[i].item()  ] )  for i in range( X_test.shape[0] ) ]


\end{lstlisting}
\end{minipage}

The following 3 examples show us what these lists look like

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Parameters}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

print( wine_train_list[:3] )


[(tensor([6.3000e+00, 2.8000e-01, 2.9000e-01, 6.8000e+00, 5.1000e-02, 4.0000e+01,
          1.4300e+02, 9.9374e-01, 3.4300e+00, 5.9000e-01, 1.1000e+01]),
  3),
 (tensor([7.3000e+00, 2.3000e-01, 3.7000e-01, 1.9000e+00, 4.1000e-02, 5.1000e+01,
          1.6500e+02, 9.9080e-01, 3.2600e+00, 4.0000e-01, 1.2200e+01]),
  5),
 (tensor([6.6000e+00, 3.8000e-01, 1.5000e-01, 4.6000e+00, 4.4000e-02, 2.5000e+01,
          7.8000e+01, 9.9310e-01, 3.1100e+00, 3.8000e-01, 1.0200e+01]),
  3)]


\end{lstlisting}
\end{minipage}

the train data loader is created with the following statement

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Train data loader for the Wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

train_dl = torch.utils.data.DataLoader(wine_train_list, batch_size=batch_size, shuffle=True)


\end{lstlisting}
\end{minipage}

we do something similar for the test data loader

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Test data loader}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## X_test.shape[0] -> 980

all_test_data = X_test.shape[0]

test_dl  = torch.utils.data.DataLoader(wine_test_list,  batch_size=all_test_data, shuffle=True)


\end{lstlisting}
\end{minipage}

Once the data is ready, we can proceed to define the architectures and train and evalaute our model. 

The architecture for the MLP is as follows. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP architecture for Wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## MLP

class MLP_Net(nn.Module):
    ## init the class
    def __init__(self, x_means, x_deviations):
        super().__init__()
        
        self.x_means      = x_means
        self.x_deviations = x_deviations
        
        self.linear1 = nn.Linear(11, 5)
        self.act1    = nn.ReLU()   ## nn.Sigmoid()
        self.linear2 = nn.Linear(5, 7)
        self.act2    = nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        
        
    ## perform inference
    def forward(self, x):
        
        ## x      = (x - self.x_means) / self.x_deviations
        
        x      = self.linear1(x)
        x      = self.act1(x)
        ## x      = self.dropout(x)
        x      = self.linear2(x)
        y_pred = self.act2(x)
        
        return y_pred
        


\end{lstlisting}
\end{minipage}

and the deep learning architecture can also be defined as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={DL architecture for the Wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## Deep Learning with 2 hidden layers

class DL_Net(nn.Module):
    
    def __init__(self, x_means, x_deviations):
        super().__init__()
        
        self.x_means      = x_means
        self.x_deviations = x_deviations
        
        self.linear1 = nn.Linear(11, 15)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(15, 9)
        self.act2    = nn.ReLU()
        self.linear3 = nn.Linear(9, 7)
        self.act3    = nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        
    ## perform inference
    def forward(self, x):
        
        x      = (x - self.x_means) / self.x_deviations
        
        x      = self.linear1(x)
        x      = self.act1(x)
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.dropout(x)
        x      = self.linear3(x)
        y_pred = self.act3(x)
        
        return y_pred


\end{lstlisting}
\end{minipage}

Finally, we proceed to train and evaluate our models. Let us first look at the MLP model

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP for Wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

model      = MLP_Net( x_means, x_deviations  )

opt        = torch.optim.Adam(    model.parameters(), lr=learning_rate )

## the y_test data can be integers and does not need to be one hot encoded with this function
loss_fn    = nn.CrossEntropyLoss( )   

training_loop(  N_Epochs, model, loss_fn, opt  )


\end{lstlisting}
\end{minipage}

the losses for the MLP look as follows

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={losses for MLP and Wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

0   loss= tensor(2.0045, grad_fn=<NllLossBackward0>)
50  loss= tensor(1.7409, grad_fn=<NllLossBackward0>)
100 loss= tensor(1.6410, grad_fn=<NllLossBackward0>)
150 loss= tensor(1.4973, grad_fn=<NllLossBackward0>)
200 loss= tensor(1.6076, grad_fn=<NllLossBackward0>)
250 loss= tensor(1.5390, grad_fn=<NllLossBackward0>)
300 loss= tensor(1.5283, grad_fn=<NllLossBackward0>)
350 loss= tensor(1.7964, grad_fn=<NllLossBackward0>)
400 loss= tensor(1.5162, grad_fn=<NllLossBackward0>)
450 loss= tensor(1.6949, grad_fn=<NllLossBackward0>)
500 loss= tensor(1.8356, grad_fn=<NllLossBackward0>)
550 loss= tensor(1.5983, grad_fn=<NllLossBackward0>)
600 loss= tensor(1.6706, grad_fn=<NllLossBackward0>)
650 loss= tensor(1.7059, grad_fn=<NllLossBackward0>)
700 loss= tensor(1.5805, grad_fn=<NllLossBackward0>)
750 loss= tensor(1.6615, grad_fn=<NllLossBackward0>)
800 loss= tensor(1.5225, grad_fn=<NllLossBackward0>)
850 loss= tensor(1.7477, grad_fn=<NllLossBackward0>)
900 loss= tensor(1.6259, grad_fn=<NllLossBackward0>)
950 loss= tensor(1.4791, grad_fn=<NllLossBackward0>)


\end{lstlisting}
\end{minipage}

From the losses, it can be seen that the  model has trouble training and learning. Let us verify this by running the model on the test set with the following code

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={MLP model on test set for the wine data}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

with torch.no_grad():
    for x_real, y_real in test_dl:
        y_pred = model(  x_real  )
        vals, indeces = torch.max( y_pred, dim=1  )
        preds = indeces
        print_metrics_function(y_real, preds)


\end{lstlisting}
\end{minipage}

Running the classification metrics we see that the model does not learn well. It is likely that the class imbalance is affecting performance. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Performance metrics for MLP and Wine}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

Accuracy: 0.52
Confusion Matrix:
[[  0   0   1   1   0   0]
 [  0   3  19   7   0   0]
 [  0   3 171 119   0   0]
 [  0   3  99 333   0   0]
 [  0   0   5 179   0   0]
 [  0   0   0  37   0   0]]
Precision: 0.402
Recall: 0.517
F1-measure: 0.445


\end{lstlisting}
\end{minipage}

we repeat the exercise with the DL architecture

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Train DL with the Wine data.}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

model      = DL_Net( x_means, x_deviations  )

opt        = torch.optim.Adam(    model.parameters(), lr=learning_rate )

## the y_test data can be integers and does not need to be one hot encoded with this function
loss_fn    = nn.CrossEntropyLoss( )   

training_loop(  N_Epochs, model, loss_fn, opt  )

with torch.no_grad():
    for x_real, y_real in test_dl:
        ## batch_size = imgs.shape[0]
        y_pred = model(  x_real  )
        vals, indeces = torch.max( y_pred, dim=1  )
        preds = indeces
        print_metrics_function(y_real, preds)


\end{lstlisting}
\end{minipage}

As can be seen below, the results are not good. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Performance metrics for DL and Wine}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

Accuracy: 0.52
Confusion Matrix:
[[  0   0   1   1   0   0]
 [  0   0  15  14   0   0]
 [  0   0 162 131   0   0]
 [  0   0  83 352   0   0]
 [  0   0   5 179   0   0]
 [  0   0   0  37   0   0]]
Precision: 0.401
Recall: 0.524
F1-measure: 0.445


\end{lstlisting}
\end{minipage}

So, that is it. That completes the Wine data discussion for this section. It seems to be a more challenging problem. I encourage the reader to try to improve the results. Consider trying the following:

\begin{itemize}
    \item Combining classes
    \item trying different architectures with deeper networks
    \item over-sampling or under-sampling the data
\end{itemize}






<h1>

Summary	
</h1>

	<p>

	In this chapter, the main topic of deep learning was introduced. The chapter addressed the PyTorch environment and code definitions as well 
		as theoretical concepts for deep learning. Issues about neural network architecture and performance evaluation were also presented. 
		Finally, several coding examples using python, Sklearn, numpy, and PyTorch were provided in an incremental fashion for the algorithms of 
		linear regression, logistic regression, 1-layer neural networks (MLP), and n-layer neural networks (Deep Learning). The next chapters will 
		\further look at other methods that can be implemented with PyTorch and, in particular, that are more advanced algorithms. 


	
	</p>













<h1>Masks</h1>

    <p>
Masks serve several purposes. One is to help ignore the padded values during training. The other goal is to block the given word you want to predict 
      or future words). This brings up the important aspect of training with Transformers. Transformers predict the last word in a sequence. For example:
    </p>
<p>

 Given an input in english: "the cat is sleeping"
 
</p>
	  
<p>
a Transformer is also given part of the output sentence. In this case:  "el gato esta ?". 
      The Transformer will predict the next word in the sequence which in this case would be "durmiendo" to complete the translation as “el gato esta durmiendo”. 
	All of this is achieved through the masks to ignore padded values and to only show the partial sentence. 
  
    </p>


<h1>
Positional Encoding
  
</h1>

<p>

  This is the technique that allows you to encode sequence. Transformers are all about being parallel. Their direct competitor is Recurrent Neural Networks (RNNs).
  RNNs have had several problems in the past. One is that they do not scale well to GPUs and parallel approaches because of their recurrence and dependence on previous
  steps. The other problem is the famous "vanishing gradients" problem which was addressed by by residuals and LSTMs seem to have addressed this now.  Transformers did
  away with the type of sequence modeling approach used in RNNs all together so they are very good for parallel approaches. But how do they address or encode the sequence? 
  Obviously knowing that the word "cat" goes before the word "sleeping" is useful. This is where a technique called positional encoding comes into play. Basically, after 
  embedding, you have a vector per token of, say, size 512. 

Now, with positional encoding, a function that calculates sines and cosines, is used to create a new vector also of size 512 that represents position (i.e. sequence) of 
  the tokens. The 2 vectors are added together (embedding + positional_encoding) to get the new inputs to the network. Also, the position vector values are smaller than
  the embedding vector values so as to not let position dominate. 

</p>

 

<h1>
Tokens
</h1>
    
<p>

  In a GPT we want to predict the next word given previous words. However, to improve performance, transformer models do not predict the next word. Instead, they 
  predict the next subword. A good analogy for subword is syllable, although transformer do not use syllables either. The subwords are calculated based on specific 
  algorithm such as BPE or SentencePiece. This allows transformers to learn to generate new words never seen before. For example, it may have seen 
<br/>
The dog is play - ing.
<br/>
And by breaking the word into subwords (i.e. play and ing), it can learn to generate new variations of words it never saw before such as
<br/>
The lady is iphone - ing.
<br/>
We and the Transformer know intuitively what this means.
<br/>
The fact is that tokens can be words, syllables, subwords, letters, etc. Subwords through SentencePiece type algorithms just have proven to give the best results. 

</p>

<h1>

Inputs and Outputs
  
</h1>

<p>
    
So, let us start there. Let's quickly remember our classic example of MNIST supervised classification. In MNIST standard feed forward classification, you have an 
  input image which is 28x28 and a predicted vector of size 10 for the classes. So, what do the inputs and outputs look like for transformers? For language translation, 
  they are lists of ids. Each id can represent a word in a sentence. This is best visualized with an example. 
First, let us look at the classic use case for Transformers. As I said earlier, Transformers have been used extensibly in NLP. And the first example was in language 
  translation where we have sentence pairs. Such as the following for English-Spanish translation:
<br/>
"the cat is sleeping"    -->   which translates to   -- >    "el gato esta durmiendo"
<br/>
Therefore, first we need to understand how to encode this for the neural network and then to understand how exactly it is that the network will train and learn. 
  So, again, before you look into the network's very deep and complex layers, I believe that one needs to  focus on:

  
</p>

	  <p>
    <ul>
    <li> Padding these sequences of ids</li>
    <li> Taking text sentences and converting them into sequences of ids</li>   
    </ul>
	  </p>
   



 <p>

   Consider that after encoding and padding, your sentences will look like this:

 </p>








<p>

	and for the other language


</p>
   






<p>
GPTs stand for Generative Pre-trained Transformers. The GPT uses the decoder only part of the Transformer. The input to the decoder varies based on whether you are 
	training or predicting. If you are training, the input to the decoder is the sentence itself. When training, a mask is needed here to prevent the model from 
	seeing all the words it is trying to predict. This is called a look ahead mask.
If you are testing, the input is just the previous words before the word you are trying to predict. You start with a start of sentence token (e.g. <sos>) and predict. 
	The predicted word is then added to the previous tokens and the process is repeated.
The decoder consists of N (e.g. 6) decoder layers, followed by a fully connected layer.

The full architecture of the decoder can be seen in the following figure. 

	
</p>



  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/full_decoder_gpt.png" height="800" width="auto">
      </div>

    </center>

<p>
Each decoder layer consists of a decoder multi-head attention layer, followed by a fully connected layer. The attention layers consist of m_heads (e.g. 8) parallel 
	attention sub layers that are later concatenated. The numbers 6 and 8 are a choice the architect makes.

	
</p>


<h1>

	Teacher Forcing
</h1>
	  
<p>
You may have already read somewhere (on-line) that the Decoder in the Transformer network predicts one word at a time and that that word is read back as an input in the 
	next iteration. Also, the network predicts the last word in the sequence of words. But you may think, aren't those last words just padding? Eh? So, what is going on 
	here? As it turns out, the mechanism of predicting one word at a time and feeding it back as an input in the next iteration is only done during the "testing"
	phase and it is not done during "training". Instead, during "training" of a decoder we use “Teacher Forcing”.
Teacher forcing is a technique in auto regressive models where you do not use the predicted outputs of the decoder to feed back as input but instead you use the real data. 
	This helps the model to learn the correct information instead of its own erroneous predictions (especially at the beginning of training).
</p>

	  <h1>
Implementing a GPT in PyTorch from Scratch
		  
	  </h1>

	  <p>
In this section,  I will implement a simple GPT using everything we have learned in this book. The code will be very object oriented for efficiency. That being said, 
	this GPT is implemented from scratch, works really well, and can be scaled. Thanks to Andrej Karpathy for helping me to better understand the PyTorch 
		  implementation of a GPT (<a href="https://karpathy.ai">Andrej Karpathy</a>).

For the sake of simplicity I will not use subwords here and instead just use the letters of the English alphabet and a few symbols. The vocabulary of a large GPT such as
	GPT-4 could be hundreds of thousands of subwords or more. This GPT reads in one text file and trains on it. 

<br/>
Here, we first input our common python libraries.  

	
</p>


<center>
<div>
<textarea rows="8" cols="40">

import torch
import numpy as np
import torch.nn as nn

from torch.nn import functional as F
  
</textarea>
</div>
  </center>


<p>

	In the following code segment we can set the parameters as we have done before.

</p>
	


<center>
<div>
<textarea rows="20" cols="70">


torch.manual_seed(256)
device = 'cuda' if torch.cuda.is_available() else 'cpu'

block_size        = 40      ## N tokens in sequence
batch_size        = 64 
max_iters         = 6000
eval_interval     = 500     
learning_rate     = 0.0003
eval_iters        = 300
vocab_size        = 65

## every id for a given token is embedded to vector of this size
n_embd            = 512                  
n_head            = 8         ## 8 attention heads
n_layer           = 6         ## 6 eoncoder layers
dropout           = 0.2
  
</textarea>
</div>
    </center>

      
<p>

Now we proceed to read the text data to train on. 

	
</p>



<center>
<div>
<textarea rows="10" cols="80">


text = ''

input_file2 = 'AdventureHuckFinn.txt'

with open(input_file2, 'r', encoding='utf-8') as f:
    text = f.read()
  
</textarea>
  
</div>
    </center>

<p>
After reading the text file, we can look at the information about it with the following code. 

	
</p>




<center>
<div>
<textarea rows="8" cols="80">

print("length of data in letter or characters")
len(text)

list(set(text))
  
</textarea>
  
</div>
 </center>



  <p>
With the previous code we can look at the length of the text and type of characters. The length of data in letters or characters is 2,365,132, for instance. 
	  The characters can be seen in the next code listing. 


	  
  </p>





<center>
<div>
<textarea rows="10" cols="130">


['u', 'v', 'W', "'", '$', 'I', 'Q', 'L', ',', 'Y', 'w', 'D', 'e', 'P', 'h', 'z', 'F', 'n', 'l', 'T', '-', 'q',
 '&', 'p', '3', 'r', 'j', 'X', '!', 's', 'A', 'H', '\n', 'O', '.', ':', 'S', 'K', 'C', 'N', 'E', 'Z', ' ', 'd', 
 'y', 'x', 'c', 'f', ';', '?', 'B', 'g', 'o', 'G', 'V', 'R', 't', 'i', 'm', 'M', 'k', 'b', 'a', 'U', 'J']

 
</textarea>
  
</div>
    </center>


<p>
With the following code we can calculate the size of the vocabulary which is 65 and can print the tokens as a string. 

		
</p>


  
<center>
<div>
<textarea rows="15" cols="100">

the_chars  = sorted(     list(set(text))     )

vocab_size = len( the_chars )      ## 65

print(  len(the_chars)  )

print(  ''.join(the_chars)  )

## The printed oputput
## !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz

 
  
</textarea>
</div>
    </center>

<p>
The tokens need to be converted into IDs. We can use a dictionary and reverse dictionary for this like so. This was previously shown in the word2vec code description. 
	These are called the tokenizer. 
	
</p>


 
<center>
<div>
<textarea rows="5" cols="60">

   stoi = { ch:i for i, ch in enumerate(the_chars) }
   itos = { i:ch for i, ch in enumerate(the_chars) }
  
</textarea>
  
</div>
</center>
  

<p>
We can now print the dictionary (string to int ) and reverse dictionary (int to string). 	
</p>



<center>
<div>
<textarea rows="5" cols="60">

print( stoi )
print( itos )
  
</textarea>
  
</div>
</center>

<p>
The string to int dictionary will give us	
</p>



<center>
<div>
<textarea rows="30" cols="85">


{'\n': 0,
 ' ': 1,
 '!': 2,
 '$': 3,
 '&': 4,
 "'": 5,
 ',': 6,
 '-': 7,
 '.': 8,
 '3': 9,
 ':': 10,
 ';': 11,
 '?': 12,
 'A': 13,
 'B': 14,
 'C': 15,
 'D': 16,
 'E': 17,
 ...
 }

</textarea>
  
</div>
    </center>
  

<p>
and the int to string dictionary will give us

	
</p>



<center>
<div>
<textarea rows="30" cols="85">


{0: '\n',
 1: ' ',
 2: '!',
 3: '$',
 4: '&',
 5: "'",
 6: ',',
 7: '-',
 8: '.',
 9: '3',
 10: ':',
 11: ';',
 12: '?',
 13: 'A',
 14: 'B',
 15: 'C',
 16: 'D',
 17: 'E',
 ...
 }

  
</textarea>
  
</div>
    </center>
  

<p>

	
Now we need to define an encoding tokenizer called "encode" so we can convert string to integer.

</p>



<center>
<div>
<textarea rows="5" cols="100">

encode = lambda s: [ stoi[c]          for c in s   ] 

encode("bahh")


</textarea>
  
</div>
    </center>
  

<p>
Encoding from the sheep language "bahh" with the tokenizer encoder gives [40, 39, 46, 46].
<br/>
We do the same for the tokenizer decode to decoder from integer to strings as follows: 

	
</p>


<center>
<div>
<textarea rows="5" cols="100">

decode = lambda l: ''.join(   itos[i] for i in l   )    

decode([40, 39, 46, 46])


</textarea>
  
</div>
    </center>



<p>
Using the function decode([40, 39, 46, 46]) gives us our sheep tokens back which are  'bahh'.

Now we need to encode the text from our book and convert it to a Torch tensor. The code for that is as follows: 

	
</p>




   <center>
<div>
<textarea rows="10" cols="100">


data = torch.tensor(   encode(text), dtype=torch.long   )

print( data )

  
</textarea>
  
</div>
    </center>
  
<p>

Printing the encoded data in the Torch tensor gives us:  
<br/>
<br/>
tensor([18, 47, 56,  ..., 45,  8,  0])
<br/>
<br/>

We now proceed to split the data into train and text. We do that next by slicing the data torch tensor with $ n $.

	
</p>



<center>
<div>
<textarea rows="10" cols="100">

n          = int(   0.9*len(data)   )

train_data = data[:n]
val_data   = data[n:]

  
</textarea>
  
</div>
    </center>

  
<p>
The next step is to create a function to read the data so we can train the GPT. We will use a function to get the data in batches. The code can be seen in the
	  next code listing.


	
</p>



<center>
<div>
<textarea rows="20" cols="100">

def get_batch(split):
    if split == "train":
        data = train_data
    else:
        data = val_data
        
    ix = torch.randint(   len(data) - block_size, (batch_size,)   )
    
    x  = torch.stack(    [  data[   i : i+block_size ]     for i in ix ]    ) 
    y  = torch.stack(    [  data[ i+1 : i+1+block_size ]   for i in ix ]    )
    
    x, y = x.to(device), y.to(device)

    return x, y

  
</textarea>
</div>
    </center>

  <p>

To better understand the previous function, I will create a simple example with smaller values for the batch size and the M\_tokens parameter. 
	  This will help to illustrate what is going on on this function. 
<br/>
A GPT is a very deep neural network. To train it you need inputs ( "x" ) and outputs ( "y" ).  Inputs and outputs are matrices of the
	  same size [batch_size, N_tokens]. They are basically several sentences as rows (batch_size) with N_tokens (i.e. 40) as columns for each sentence.  
<br/>
The same sentence is selected for "x" and "y" . They are the same sentence but "y" is shifted by one from "x".
<br/>
For our example, we can slice batches of 4 with a sentence sequence length of 16. The torch.randint function helps us to select random starting points for the 4 sentences
	  from the text. Printing the variable "ix" from the code below gives us the following 4 starting points in the text. 
<br/>
tensor([   213173, 989153, 193174, 874116   ])

	  
  </p>




    <center>
<div>
<textarea rows="15" cols="100">


temp_batch_size = 4
temp_block_size = 16

## select random starting points for the 4 sentences
ix = torch.randint(   
            len(data) - block_size, 
            (temp_batch_size,)   
)

print( ix )

  
</textarea>
  
</div>
</center>




<p>
Given the four index position (13173, 989153, 193174, 874116), we can see what Tokenizer IDs are stored there with the following code listing. The "for" loop gives us: 
<br/>
tensor(59), tensor(43), tensor(58), tensor(17)



	
</p>








    <center>
<div>
<textarea rows="5" cols="100">


for index_temp in ix:
    print(  data[index_temp]  )



</textarea>
  
</div>
    </center>



<p>

Now with these 4 index positions we can proceed to slice out the four sentences of size 16 from the torch data tensor. Remember that we hold IDs for the tokens and not 
	the actual letter in this tensor. This gives us 4 pairs of (x, y). Notice that "y" is shfted by one from "x". 

  
	
</p>




<center>
<div>
<textarea rows="15" cols="100">

x  = torch.stack(    
    [ data[   i : i+  temp_block_size ]   for i in ix ] 
    
) 

y  = torch.stack(    
    [ data[ i+1 : i+1+ temp_block_size ]  for i in ix ]    
)

print(x)
print(y)
  

  
</textarea>
  
</div>
    </center>
  


<p>

Printing "x"and "y" gives us our "x" batch of size [4, 16] and our shifted "y" batch of size [4, 16] as can be seen below.
	
</p>





 


<p>


And that is how you get and process the data to train a GPT. This is sometimes called data wrangling. More detail about data wrangling is provided later in the chapter.

Now we proceed to define the loss function. In this function we evaluate the model by predicting and comparing the predictions to the real values. The difference is the 
	loss as can be seen below. 


	
</p>







  <center>
<div>
<textarea rows="20" cols="100">


@torch.no_grad()    ## for efficient processing
def estimate_loss():
    out = {}
    model.eval()   ## set to no training
    for split in ['train', 'val']:
        losses = torch.zeros(eval_iters)
        for k in range(eval_iters):
            X, Y = get_batch(split)
            logits, loss = model(X, Y)
            losses[k] = loss.item()
        out[split] = losses.mean()
    model.train()  ## back to training
    return out


  
</textarea>
  
</div>
    </center>
  


<p>




I will now proceed to describe the architecture of the decoder (GPT). 


	
</p>




<h1>
Architecture of the GPT or Decoder
	
</h1>
	  
<p>
As can be seen in the following figure, the decoder starts with inputs that go in sequentially into N (e.g. 6) decoder layers, and then a feed forward layer to predict 
	the logit for the given token in the vocabulary. Each decoder layer has the exact same architecture and consists of multi-head attention layers, feed forward layers, 
	and performance improvement steps such as batch normalizations, residuals, dropouts, etc. Remember that the encoder is not used for the GPT.


</p>


  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/full_decoder_gpt.png" height="700" width="auto">
      </div>

    </center>
	  

<p>

In the following code segment we can see the class to instantiate the whole decoder with all 6 decoder layers and the last feed forward layer. 

	
</p>


  <center>
<div>
<textarea rows="30" cols="130">


class GPTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]
        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]
        
        self.blocks = nn.Sequential(
                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]
        )
        
        self.ln_f    = nn.LayerNorm(  n_embd    )        
        self.lm_ffw_head = nn.Linear(n_embd, vocab_size)  ## [512, 65] # FFW Layer
        
    def forward(self, idx, targets=None):
        B, T = idx.shape     ## (Batch, 40)
        ## ids and targets are both (B, T) tensors of integers
        
        tok_emb = self.token_embedding_table(idx)      
        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  
        
        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]

        ## This is the architecture
        x = self.blocks(  x  )   ## (B, T, E)        
        x = self.ln_f(    x  )   ## (B, T, E)   ## norm
        logits = self.lm_ffw_head(x)         ## [B, 40, 65] 
        
        if targets is None:
            loss = None
        else:
            B, T, E  = logits.shape
            logits  = logits.view( B*T, E)
            targets = targets.view(B*T)
            loss    = F.cross_entropy(logits, targets)
        return logits, loss
        
    def generate(self, idx, max_new_tokens):    ## idx is (B, T)
        for _ in range(max_new_tokens):
            ## crop idx to the last block_size tokens
            idx_cond = idx[:, -block_size:]
            logits, loss = self(idx_cond)    ## ## get preds
            logits = logits[:, -1, :]    ## focus on last one (B, E)
            probs = F.softmax(logits, dim= -1)    ## (B, E) get probs
            idx_next = torch.multinomial(probs, num_samples=1)     ## (B, 1) selected
            idx = torch.cat(  (idx, idx_next), dim=1  )   ## (B, T+1) append sample to running sequence
        return idx
            

  

  
</textarea>
  
</div>
    </center>
  

<p>
The GPTmodel class consists of 3 functions. They are init, forward, and generate. We initialize the embedding and positional encoding object in init. 

The following code is what instantiates the 6 decoder layers in sequence where the outputs from one decoder layer become the inputs of another decoder layer. 



	
</p>



  <center>
<div>
<textarea rows="6" cols="100">

self.blocks = nn.Sequential(
                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]
        )


</textarea>
  
</div>
    </center>


  


<p>

The final 2 lines of code in the init function define a normalization and the feed forward layer to predict the logits (i.e. the tokens).
<br/>
The second function is the forward funtion which is where we actually define the architecture from inputs to outputs through the entire deep neural network of the decoder.
<br/>
First we take "idx" (the data as ids) an pass it through the embedding layer. This gives us "tok_emb". Remember that the token embedding are learned by 
	Transformers during the training. After that we create the positional encoding table. The encoded "tok_emb" does not go through this object. 
	Instead "pos_emb" is added to "tok_emb". Sequence was established when "pos_emb" was instantiated. Adding them gives us "x" which
	goes into  the main architecture as can be seen below


	
</p>






<center>
<div>
<textarea rows="7" cols="100">


x      = self.blocks(  x  )      ## (B, T, E)        
x      = self.ln_f(    x  )      ## (B, T, E)   norm
logits = self.lm_ffw_head(x)     ## [B, 40, 65] 


</textarea>
  
</div>
    </center>



<p>
Finally, the generate function invokes the model defined through forward to generate text auto-regressively. 
<br/>
The GPTmodel class used a Block class to define the the decoder layers. We can now define that class. Block needs "n_embd" which is the embedding
	dimension (e.g. 512), and "n_head" which is the number of Attention heads we will use (e.g. 8). We need to 
	calculate the "head_size" by dividing "n_embd" by "n_head". For our example this should be

</p>
	<center>
<p>

 64 = 512 / 8 
		
	</p>
	</center>
	
<p>

Here it might help to look at a diagram of the decoder layer.


	
</p>
	


 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/Decoder_Layer_gpt.png" height="700" width="auto">
      </div>

    </center>


<p>

As can be seen we need a Multi-Head Attention layer followed by a FeedForward layer. Two normalizations (ln1, ln2) can also be performed. 
	
</p>



  
<center>
<div>
<textarea rows="20" cols="100">


class Block(nn.Module):
    
    def __init__(self, n_embd, n_head):     ## (512, 8)
        super().__init__()
        head_size = n_embd // n_head        ## 64
        self.sa   = MultiHeadAttention(n_head, head_size)
        self.ffwd = FeedForward( n_embd)    ## 512
        self.ln1  = nn.LayerNorm(n_embd)
        self.ln2  = nn.LayerNorm(n_embd)
        
    def forward(self, x):
        x = x + self.sa(     self.ln1(x)      )
        x = x + self.ffwd(   self.ln2(x)      )
        return x

  
</textarea>
  
</div>
    </center>
  




<p>

The Block class uses 2 more classes which are Multi-Head Attention and FeedForward. We can now proceed to define these. 
<br/>
We can first define the Multi-Head class as follows


	
</p>




 


<center>
<div>
<textarea rows="16" cols="100">


class MultiHeadAttention(nn.Module):

    def __init__(self, num_heads, head_size):    ## (8, 64)
        super().__init__()
        self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )
        self.proj  = nn.Linear(n_embd, n_embd)   ## 512, 512
        self.dropout = nn.Dropout(dropout)
    
    def forward(self, x):
        out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )
        out = self.proj(  out   )
        out = self.dropout(   out   )
        return out

  
</textarea>
  
</div>
    </center>




<p>


The Masked multi-head attention layer is done N\_head times (e.g. 8) in parallel and the results are concatenated. This concatenated result is added to the original 
	after mapping it through one more layer and a Residual can also be used.

The 2 key aspects are the instantiation of 8 heads which are parallel and independent of each other using "nn.ModuleList"as can be seen in the next code listing



	
</p>






   <center>
<div>
<textarea rows="6" cols="100">


self.heads = nn.ModuleList(  [ Head(head_size) for _ in range(num_heads) ] )


</textarea>
  
</div>
    </center>
  


<p>

and the concatenation of the 8 head Heads of size 64 to create a new tensor of size 512 ( 64 * 8 = 512).


	
</p>




 


   <center>
<div>
<textarea rows="4" cols="100">

out = torch.cat(   [ h(x) for h in self.heads ], dim = -1   )

</textarea>
  
</div>
    </center>


<p>

	
The FeedForward class is very straight forward  as can be seen below. It is a simple linear layer followed by a non-linearity. 



</p>









<p>

Finally, the Multi-Head Attention class use the Head class where the Attention mechanism is defined. The  next code segment is probably the most important in
	terms of the power of Transformers. It defines the Attention layer. Here we define the Attention Head class. 

 

	
</p>




    <center>
<div>
<textarea rows="30" cols="100">


class Head(nn.Module):

    def __init__(self, head_size):
        super().__init__()
        
        self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
        self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
        self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]

        tril_def = torch.tril( torch.ones(block_size, block_size) )  ## [40, 40]
        
        self.register_buffer(
                  'tril', 
                  tril_def
               )
        
        self.dropout = nn.Dropout(dropout)

    def forward(self, x):
        
        B, T, E = x.shape   ## [batch_size, 40, 512]
        
        k = self.key(   x )            ## k = (B, T, 64)
        q = self.query( x )            ## q = (B, T, 64)

        E2 = 64     ## I think this is 64 and not 512
        ## (B, T, E) @ (B, E, T)  -> (B, T, T)
        wei = q @ k.transpose(-2, -1) * E2 ** -0.5        
        
        wei = wei.masked_fill(
                      self.tril[:T, :T] == 0, 
                      float('-inf')
        )   
        
        ## (B, T, T)
        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
        wei = self.dropout(   wei   )
        
        ## perform weighted aggregation of values
        
        v   = self.value(  x  )   ## x = (B, 40, E)
        out = wei @ v             ## (B, T, T) @ (B, T, 64) -> (B, T, 64)
        
        return out
  

  
</textarea>
  
</div>
    </center>






   <center>
<div>
<textarea rows="4" cols="100">

self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))

</textarea>
  
</div>
    </center>


<p>


The Attention mechanism uses K, Q, and V to compute the Attention scores. The values are computed from the original "x" input. The intuition is that the sentence 
	is compared with itself and that is why the comparison or scores matrix will result in size [N_tokens, N_tokens] (e.g. [40, 40]). This is accomplished with 
	the following code:

	
</p>




<center>
<div>
<textarea rows="7" cols="100">


self.key   = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
self.query = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]
self.value = nn.Linear(n_embd, head_size, bias=False)  ## [512, 64]


</textarea>
  
</div>
    </center>
  


<p>


The input "x" is of size [N, 40, 512] and the "look_ahead_mask" is of size [N_batches, 40, 40].


Remember that using "nn.Linear" is equivalent to the following:


	
</p>






  
     <center>
<div>
<textarea rows="17" cols="100">


## (B, T, 64) @ (B, E, 64)  -> (B, T, T)

wei = q @ k.transpose(-2, -1) * E ** -0.5        
        
wei = wei.masked_fill(
        self.tril[:T, :T] == 0, 
        float('-inf')
)   
        
## (B, T, T)
wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
wei = self.dropout(   wei   )


</textarea>
  
</div>
    </center>

  

<p>

The variable "wei" is computed by a nn.matmul between Q and the transpose of K like so
<br/>
<br/>
    wei = nn.matmul( Q, K, transpose_b=True) 
<br/>
<br/>
	
This nn.matmul results in a matrix of size  [N, 40, 40]. We then divide "wei" by 
<br/>
<br/>
    sqrt(  Embd_size  )        
<br/>
<br/>
	
where Embd_size is equal to 64 (i.e. E ** -0.5). At this point "wei" continues to be of size [N, 40, 40].

The following code segment adds "wei" to the Mask. 


	
</p>






      <center>
<div>
<textarea rows="8" cols="80">

wei = wei.masked_fill(
        self.tril[:T, :T] == 0, 
        float('-inf')
)
  
</textarea>
  
</div>
</center>


<p>


The "look_ahead_mask" is of size [N, 40, 40]. This should be an addition of [N, 40, 40] + [N, 40, 40]. Notice that the wei.masked_fill function
	makes use on an infinity parameter. A simplified view of this operation is as follows:

<br/>
    wei = wei + (look_ahead_mask * -1e9)
<br/>


The final part of the forward function in the Head class (next code segment) finishes the Attention computation. The softmax is used to normalize on 
	the last axis so that the scores add up to 1 (axis -1 is for last dimension in the tensor). 


	
</p> 
        



  

<center>
<div>
<textarea rows="20" cols="100">


class Head(nn.Module):

    ...

    def forward(self, x):
        
        ...
        
        ## (B, T, T)
        wei = F.softmax( wei, dim= -1 )         ## (B, T, T)
        wei = self.dropout(   wei   )
        
        ## perform weighted aggregation 
        
        v   = self.value(  x  )   ## (B, T, E)
        out = wei @ v             ## (B, 40, 40) @ (B, 40, 64) -> (B, 40, 64)
        
        return out

  
</textarea>
  
</div>
    </center>



<p>
   

Finally, the following operation is performed which result in a tensor of size [N, 40, 64]. Remember that 8 of these Head output tensors will be concatenated to return 
	to the original size of [N, 40, 512] (64 * 8 = 512). 


	<br/>
For example, the  softmax ( torch.nn.softmax(a7) ) for “a” defined as follows:
<br/>
	<br/>
a7 = torch.constant([0.6, 0.2, 0.3, 0.4, 0, 0, 0, 0, 0, 0]) 
 <br/>
	<br/>
gives the following

	
</p>
        

  
<center>
<div>
<textarea rows="8" cols="100">


<torch.Tensor: shape=(10,), dtype=float32, numpy=
array([0.15330984, 0.10276665, 0.11357471, 0.12551947, 0.08413821,
0.08413821, 0.08413821, 0.08413821, 0.08413821, 0.08413821], dtype=float32)>


</textarea>
</div>
</center>



<p>

now, if some of the values are negative infinities
<br/>
	<br/>
b7 = torch.constant([0.6, 0.2, 0.3, 0.4, -1e9, -1e9, -1e9, -1e9, -1e9, -1e9])
<br/>
	<br/>
then the softmax operation on b7 (torch.nn.softmax(b7)) should give us
<br/>

	
  
</div>
    </center>




 <p>


Notice the infinities are now zeros! 

<br/>
The decoder has a final linear layer after the 6 decoder_layer functions. The final layer in the decoder is the decoder_final_layer. This is a linear layer with 
	 no non-linearities and a softmax that maps the tensor [N, 40, 512] to a tensor of size [N, 40, n_vocab_size].

And that covers all the classes of the NN architecture. We are now ready to instantiate the GPT and call the core functions for the optimizer, etc. like so:

	 
 </p>




<p>
The training function is presented below and is straight forward

	
</p>





        <center>
<div>
<textarea rows="18" cols="100">

for iter in range(max_iters):
    
    if iter % eval_interval == 0:
        losses = estimate_loss()
        print(f"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}")

    xb, yb = get_batch('train')
    
    ## eval the loss
    logits, loss = m(xb, yb)
    
    optimizer.zero_grad(set_to_none=True)   ## zero out
    loss.backward()
    optimizer.step()
  

</textarea>
  
</div>
    </center>



<p>

Now, regenerate after some training


	
</p>





          <center>
<div>
<textarea rows="10" cols="100">

## Starting token  id_sos = 0
sos_context = torch.zeros(  (1, 1),  dtype=torch.long, device=device   )   

generated_text = m.generate(sos_context, max_new_tokens=500)[0].tolist()

print(  decode(generated_text)   )


</textarea>
  
</div>
    </center>




<p>
Using the generate function gives GPT generated text. 

Obviously, the amount of data will determine the quality of a GPT and it can take a lot of money and time to properly train a GPT. 
	The following are examples of generated text using just single books or scripts. 
<br/>
For South Park training data we can get
	
</p>



  
<center>
<div>
<textarea rows="20" cols="100">


Mr. Hankey: Who, don't look it, but looks like you have thrown them.
These chees. 
Stan: Now back a friend people.me. 
Kenny: (HA f!) 
Stan: The new bestsays to expon is weep thing the beny first they wan
t
Stan: Thank you.
Kyle: His realet! Stan, co musb me friends Vagisil magine?
Stan: Nat Just sind out hurt. Hallway gaves millions? Are Me: Preest
y revitalizing there?
Stan: D'RCRANNSSEA.
Stan: What?
Stan: Dammit!
Cartman: If anyone cools orget and have meet hundestly kids he since


  
</textarea>
  
</div>
    </center>



<p>

For Harry Potter training data we can get

	
</p>



 


<center>
<div>
<textarea rows="20" cols="100">


HARRY: What is saying that Time-Turner, ghe dangerous
and gentlemen —
GINNY: And is Albus Scorpius about to ldemborn King. And
we should be very moths die. He means the
rumble. It feels the appos his and forcement.
HARRY: Get out out of the train is and for the
Ministry had of fist or your pament.
DRACO: Wh, does it say?
HARRY: You came?
RON enters on a baccused by through through,
finality. It is it can’t better but Padma sets in for
one champions and to be to reface the Boy — she
speak.
HARRY: Year the rumors?
PROFESSOR McGONAGALL: I came it extraord the might be
minty Iave progice to your paplay — then your
nose? (She fining, an is hurts.) I, am Dad.
Sound that . . . weld your have beyou’ve gone?
SCORPIUS is saying in his roommount. What she
falls talking about the blanked than I had a son.
ALBUS: I’ll give to you that strave to do with my
died it son. And my for you because it fly. And
you schoolow how Harried in Potion
  

  
</textarea>
  
</div>
    </center>




<p>

And that concludes the discussion on GPTs.
	
</p>








	<h1>
Encoder Only Models
		
	</h1>

<p>
The encoder has 6 sub-layers called encoder layers. Each encoding layer has a Multi-Head Attention layer followed by a standard fully connected feed forward layer. 
	The input to the encoder goes through all these layers in the encoder and it is converted into an encoder output. The input to the encoder and the output of 
	the encoder have the same dimensions. For instance, here, the input to the encoder would be the English sentence. 

The attention layer consists of 8 parallel Attention sub layers that are later concatenated. The intuition is that each of these 8 layers can learn something new and 
	different. So this gives more capacity to the network. The input to the encoder goes through all these layers in the encoder and is converted into an encoder output. 

The next code segment shows the standard encoder architecture code. Notice it is almost exactly like the GPT (decoder) code. The only difference is in the last layer.
	The pure Encoder does not need to predict words. Instead, it takes sentences and converts them to embeddings. In this case of size [B, 40, 512]. 


	
</p>




<center>
<div>
<textarea rows="24" cols="100">


class Encoder_Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   ## [65, 512]
        self.pos_emb_table = nn.Embedding(block_size, n_embd)     ## [block, 512]
        
        self.blocks = nn.Sequential(
                *[   Block(n_embd, n_head=n_head) for _ in range(n_layer)    ]
        )
        
        self.ln_f    = nn.LayerNorm(  n_embd    )        
        
        
    def forward(self, idx, targets=None):
        B, T = idx.shape     ## (Batch, 40)
        ## ids and targets are both (B, T) tensors of integers
        
        tok_emb = self.token_embedding_table(idx)      
        pos_emb = self.pos_emb_table(torch.arange(T, device=device))  
        
        x = tok_emb + pos_emb    ## [B, T, E] or [64, 40, 512]

        ## This is the architecture
        x = self.blocks(  x  )   ## (B, T, E)        
        x = self.ln_f(    x  )   ## (B, T, E)   ## [B, 40, 512]




  
</textarea>
  
</div>
    </center>


<p>
Notice that 6 identical encoder layers are created were the outputs of one become the inputs of the next layer. The dimensions of all inputs and output at this 
	stage are the same [B, 40, 512] where B is batch size.  The input is  a batch of "B" sentences, with 40 tokens per each sentence, and where 512 is 
	each id that has been embedded to a vector of size 512. Remember that the embedding vectors of size 512 are learned by the model so initially they are random data. 

We use a padding mask to ignore tokens with 0 value (i.e. padding).


BERTs are based on the encoder part of the original Transformer,  and are encoder only Transformers.

	
</p>
	
<h1>

	BERT
</h1>


<p>

BERT is an example of an encoder-only Transformer. In contrast to pure Encoders that take a sentence and only produce an embedding (e.g. [B, 40, 512]), BERT 
	models will add neural network layers (called heads) after the embedding (e.g. [B, 40, 512]) to convert those embeddings into words or sentences. 

BERT stands for Bidirectional Encoder Representations from Transformers. They were trained using 2 approaches. 

	
</p>

	

   <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/BERT_final_masking.png" height="900" width="auto">
      </div>

    </center>
  

<p>
The approaches are:
	
</p>


<ul>
<li>Masked language task training</li>
<li>Two sentence task training</li>
	
</ul>


	<p>

The first task BERT was pre-trained on was the Masked Language modeling approach. This approach is summarized in the previous figure. Here the BERT model 
		receives the same sentence as input and output. Some tokens are masked and the model needs to learn to predict those masked tokens during the training process. 

The second task BERT was pre-trained on is a 2 sentence classification task. The figure below summarizes this approach. Basically, here, 2 sentences are given to the BERT
		model as input. The model trains to predict if these 2 input sentences are sequential whcih means they are also related, or if they are not sequential and, 
		therefore, unrelated. 

BERT was originally developed by Google and there have now been several other versions that were developed. They all follow the simliar naming convention of being
		called RoBERTa, AlBERT, DistilBERT, etc.


		
	</p>



  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/BERT_final_masking.png" height="900" width="auto">
      </div>

    </center>
	<br/>
	<br/>

	<h1>
Encoder Decoder Transformers
		
	</h1>
<p>

In this section, I will discuss the first version of the Transformer first made popular in the paper “Attention Is All You Need” by Vaswani et al. 
	They were first used for language translation. The Encoder Decoder with Multi Head Attention Transformer is a very deep network.  
The architecture has an encoder followed by a decoder. 

The decoder layer has 2 inputs. One input is the encoder output. The second input to the decoder varies based on whether you are training or predicting. 
	If you are training, the input to the decoder is the sentence in the other language. For instance, the Spanish sentence. In the decoder, when training the 
	Transformer, a mask is needed to prevent the model from seeing all the words it is trying to predict. This is called a look ahead mask. 

If you are testing, the input to the decoder is just the previous words before the word you are trying to predict. You start with a start of sentence token (e.g. <sos>)
	and predict iteratively. The predicted word is then added to the previous tokens and the process is repeated. 

In the Encoder Decoder Transformer (for the language translation problem),  the decoder layer has 2 inputs. One input is the encoder output. The second input to the 
	decoder varies based on whether you are training or predicting. If you are training, the input to the decoder is the sentence in the other language. For instance, 
	the Portuguese or Spanish sentence. When training, a mask is needed here to prevent the model from seeing all the words it is trying to predict. This is called a 
	look ahead mask. 


If you are testing, the input is just the previous words before the word you are trying to predict. You start with a start of sentence token (e.g. <sos>) and predict. 
	The predicted word is then added to the previous tokens and the process is repeated. The decoder consists of 6 decoder layers, followed by a linear layer. 
	Each decoder layer has a decoder multi-head attention layer, followed by a decoder-encoder attention layer, and a fully connected layer. 
	The decoder architecture for the Encoder Decoder Transformer (for the language translation problem) can be seen in the following figure.

	
</p>

 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/decoder_layer.300dpi_lang_model.jpg" height="700" width="auto">
      </div>

    </center>
  

<p>
The attention layers consist of 8 parallel attention sub layers that are later concatenated. The numbers 6 and 8 are a choice the architect makes.
The first code segment in this section describes the decoder’s overall architecture. The decoder has more inputs than the encoder. 

The decoder_layer is the busiest function of the Transformer. It is basically very similar to the encoder_layer except that it has 2 attention mechanisms instead of
	just one. The Multi-Head Attention is the first attention mechanism. For our reference language problem, The Portuguese sentence and corresponding padding mask 
	are the only inputs to this sub layer. 
The output of this attention mechanism plus the encoder output are the inputs to the second attention mechanism which is usually referred to as the Encoder-Decoder-Attention
	mechanism. The output of this second Attention mechanism is passed to a fully connected layer just like the one used in the encoder. The first Masked multi-head
	attention layer is done 8 times in parallel just like in the encoder and the results are concatenated. This concatenated result is added to the original after 
	mapping it through one more layer to calculate the residual. 

The final layer maps a tensor of size [N, 40, 512] to a tensor of size [N, 40, pt_vocab_size] where pt_vocab_size is the size of the Portuguese vocabulary. 



This is what allows us to select the predicted word. 


	
</p>
	





	<h1>

Data Wrangling from Scratch
		
	</h1>
<p>

PyTorch offers many new techniques for extracting and processing data sets. As I like building things from scratch, I will present my own approach to data wrangling for 
	Transformers. The approach is very standard and is similar to what you do in NLP for algorithms like word2vec, for instance.

For this example, I will use the implementation of a Transformer-based Translator using the English to Portuguese dataset. The code and data set are available 
	on the book GitHub. First, let us import the libraries:

	
</p>




<center>
<div>
<textarea rows="15" cols="100">


import sklearn
import numpy as np
import nltk
from nltk.tokenize import word_tokenize
from numpy import genfromtxt
from sklearn import datasets
from sklearn.model_selection import train_test_split 
import pandas as pd
import pickle
import collections

  
</textarea>
  
</div>
    </center>
  


<p>

I like working with python dictionaries so, for this example, I extracted the data set and created python dictionaries for training and testing. 
	I saved the dictionaries to Python pickle files for ease of use. The following code shows how to load the dictionaries. 


</p>




 <center>
<div>
<textarea rows="10" cols="100">


def load_dictionary(file_name):
    with open(file_name, 'rb') as handle:
        dict = pickle.loads( handle.read() ) 
    return dict

  
</textarea>
  
</div>
    </center>



<p>

	
After loading the data sets from file, you have to create the dictionary and reverse dictionary. You create 2 dictionaries per language (e.g. two for English 
	and two for Portuguese). These  are dictionaries of ids to tokens and vice-cersa. Notice that I set the vocabulary size to 12,000. You can play with this 
	value for optimal performance.


</p>  







      <center>
<div>
<textarea rows="20" cols="100">

## Includes <eos> and <sos> tokens

def build_dataset(words):
    START_TOKEN = "<sos>"
    END_TOKEN   = "<eos>"
    UNK_TOKEN   = "<unk>"
    count = collections.Counter(words).most_common(12000) 
    dictionary = dict()
    for word, _ in count:
        ##add + 1 so that 0 is not used as index to avoid padding conflict 
        dictionary[word] = len(dictionary) + 1         ## + 1
    size_vocab = len(dictionary)
    dictionary[START_TOKEN] = size_vocab 
    dictionary[END_TOKEN]   = size_vocab + 1 
    dictionary[UNK_TOKEN]   = size_vocab + 2

    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) 
    
    return dictionary, reverse_dictionary


</textarea>
  
</div>
    </center>
  

<p>
The following is an example function in case you want to process sentences with regular expressions or tokenize manually. 



	
</p>




      <center>
<div>
<textarea rows="20" cols="100">


def preprocess_sentence(sentence):
    sentence = sentence.lower().strip()
    # creating a space between a word and the punctuation following it 
    # eg: "it is a cat." => "it is a cat ."
    sentence = re.sub(r"([?.!,])", r" \1 ", sentence)
    sentence = re.sub(r'[" "]+', " ", sentence)
    # replacing everything with space except (a-z, A-Z, ".", "?", "!", ",") 
    
    sentence = re.sub(r"[^a-zA-Z?.!,]+", " ", sentence)
    sentence = sentence.strip()
    return sentence

  
</textarea>
  
</div>
    </center>
  



<p>

For tokenization, I used the NLTK tokenizer. In the paper “Attention Is All You Need”, the authors used byte pair encoding. Byte pair encoding does not use
	full words as tokens. Instead, you do something like this: "walk" and "ing" for the word “walking”. Therefore, words are broken into smaller elements 
	(subwords). Byte-pair encoding is used to tokenize sentences in a language, which, like the WordPiece encoding, breaks words up into tokens that are
	slightly larger than single characters but less than entire words. 


  
	
</p>





      <center>
<div>
<textarea rows="15" cols="100">


def get_tokens(sentence_list): 
    tokens_list = []
    for sentence in sentence_list:
        tokens = word_tokenize(sentence) 
        for word in tokens:
            tokens_list.append(word) 
    tokens_list = np.array(tokens_list) 
    return tokens_list



  
</textarea>
  
</div>
    </center>


<p>

	Once you have the dictionaries and the tokens, you can proceed to convert words into ids with the encode function.


</p>






<center>
<div>
<textarea rows="15" cols="100">


def encode(sentence, dictionary): 
    ids_list = []
    tokens = word_tokenize(sentence) 
    for word in tokens:
        if word in dictionary.keys(): 
            ids_list.append( dictionary[word] )
    return ids_list

  
</textarea>
  
</div>
    </center>



<p>


Decoding is just the process in reverse. Here you convert ids back to tokens using the reverse dictionary for convenience and speed up.


  
	
</p>





  
<center>
<div>
<textarea rows="10" cols="100">

def decode(list_ids, reverse_dictionary): 
    words_list = []
    for id in list_ids:
    if id in reverse_dictionary.keys(): 
        words_list.append( reverse_dictionary[id] )
    return words_list

  
</textarea>
  
</div>
    </center>



<p>

The following function aligns the English and Portuguese sentence pairs and creates two lists.


	
</p>

<center>
<div>
<textarea rows="20" cols="100">


## this returns 2 lists of english and portuguese sentences 
## that are aligned by index

def get_en_and_pt_sentences(train_dict): 
    en_list, pt_list = [], []
    for key, val in train_dict.items():
        print(key)
        print(val)
        en_list.append( val['en']  )
        pt_list.append( val['pt']  )
    return en_list, pt_list


</textarea>
  
</div>
    </center>


  
<p>


The below line of code just loads the sentences data before processing from the pickle objects.

	
</p>




<center>
<div>
<textarea rows="5" cols="100">

## Read in the data of english and portuguese sentences

train_dict = load_dictionary("data/en_pt_train_dictionary.txt") 
validation = load_dictionary("data/en_pt_val_dictionary.txt"  )

</textarea>
  
</div>
</center>



<p>
The next function creates 2 lists of aligned English and Portuguese sentences.

	
</p>




    

<center>
<div>
<textarea rows="5" cols="100">

english_sentence_list, portuguese_sentence_list = get_en_and_pt_sentences(train_dict)

</textarea>
  
</div>
    </center>


<p>
The function get_tokens converts each sentence into a list of tokens. 

	
</p>


  

<center>
<div>
<textarea rows="10" cols="100">


print("creating the dictionaries takes a while ... ")

en_tokens = get_tokens(english_sentence_list   ) 
pt_tokens = get_tokens(portuguese_sentence_list)


</textarea>
  
</div>
</center>



<p>


After creating the dictionaries for each language, we calculate the vocabulary size for each language. 
	
</p>



  

<center>
<div>
<textarea rows="15" cols="120">


## when 2 languages, you have 2 separate tokenizers.

en_dictionary, en_reverse_dictionary = build_dataset(en_tokens) pt_dictionary, pt_reverse_dictionary = build_dataset(pt_tokens)

VOCAB_SIZE_EN = len(en_dictionary) 
VOCAB_SIZE_PT = len(pt_dictionary)

print("vocab size english ",    VOCAB_SIZE_EN) 
print("vocab size portuguese ", VOCAB_SIZE_PT)


</textarea>
  
</div>
    </center>



<p>

The following “for” loop brings all the previous functions together. It results in 2 lists of sentence ids, one for each language  (2 lists of Numpy objects). 
	Notice that, to each sentence list of ids, we add the start token id at the beginning and the end token id at the end. 

The final “if” statement is used to only include sentences shorter than 40 tokens (the max length I used). Sentences shorter than 40 will be padded but all 
	sentences will eventually be tensors of size 40 (n_tokens + padding).

	
</p>




   <center>
<div>
<textarea rows="25" cols="100">


english_sentence_ids_list = [] 
portuguese_sentence_ids_list = []

for i in range( len(english_sentence_list) ): 

    en_sentence = english_sentence_list[i] 
    pt_sentence = portuguese_sentence_list[i]
    
    en_sentence_ids = encode(en_sentence, en_dictionary) 
    pt_sentence_ids = encode(pt_sentence, pt_dictionary)
    
    en_sentence_ids = np.array(en_sentence_ids) 
    pt_sentence_ids = np.array(pt_sentence_ids)
    
    en_START_TOKEN_id = en_dictionary['<sos>'] 
    en_END_TOKEN_id   = en_dictionary['<eos>']
    
    pt_START_TOKEN_id = pt_dictionary['<sos>'] 
    pt_END_TOKEN_id   = pt_dictionary['<eos>']
    
    en_sentence_ids = np.concatenate(
        [ [en_START_TOKEN_id], en_sentence_ids, [en_END_TOKEN_id] ] )
        
    pt_sentence_ids = np.concatenate(
        [ [pt_START_TOKEN_id], pt_sentence_ids, [pt_END_TOKEN_id] ] )
        
    if len(en_sentence_ids) <= MAX_LENGTH and len( pt_sentence_ids) <= MAX_LENGTH: 
        english_sentence_ids_list.append(    en_sentence_ids) 
        portuguese_sentence_ids_list.append( pt_sentence_ids)


</textarea>
  
</div>
    </center>
  

<p>
Now we need to use a Torch padding function. 

  
	
</p>

 


   <center>
<div>
<textarea rows="14" cols="100">


en_MAX_LENGTH = MAX_LENGTH 
pt_MAX_LENGTH = MAX_LENGTH + 1

english_sentence_ids_list = torch.preprocessing.sequence.pad_sequences( english_sentence_ids_list, maxlen=en_MAX_LENGTH, padding='post')

portuguese_sentence_ids_list = torch.preprocessing.sequence.pad_sequences( portuguese_sentence_ids_list, maxlen=pt_MAX_LENGTH, padding='post')


</textarea>
  
</div>
</center>





<p>


	If you would like to view the data, you can do so with the following code.


</p>



 
<center>
<div>
<textarea rows="10" cols="80">


for i in range( len(english_sentence_ids_list) ):   
    print("@@@@@@@@@@@@@@@@@@@@@@@@@@@") 
    print(english_sentence_ids_list[i]) 
    print(portuguese_sentence_ids_list[i])
    ## input()


</textarea>
  
</div>
    </center>




<p>
After padding, the data will look like this:

</p>







<center>
<div>
<textarea rows="20" cols="100">

en
    
[12110   203     4  3947    29     2   168     2     4    27    68  
  4333     8  3622  2943  1012     1 12111     0     0     0     0    
     0     0     0     0     0     0     0     0     0     0     0     
     0     0     0     0     0     0     0 ]

pt
         
[12210    13     4  3947    29     2     5    32    36    16  1145     
     4    58    34  7905    58    25    28   354  2482     3    17    
    27    28  4395     9  2886     7 12211     0     0     0     0     
     0     0     0     0     0     0     0 ]


</textarea>
  
</div>
    </center>





<p>

And without padding, the data will look like this: 

   
	
</p>





     <center>
<div>
<textarea rows="20" cols="100">


en
    
[12110    13     4  3947    29     2     5    32    36    16  
  1145     4    58    34  7905    58    25    28   354  2482     
     3    17    27    28  4395     9  2886     7 12111    ]
         
pt
         
[12210    62   585   132   202  4395 11969     3    43    18    
    27   107  7042    15    10   814 11717     4  4053    89  
  2960     2   157   119     1 12211     ]


</textarea>
  
</div>
    </center>

         


<h1>Summary</h1>
                
<p>

  In this chapter, I have introduced the topic of Transformers. I discussed the main ideas and code for the Encoder Decoder with Multi-Head Attention 
  Transformer first introduced by Vaswani et al. (2017), ideas of BERTs, and the GPT.

</p>



</div>  <!-- for the fixed nav bar -->

    
  </body>
</html>
