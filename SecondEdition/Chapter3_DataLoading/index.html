<html>
<head>

  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

  <body>

<div class="navbar">
  <a href="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/index.html"> Deep Learning </a>
  <a href="https://ricardocalix.substack.com">Substack</a>
  <a href="https://www.youtube.com/channel/UCKRgi-HJDEq0a3nhlG2nQvg">YouTube</a>
  <a href="https://github.com/rcalix1/DeepLearningAlgorithms/tree/main/SecondEdition">GitHub</a>
  <a href="https://www.galacticbackwater.com/theAIhub/index.html">Recommender</a>
  <a href="https://amzn.to/3OauEG0">Books</a>
  <a href="https://www.linkedin.com/in/ricardo-calix-phd">About</a>
  <a href="https://scholar.google.com/citations?hl=en&user=TiKVs6AAAAAJ">Scholar</a>	
  <a href="">Shop</a>
  <a href="https://www.rcalix.com">Contact</a>
</div>

    

<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->

<div class="main">    <!-- for the fixed nav bar -->

<h1>Chapter 3 - Data Loadin and Pre-Processing )</h1>

    <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/ganNN.300dpi.jpg" height="400" width="auto">
      </div>

    </center>

<p>
	In this section of the book I will cover Generative Adversarial Networks (GANs). Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) are a first attempt at creating generative models.  In the context of games, GANs are modeled as a two player adversarial games. One of the biggest challenges faced with supervised learning is annotating the data. We cannot annotate automatically and without annotations we cannot train our learning models. But what if we could substitute the annotation of the data for something else? For instance, what if we could model the annotation task as a game or use other previous knowledge about the world as labels. These ideas are one of the main motivations for GANs. 
GANs are deep neural networks that consist of a generator network connected to a discriminator network. The discriminator network has training data and the generator network only has random or noise data as input. GANs are essentially 2 player games where one player (the generator) creates synthetic data samples, while the second player (the discriminator) takes the generated sample and performs a classification. 
This classification is performed to determine if the synthetic sample is similar to the distribution of the discriminator's training data. Since both networks are connected, the deep neural network (GAN) can learn to generate better synthetic samples with the help of the discriminator’s feedback. Basically, the discriminator tells the generator how to adjust its weights to produce better synthetic samples. 

Generative Adversarial Networks are methods that use 2 deep neural networks to interact with each other and generate data. Its formulation is consistent with 2 player adversarial game frameworks. One of the 2 algorithms (or networks) tries to learn a data distribution and produce new samples similar to the samples in the real data (the generator). The second algorithm (the discriminator) is a classifier that tries to determine if the new samples generated by the generative algorithm are fake or real. These 2 algorithms work together to achieve an optimal outcome of producing better output samples from the Generator. 


The generator in a GAN is based on Auto-encoders. Therefore, before looking at GANs, we will look at the Auto-encoder
</p>




<h1>Copyright, License, FTC and Amazon Disclaimer</h1>

<p>
 Copyright &copy by Ricardo A. Calix. <br/>
 All rights reserved. No part of this work may be reproduced or transmitted in any form or by any means, without written permission of the copyright owner. <br/>
 This post/page/article includes Amazon Affiliate links to products. This site receives income if you purchase through these links. 
 This income helps support content such as this one. 
 <br/>

	

  
</p>

     <center>
      <div class="img"> 
        <a href="https://amzn.to/3vOL8NF"><img src="https://m.media-amazon.com/images/I/71Wi+z5fKzL._SL1233_.jpg" height="500" width="auto"></a>
      </div>

    </center>
    

<h1>

	Generative Adversarial Networks
</h1>


<p>

In this section of the book I will cover Generative Adversarial Networks (GANs). Generative Adversarial Networks (GANs) (Goodfellow et al. 2014) are 
	a first attempt at creating generative models.  In the context of games, GANs are modeled as a two player adversarial games. One of the biggest challenges
	faced with supervised learning is annotating the data. We cannot annotate automatically and without annotations we cannot train our learning models. But what 
	if we could substitute the annotation of the data for something else? For instance, what if we could model the annotation task as a game or use other previous
	knowledge about the world as labels. These ideas are one of the main motivations for GANs. 
GANs are deep neural networks that consist of a generator network connected to a discriminator network. The discriminator network has training data and the generator 
	network only has random or noise data as input. GANs are essentially 2 player games where one player (the generator) creates synthetic data samples, while the 
	second player (the discriminator) takes the generated sample and performs a classification. 
This classification is performed to determine if the synthetic sample is similar to the distribution of the discriminator's training data. Since both networks are 
	connected, the deep neural network (GAN) can learn to generate better synthetic samples with the help of the discriminator’s feedback. Basically, the discriminator 
	tells the generator how to adjust its weights to produce better synthetic samples. 
<br />
Generative Adversarial Networks are methods that use 2 deep neural networks to interact with each other and generate data. Its formulation is consistent with 2 player
	adversarial game frameworks. One of the 2 algorithms (or networks) tries to learn a data distribution and produce new samples similar to the samples in 
	the real data (the generator). The second algorithm (the discriminator) is a classifier that tries to determine if the new samples generated by the generative 
	algorithm are fake or real. These 2 algorithms work together to achieve an optimal outcome of producing better output samples from the Generator. 

<br />
The generator in a GAN is based on Auto-encoders. Therefore, before looking at GANs, we will look at the Auto-encoder
	
</p>

<h1>
Autoencoders
	
</h1>

<p>

Autoencoders are a type of compression method where a neural network learns how to represent a vector of size “m” into a vector of size “n” where m >> n. 
	Here, the input and output vectors in the network are the original sample and the reproduced sample and the hidden layer of the network is the new
	compressed representation of the input vector. The objective function minimizes the difference/distance between the original input sample and the reproduced 
	output sample.  
	
</p>


\chapter{Data Loading and Pre-processing}


In this chapter, I will address the very important issue of dealing with the data. To me and most practitioners, data collection is the most important issue in machine learning. 

\textbf{ \underline{Objective:}} Data Loading and Pre-processing.


There are many aspects that must be addressed when dealing with data. These include: 

\begin{itemize}
\item getting the data
\item cleaning data
\item pre-processing data
\item building a corpus and annotating it
\item performing inter-annotator agreement
\item etc.
\end{itemize}




Here in this chapter I will also address general issues about data as well as data issues related to deep learning such as one-hot encoding.   

\section{ Loading the Data}

Data can be obtained from the web such as text from twitter or web pages. Specific data sets can also be obtained from the machine learning libraries. Sklearn has a “dataset” module. This dataset module can be used to obtain certain data sets such as the iris dataset. An example of this code can be seen below.



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Iris data}}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

iris = datasets.load_iris() 

X = iris.data[:, [1,2,3]]

y = iris.target
   


\end{lstlisting}
\end{minipage}



\begin{comment}

This is my comment.
Note that it can span multiple lines.
This is very useful.
\end{comment}


Here, the first index in the data matrix represents the rows and the second index represents the columns. Data can also be obtained from text files. Many practitioners and academics will have their own data in text files. This data can be formatted in many different ways and loaded into the code. In most of the examples in this book, the data is assumed to be formatted in csv (comma separated) format. 
The code to load the data to both SKlearn based traditional machine learning algorithms and to PyTorch code files is shown below. In the code we can see that we are using the numpy library (or namespace) to obtain the data. We assume the data is stored in the file data/12559\_Training\_Dataset.csv and is read by loadtxt() into the python variable Matrix\_data. Since we are using csv format, the data file can look like the following.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Iris data}}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

1.0,6.1,2.8,4.7,1.2 
0.0,5.7,3.8,1.7,0.3 
2.0,7.7,2.6,6.9,2.3 
1.0,6.0,2.9,4.5,1.5 
1.0,6.8,2.8,4.8,1.4 
0.0,5.4,3.4,1.5,0.4 
...
   


\end{lstlisting}
\end{minipage}


Once the data is in Matrix\_data, it can be processed as a numpy array matrix. This means that it is no longer just an array but instead it is more a vector or matrix as in linear algebra. Many operations are now simplified like extracting certain columns or rows. This is usually referred to as slicing.

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Iris data slicing}}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

f_numpy = open("data/12559_Training_Dataset.csv",'r') 

Matrix_data = numpy.loadtxt(f_numpy, delimiter=",", skiprows=1)
A = len(Matrix_data[0,:])
print("num features,", A )

#X=Matrix_data[:, [1,2,3,4,5,6]] 

X = Matrix_data[:,:18]             #[:,:149] 
y = Matrix_data[:, 19]
   


\end{lstlisting}
\end{minipage}


In the previous code we can see that we can calculate the dimensions of the matrix as in 

A = len( Matrix\_data[0,:] ) 

which gives you the number of columns or the number of features plus the class. 



\section{Data and Feature Pre-Processing }

Feature scaling is very important to achieving good results in modeling tasks. For example, in Principal Component Analysis (PCA) which is a feature reduction technique, feature scaling is very important. The purpose of PCA is to project data to a vector that captures the most variability in the data. If the features are not scaled properly, one feature could dominate over the others and therefore be considered as the most variable feature. 
With feature scaling, features with real valued numbers from any range can be mapped to other ranges such as from -1.0 to 1.0. This is performed for all features so that no one feature will dominate in the model. 
Other classifiers and Deep learning models are also susceptible to feature scaling. The code below shows how the data can be scaled from X\_train to X\_train\_normalized. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Feature Scaling}}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## feature scaling
sc = StandardScaler()

sc.fit(X_train)

X_train_normalized = sc.transform(X_train)
X_test_normalized  = sc.transform(X_test)


\end{lstlisting}
\end{minipage}

In the following code I am showing you a general way in which you can take a standard dataset such as iris or mnist and save it to a csv file. 
This approach allows you to do the deep learning modeling by reading data from text files where the data is formatted in a very standard and well know format such as csv (comma separated format). 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={create csv files }}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

## create csv files from mnist or iris

def buildDataFromMnist(data_set):
    #iris = datasets.load_iris()
    X_train, X_test, y_train, y_test =
                train_test_split(data_set.data, data_set.target, test_size=0.30, random_state=42) 
                
    f=open('2.0_training_mnist.csv','w')
    for i,j in enumerate(X_train):
        k=np.append(np.array(  y_train[i]), j   )
        f.write(",".join([str(s) for s in k]) + '\n')
    f.close() 
        
    f=open('2.0_testing_mnist.csv','w') 
    for i,j in enumerate(X_test):
        k=np.append(np.array( y_test[i]), j   )
        f.write(",".join([str(s) for s in k]) + '\n')
    f.close()


\end{lstlisting}
\end{minipage}


\section{ One Hot Encoding}

Algorithm implementations in PyTorch use one-hot encoding. Quite simply, one hot encoding means that you take labels in the following format.



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={one-hot encoding before }}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

0 
1 
1 
2 
0 
1 
1 
2 
1 
...


\end{lstlisting}
\end{minipage}



and convert them to labels in the equivalent one-hot encoded format as shown below. So, we create new vectors where all values are zero except for the value of the position of the correct class in the vector. 



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={one-hot encoding after}}
%% \lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


1,0,0 
0,1,0 
0,1,0 
0,0,1 
1,0,0 
0,1,0 
0,1,0 
0,0,1 
0,1,0 
...

\end{lstlisting}
\end{minipage}


One-hot encoding transforms the labels vector (y) of size n into a matrix of size n by B where B represents the number of classes in the data set. For the case of the iris dataset, we have 3 classes and, therefore, for a sample with label 2 we would get an equivalent one-hot encoded vector equal to [0,0,1]. 
The code to convert the data to one-hot encoded format is provided below. There are several ways of implementing one-hot encoding. I have used the approach below because I think it is the easiest to understand (while possibly not the most efficient or pythony).
Notice how “a” is a 2-dimensional array initialized with all zeros. You use the value in the input vector data to determine the index i and j that are used to assign a 1 to the correct position in the matrix. 



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={one-hot encoding code}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

# Convert to one hot data
def convertOneHot_data2(data):
    y=np.array([int(i) for i in data])
    #print y[:20]
    rows = len(y)
    columns = y.max() + 1
    a = np.zeros(shape=(rows,columns))
    #print a[:20,:]
    print rows
    print columns
    #rr = raw_input()
    #y_onehot=[0]*len(y)
    
    for i,j in enumerate(y):
        #y_onehot[i]=np.array([0]*(y.max() + 1) )
        #y_onehot[i][j]=1
        a[i][j]=1
        
    return (a)

\end{lstlisting}
\end{minipage}

\section{Features}

A supervised machine learning algorithm is only as good as the features that are provided to it. This statement used to be very true and many people made careers of just developing features for problems in different domains. For instance, in NLP, many people would spend a lot of time developing parsers and other techniques to find and create features from a text based problem. Similarly, in image processing, researchers developed many techniques to filter data out of images to perform efficient image classification. Today, deep learning has somewhat changed this. It has managed to introduce approaches to decrease the amount of human involvement in the feature extraction process. Basically, deep learning methods, in some cases, have the ability to extract features from data using only un-supervised or semi-supervised techniques. In some way, you can say that deep learning algorithms can extract the features themselves without human involvement. This ability has had a very strong impact in the performance of the algorithms implemented in industry and in the work performed by machine learning specialists. These abilities for enhanced feature extraction are available in the main mediums of text processing and image processing.

\subsection{Features from Text}

Feature extraction from text usually involves the processing of text documents to extract tokens, words, chunks, or other phrases to be used to create the features. There are many, many types of features that can be extracted from text. Some of the methods (Jurafsky and Martin 2008) that can be used are:




\begin{itemize}
\item the bag of words approach
\item frequency histograms of the words
\item Part of speech tagging of the words
\item Syntactic parsing of sentences
\item Anaphora resolution
\item word embeddings (the main method used today)
\end{itemize}

With the information provided by the previous methods, many features can be extracted. In general, text features can be binary or numeric. Binary features include the presence or absence of words, part of speech tags, chunks, syntactic parses, semantic parses, etc. Numeric based text features can be derived from performing counts or calculating distance metrics between words or higher level semantic concepts.
 
One technique in particular that has had success to extract features for supervised machine learning is called the gramulator (McCarthy et al. 2012). The gramulator is a feature extraction technique used particularly in natural language processing. The main idea is that, for a 2 class problem, you want to extract features (e.g. words) that are very frequent in one class but infrequent in the other. This helps to better discriminate between the classes. The downside of this approach, however, is that it needs a lot of annotated or labeled data to extract the grams or words from each class that are infrequent in the opposite class. If the grams are representative of the entire population; then, it can be expected that a classifier will have good performance in the classification task.

The downside of most of these techniques is that in the past they have required annotated data. Deep learning has several new techniques that address this issue and obtain good performance without needing large amounts of annotated data. These mainly involve some type of word embedding. Word embeddings are vector representations of words or syllables or subwords. The vectors are dense and usually of fixed size such as 256. The values of each vector representing the token in question are learned through some algorithmic scheme such as word2vec, or Transformers (covered in next chapters).

\subsection{Features from Images}

Feature extraction from images is another area where deep learning is revolutionizing the way features are engineered and obtained. The input to a classifier when performing image processing and classification is an image. In general images are 2 dimensional arrays that contain the pixel intensities that define the image. For color images, you have 3 two-dimensional matrices where each stores the intensity for the R, G, and B colors of the image. 

\subsubsection{Traditional Feature Extraction Techniques}

In the past, these images where converted into feature vectors for use in machine learning using image processing based feature extraction techniques. Again, here, researchers spent considerable amounts of time performing feature engineering. Some of the methods widely used in image processing (Gonzales and Woods) include:



\begin{itemize}
\item Image segmentation
\item Region growing
\item Image morphing
\item Fourier transformations
\item Etc.
\end{itemize}

Many features could be extracted from these methods. Generally speaking, many of these techniques are implemented as a filter that is applied to the images to convert them into another matrix of the same size or of another size. This new image will store new information about the image such as the pixel positions where an edge was detected. Here, once again, deep learning changed how this process is done. 


Deep neural networks can be used to discover the features simply by providing the inputs and some annotation. This information alone allows the neural network architecture to connect the neurons in ways where it can discover features by itself. In fact, deep neural networks are not just used for classification but can also be used just for feature extraction. The extracted features can then be used with other classifiers such as SVM, logistic regression, etc. In these cases, the input layer and hidden layers are used for feature extraction without having to use the output layer for classification. Convolutional Neural Networks (CNNs) can provide this functionality in image processing and classification.

\subsubsection{A Class to Load Images into Tensors}

Loading images into tensors can be challenging. The following code listing presents an object oriented approach to load images from files into pytorch tensors. This class was written by my students Danielle Turner, David Highley, and Joseph Shapiro and I thank them for it. 

First we import the libraries. 

\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Load images class - libraries}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

import os
import torch
import imageio
import torchvision

from torch.utils.data import Dataset

from torchvision import transforms

from sklearn.model_selection import train_test_split

\end{lstlisting}
\end{minipage}




Next we define the class to load the images from folders into tensors. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Load images class - part 1 }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

class ImageDataset(Dataset):
  
    def __init__(self, dataset_save="data.pt", raw_data=None, train=True, shuffle=False, transform=None, target_transform=None, convert=False, size=32):
        self.targets = []
        self.labels = []
        self.data = []

        self.X_train = []
        self.X_test = []
        self.y_train = []
        self.y_test = []
        
        self.transform = transform
        self.target_transform = target_transform

        if convert:
            self.convert(dataset_save, raw_data, size)
        else:
            self.load(dataset_save)

        seed = int(random.random() * 100) if shuffle else 42

        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.targets, test_size=0.2, random_state=seed)

        if train:
            self.data = self.X_train
            self.targets = self.y_train
        else:
            self.data = self.X_test
            self.targets = self.y_test

    def __len__(self):
        return len(self.data)

    ...

\end{lstlisting}
\end{minipage}



The Dataset of images is data\_path which is the path to the images folder. This should contain multiple folders of each class



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={folder of images structure }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]


            - images
                - cats
                    - cat1.jpg
                - dogs
                    - some-dog.jpg
                - ...

\end{lstlisting}
\end{minipage}


The root is where the pt file will be stored. The train parameter is for whether to load train or test data. The transform parameter indicates the torch transform to apply to the image data. The target\_transform is the transform to apply to the targets. The convert parameter is used to indicate if the data should be converted from images, or loaded from a pt file. The size parameter is to set the size of the images to convert to. This should be the same as the size of the images in the pt file.

The next code segment includes the convert and load functions for the images. 


\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Load images class - part 2 }}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

class ImageDataset(Dataset):
  
    ...

    def __getitem__(self, index):
        image, target = self.data[index], self.targets[index]
        if self.transform is not None:
            image = self.transform(image)
        if self.target_transform is not None:
            target = self.target_transform(target)
        return image, target
    
    def convert(self, dataset_save, raw_data, size):
        dataset = []
        self.labels = []
        targets = []
        if not os.path.exists(raw_data):
            raise ValueError('Raw image directory does not exist.') 
        for folder in os.listdir(raw_data):
            if folder == ".DS_Store":
                continue

            for image in os.listdir(os.path.join(raw_data, folder)):
                if folder not in self.labels:
                    self.labels.append(folder)
                targets.append(self.labels.index(folder))

                img_arr = imageio.imread(os.path.join(raw_data, folder, image), pilmode="RGB")
                resize = torchvision.transforms.Resize(size)
                crop_center = torchvision.transforms.CenterCrop(size)

                img = torch.from_numpy(img_arr).permute(2, 0, 1).float()
                img = resize(img)
                img = crop_center(img)
                img /= 255

                dataset.append(img)

        self.data = torch.stack(dataset)
        self.targets = torch.Tensor(targets).type(torch.LongTensor)

        torch.save((self.data, self.targets, self.labels), dataset_save)

    def load(self, dataset_save):
        if not os.path.exists(dataset_save):
            raise ValueError('Dataset file does not exist. Try creating the dataset by running with convert=True first.') 
        self.data, self.targets, self.labels = torch.load(dataset_save)

\end{lstlisting}
\end{minipage}




\section{Corpora}

A supervised machine learning algorithm is only as good as the data that is provided to it. Learning models learn how human annotators assign the labels to a sample and a system can only be expected to be as good as the human annotator. Some tasks are more subjective than others for human annotators and this is usually reflected in the classifier performance. Therefore, many practitioners recommend that before measuring classifier performance, and analysis of the subjectivity of the human annotation should be performed. This is usually referred to as inter annotator agreement. 
When annotating a new resource, the quality of the annotation process must be measured in some way. Inter-annotator metrics refer to techniques used to measure the overall agreement between the annotations of two or more individuals. Important metrics used to evaluate inter-annotator agreement (\babelEN{\cite{artsteinRef}}) include: 

\begin{itemize}
\item average observed agreement
\item Pi
\item Alpha
\item S
\item Kappa 
\end{itemize}




These metrics differ in how they correct for expected chance agreement. 

\textbf{Expected chance agreement}

Expected chance agreement is a probability that 2 annotators will agree on their annotation for an item by chance. This probability depends on the number of classes. Formally, this probability is calculated as follows:

\begin{center} 
$  A_e =  \sum_{k \in K} P( k | c_1) \cdot P(k | c_2)    $
\end{center}



where $ c_i  $  is the annotator $ i $ , and $ k $ is the assigned category. Inter-annotator agreement metrics are important because they help to set theoretical boundaries on the accuracy that a given machine learning methodology can achieve using the annotated corpora (\babelEN{\cite{birdRef}}). A brief description of some of the techniques is provided in the following discussion.

\textbf{Average Observed Agreement (Ao)}

Averaged observed agreement is the easiest metric to compute. It is the percentage of annotations that two annotators agreed upon. The metric is formulated as follows where the variable “samples” represents the total number of annotation samples and “agreed” is the amount of samples for which both annotators agreed.

\begin{center} 
$  A_o = \frac{1}{samples} \sum Agreed $
\end{center}


\textbf{ Chance-corrected Metrics (Acorr) }

Chance corrected metrics are those that take into account the expected chance agreement Ae. Once chance agreement is defined, the metric can be corrected. These types of metrics include: s, alpha, and kappa. Formally, the main concept in these metrics is defined as follows: 


\begin{center} 
$  A_{corr} =  \frac{A_o - A_e}{1 - A_e}   $
\end{center}


The following code shows how to perform this analysis using the well known nltk ( www.nltk.org ) framework. 



\begin{minipage}{\linewidth}
\lstset{language=Python}
\lstset{frame=lines}
\lstset{caption={Interannotator agreement code}}
%%\lstset{label={lst:code\_direct}}
\lstset{basicstyle=\footnotesize}
\begin{lstlisting}[backgroundcolor = \color{white}]

#interannotator agreement
import nltk

toy_data = [
    ['1', 5723,   'ORG'],
    ['2', 5723,   'ORG'],
    ['1', 55829,  'LOC'],
    ['2', 55829,  'LOC'],
    ['1', 259742, 'PER'],
    ['2', 259742, 'LOC'],
    ['1', 269340, 'PER'],
    ['2', 269340, 'LOC']
]

task = nltk.metrics.agreement.AnnotationTask(data=toy_data)

print('kappa', task.kappa() )
print('alpha', task.alpha() )
print('average Agreement', task.avg_Ao() print 'pi', task.pi() )
print( 's', task.S() ) 

toy1 = ['ORG','LOC','PER','PER']
toy2 = ['ORG','LOC','LOC','LOC']
cm = nltk.metrics.ConfusionMatrix(toy1,toy2)
print( cm )

\end{lstlisting}
\end{minipage}



More details about data collection, corpora development, and web scraping can be found from the following sources: Web Scraping with Python by Ryan Mitchell, Calix and Knapp (2011), and Natural Language Processing with Python by Bird, Klein, and Loper.  

\section{Summary}

In this chapter, a discussion about issues related to data and data pre-processing was provided. In particular, the following topics were addressed: data pre-processing, reading data from csv files, types of features, corpora processing, and one-hot encoding. In the next chapter, we will begin our discussion of how to program out first deep learning models with PyTorch. 




   












<h1>
Original GAN
	
</h1>

<p>
The original GAN consists of a generator and a Discriminator and was proposed in a 2014 paper by Ian Goodfellow. The general architecture of the GAN can be seen
	in the figure below.

	
</p>

  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/ganNN.300dpi.jpg" height="400" width="auto">
      </div>

    </center>	





<h1>
Generating MNIST digits with GANs
	
</h1>

<p>
In this section, I will describe how to implement a GAN that can generate images. The algorithm will work with the MNIST data set. As always, 
	the code can be downloaded from my GitHub. 
<br/>
First we import the libraries. 


	
</p>


<center>
<div>
<textarea rows="20" cols="100">

import torch
import numpy as np
import os
from torchvision import datasets
from torchvision import transforms
import torchvision.transforms as T
import matplotlib.pyplot as plt
import pandas as pd
from numpy import genfromtxt
from PIL import Image
import sklearn
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score
from mlxtend.plotting import heatmap
from sklearn.model_selection import train_test_split
from mlxtend.plotting import heatmap
from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim 
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable


</textarea>
  
</div>
</center>






     


Next we can define the parameters as follows



<center>
<div>
<textarea rows="7" cols="100">

learning_rate    = 0.003  ## Adam default   ## 0.001
batch_size       = 32
N_Epochs         = 30  ##27000  

</textarea>
  
</div>
</center>



<p>
We load the MNIST data in a similar way to what we did in previous chapters

	
</p>

<center>
<div>
<textarea rows="16" cols="100">

data_path   = "data/MNISTdata/"
mnist_train = datasets.MNIST(data_path, train=True, download=True)
mnist_test = datasets.MNIST(data_path, train=False, download=True)

mnist_train_tr = datasets.MNIST(data_path, train=True, download=False, 
                                            transform=transforms.Compose([
                                                transforms.ToTensor()
                                            ]))
                                            
mnist_test_tr  = datasets.MNIST(data_path, train=False, download=False, 
                                            transform=transforms.Compose([
                                                transforms.ToTensor()
                                            ]))

</textarea>
  
</div>
</center>





     


It is a good idea to print the shapes of the tensors before creating the DataLoaders.

<center>
<div>
<textarea rows="16" cols="100">

mnist_train_tr.data.shape
## [60000, 28, 28]

mnist_test_tr.data.shape
## [10000, 28, 28]

train_dl  = torch.utils.data.DataLoader(mnist_train_tr, batch_size=batch_size, shuffle=True  ) 

test_dl   = torch.utils.data.DataLoader(mnist_test_tr,  batch_size=batch_size, shuffle=False ) 


</textarea>
  
</div>
</center>





     


Now we are ready to define the GAN architectures. GANs have a Generator and a Discriminator

In the following code segment we define the architecture for the Generator. Notice that this will be a neural network of size 100x256x784. 

<center>
<div>
<textarea rows="25" cols="100">

class Generator_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        

        self.linear1 = nn.Linear(100, 256)
        self.act1    = nn.LeakyReLU(0.02)
        self.norm1   = nn.LayerNorm(256)
        self.linear2 = nn.Linear(256, 784)
        self.act2    = nn.Sigmoid()
        self.dropout = nn.Dropout(0.25)
        
    def forward(self, rand_input ):
        

        x      = self.linear1( rand_input )
        x      = self.act1(x)
        x      = self.norm1(x) 
        x      = self.linear2(x)
        x      = self.act2(x)
        y_pred = x
        
        return y_pred

     
</textarea>
  
</div>
</center>





I also tried a deeper architecture for the GAN but was not able to get it to learn in 30 epochs as I did with the simple MLP GAN. I am including it here and leave it as a exercise for the reader. 


<center>
<div>
<textarea rows="25" cols="100">


class Generator_DL_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.linear1 = nn.Linear(100, 60)
        self.act1    = nn.LeakyReLU(0.02)
        self.norm1   = nn.LayerNorm(60)
        self.linear2 = nn.Linear(60, 120)
        self.act2    = nn.LeakyReLU(0.02)
        self.norm2   = nn.LayerNorm(120)
        self.linear3 = nn.Linear(120, 784)
        self.act3    = nn.Sigmoid()
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, rand_input ):
        

        x      = self.linear1( rand_input )
        x      = self.act1(x)
        x      = self.norm1(x) 
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.norm2(x) 
        x      = self.dropout(x)
        x      = self.linear3(x)
        x      = self.act3(x)
        
        y_pred = x
        
        return y_pred

     

</textarea>
  
</div>
</center>
	




The architecture for the Discriminator can be seen in the next code segment.



<center>
<div>
<textarea rows="25" cols="100">

class Discriminator_Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        
        self.linear1 = nn.Linear(784, 100)
        self.act1    = nn.ReLU()
        self.linear2 = nn.Linear(100, 50)
        self.act2    = nn.ReLU()
        self.linear3 = nn.Linear(50, 1)
        self.act3    = nn.Sigmoid()             ## nn.Softmax(dim=1)
        self.dropout = nn.Dropout(0.25)
        

    def forward(self, x):
        
        x      = self.linear1(x)
        x      = self.act1(x)
        x      = self.dropout(x)
        x      = self.linear2(x)
        x      = self.act2(x)
        x      = self.dropout(x)
        x      = self.linear3(x)
        y_pred = self.act3(x)
        
        return y_pred

     
</textarea>
  
</div>
</center>
	






Notice that the architecture for this network is 784x100x50x1. Its input is an image vector (real or fake) and its output is one neuron with value 0 or 1. 

The following function can be used to generate seed random noise vectors for the Generator input. For training we want batches of noise vectors.



<center>
<div>
<textarea rows="9" cols="100">

def random_G_batch_vector_input():
    rand_vec = torch.randn( (batch_size, 100 ) )
    return rand_vec

    
</textarea>
  
</div>
</center>
	









To generate individual images, we can use the following function to generate seed noise vectors



<center>
<div>
<textarea rows="9" cols="100">

def random_G_vector_input():
    rand_vec = torch.randn( 100 )
    return rand_vec
    
</textarea>
  
</div>
</center>






     


The Training function for the GAN is the most complicated we have seen so far. The full code can be seen seen below. As can be seen, we train the discriminator twice and the generator once. The Discriminator looks at a real image and it should predict that it is real (a one). Then the discriminator looks at a generated image (fake) and it should predict that it is a fake (a zero). The discriminator weights should be updated accordingly for these objectives. The final step is to update the weights of the Generator. Here, we want to trick the discriminator. So now the generated image (fake) is given to the Discriminator but we want it to say that it is real (a one). We do this using the loss of the Discriminator but adjust the weights of the Generator. So the Generator weights are updated in such a way that it generates images that trick the Discriminator into predicting that the fake images are true (a one). 

Notice that before training, we need to squeeze and reshape the input \textbf{xb} tensor from [batch, 1, 28, 28] to [batch, 784] . We can do that with the following statements.

<center>
<div>
<textarea rows="6" cols="100">

xb = torch.squeeze(xb, dim=1)
            
xb = xb.reshape((-1, 784))

    
</textarea>
  
</div>
</center>
	


<p>

	and the GAN training function is
</p>
     

<center>
<div>
<textarea rows="35" cols="100">

	
list_losses_real    = []
list_losses_fake    = []
list_losses_tricked = []
def training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt   ):
    for epoch in range(N_Epochs):
        for xb, yb in train_dl:              ## xb = [batch, 1, 28, 28]
            xb = torch.squeeze(xb, dim=1)
            xb = xb.reshape((-1, 784))
            #################################################
            ## G_model.eval()     ## No G training
            ## gen_img = G_model( random_G_vector_input() )
            gen_img = G_model( random_G_batch_vector_input() ).detach()
            ## Train D with real data
            D_real_y_pred = D_model(  xb  )
            D_real_loss   = D_loss_fn( D_real_y_pred, torch.ones((batch_size, 1)) )
            D_opt.zero_grad()
            D_real_loss.backward()
            D_opt.step()
            ## Train D with fake data
            D_fake_y_pred = D_model(  gen_img  )
            D_fake_loss   = D_loss_fn( D_fake_y_pred, torch.zeros((batch_size, 1)))
            D_opt.zero_grad()
            D_fake_loss.backward()
            D_opt.step()
            ## G_model.train()    ## yes G training
            #################################################
            ## D_model.eval()     ## No D training
            ## gen_img = G_model( random_G_vector_input() )
            gen_img = G_model( random_G_batch_vector_input() )
            ## Train G with D_loss (need to trick D)
            D_tricked_y_pred = D_model(  gen_img  )
            D_tricked_loss   = D_loss_fn( D_tricked_y_pred, torch.ones((batch_size, 1)) )
            G_opt.zero_grad()
            D_tricked_loss.backward()
            G_opt.step()
            ## D_model.train()    ## yes D training
        if epoch % 1 == 0:
            print("******************************")
            print(epoch, "D_real_loss=", D_real_loss)
            print(epoch, "D_fake_loss=", D_fake_loss)
            print(epoch, "D_tricked_loss=", D_tricked_loss)
            list_losses_real.append(        D_real_loss.detach().numpy()  )
            list_losses_fake.append(        D_fake_loss.detach().numpy()  )
            list_losses_tricked.append(  D_tricked_loss.detach().numpy()  )
            


    
</textarea>
  
</div>
</center>




Finally, we can call the core functions and print the losses during training. 

<center>
<div>
<textarea rows="12" cols="100">

G_model     = Generator_Net()

## G_model     = Generator_DL_Net()

D_model     = Discriminator_Net()

## D_loss_fn   = nn.CrossEntropyLoss( )  
## D_loss_fn   = F.mse_loss

D_loss_fn   = nn.BCELoss()

G_opt       = torch.optim.Adam( G_model.parameters(), lr=learning_rate )
D_opt       = torch.optim.Adam( D_model.parameters(), lr=learning_rate )

training_loop(  N_Epochs, G_model, D_model, D_loss_fn, G_opt, D_opt )


</textarea>
  
</div>
</center>





We can seen below that the losses are going down for both the Generator and Discriminator. 

<center>
<div>
<textarea rows="25" cols="100">

******************************
0 D_real_loss= tensor(0.1157, grad_fn=<BinaryCrossEntropyBackward0>)
0 D_fake_loss= tensor(0.0114, grad_fn=<BinaryCrossEntropyBackward0>)
0 D_tricked_loss= tensor(7.8405, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
1 D_real_loss= tensor(0.2492, grad_fn=<BinaryCrossEntropyBackward0>)
1 D_fake_loss= tensor(0.0604, grad_fn=<BinaryCrossEntropyBackward0>)
1 D_tricked_loss= tensor(5.4396, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
2 D_real_loss= tensor(0.1128, grad_fn=<BinaryCrossEntropyBackward0>)
2 D_fake_loss= tensor(0.0804, grad_fn=<BinaryCrossEntropyBackward0>)
2 D_tricked_loss= tensor(4.2457, grad_fn=<BinaryCrossEntropyBackward0>)

...

******************************
27 D_real_loss= tensor(0.6145, grad_fn=<BinaryCrossEntropyBackward0>)
27 D_fake_loss= tensor(0.3502, grad_fn=<BinaryCrossEntropyBackward0>)
27 D_tricked_loss= tensor(1.2594, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
28 D_real_loss= tensor(0.4972, grad_fn=<BinaryCrossEntropyBackward0>)
28 D_fake_loss= tensor(0.3535, grad_fn=<BinaryCrossEntropyBackward0>)
28 D_tricked_loss= tensor(1.2053, grad_fn=<BinaryCrossEntropyBackward0>)
******************************
29 D_real_loss= tensor(0.5411, grad_fn=<BinaryCrossEntropyBackward0>)
29 D_fake_loss= tensor(0.5512, grad_fn=<BinaryCrossEntropyBackward0>)
29 D_tricked_loss= tensor(1.2962, grad_fn=<BinaryCrossEntropyBackward0>)

     

</textarea>
  
</div>
</center>





Using the following function, we can plot the losses. 

<center>
<div>
<textarea rows="15" cols="100">

def plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked):
    
    the_epochs = [i for i in range(len(list_losses_real))]  

    plt.plot(the_epochs, list_losses_real,    label = "real") 
    plt.plot(the_epochs, list_losses_fake,    label = "fake") 
    plt.plot(the_epochs, list_losses_tricked, label = "tricked")
    plt.legend() 
    plt.show()

plot_GAN_losses(list_losses_real, list_losses_fake, list_losses_tricked)


</textarea>
  
</div>
</center>






     


We can see that the losses of the Generator did not go below the discriminator loss. A good objective would be for them to be equal. 

	
  <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/GAN_losses_plot.png" height="400" width="auto">
      </div>

    </center>	



And that is it. The GAN is now trained. We can now proceed to test it and generate a few images. We can do that with the following code segment. 

<center>
<div>
<textarea rows="15" cols="100">

gen_test_img3 = G_model( random_G_vector_input() )
gen_test_img3 = gen_test_img3.reshape( (28,28) )
plt.imshow( gen_test_img3.detach().numpy() )
plt.show()

</textarea>
  
</div>
</center>





     


I did this several times and the results of the generated images are as follows. This first image looks like a bad zero. 

 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/bad_zero_gan.png" height="400" width="auto">
      </div>

    </center>
	



This next image looks like a better version of the zero.

 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/good_zero_gan.png" height="400" width="auto">
      </div>

    </center>



And I believe this looks like a five.


 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/good_5_gan.png" height="400" width="auto">
      </div>

    </center>



<h1>
Conditional GANs
	
</h1>

<p>

The conditional GAN  (CGAN) can generate more than random images from a distribution. Instead, in the case on MNIST, for example, 
	it can generate the image of an image given the corresponding label for the image. The architecture for the CGAN can be seen below.
	
</p>


	 <center>
      <div>
        <img src="https://rcalix1.github.io/DeepLearningAlgorithms/SecondEdition/images/ConditionalGanDiagram.jpg" height="400" width="auto">
      </div>

    </center>



<h1>
Summary
</h1>
	
<p>
In this chapter, a description of Generative Adversarial Networks was provided. Some sample code was addressed as well as some applications of GANs. 


	
</p>







</div>  <!-- for the fixed nav bar -->

    
  </body>
</html>
